{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project description:\n",
    "\n",
    "Online shops have exact same items that are sold by multiple people. ML could help in order to group them.\n",
    "\n",
    "In Kaggle competition [Shopee - Price Match Guarantee](https://www.kaggle.com/c/shopee-product-matching/overview) there are two item features provided: image and description.\n",
    "\n",
    "Submission file has to include up to 50 best matches from train dataset for every test item.\n",
    "\n",
    "Evaluation: mean F1\n",
    "\n",
    "-----------\n",
    "\n",
    "#### Planned approach in general\n",
    "\n",
    "1. With pre-trained NLP model extract probabilities of described items\n",
    "2. With pre-trained NN model extract probabilities of shown items\n",
    "3. Build AND gate that include both models threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\n\\nimport torch  # 1.4.0\\nimport torch.nn as nn\\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\\nimport torchvision  # 0.5.0\\n\\nimport transformers  # 3.5.1\\nfrom transformers import AutoModel, BertTokenizerFast, AdamW\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.utils.class_weight import compute_class_weight\\nfrom sklearn.model_selection import train_test_split\\n\\nfrom imblearn.over_sampling import RandomOverSampler\\n\\nfrom functools import partial\\n\\nimport time\\n\\nimport io\\nimport os\\n\\nRANDOM = 777\\n\\n%load_ext nb_black\\n\\ndevice = torch.device(\\\"cuda\\\")\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\n\\nimport torch  # 1.4.0\\nimport torch.nn as nn\\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\\nimport torchvision  # 0.5.0\\n\\nimport transformers  # 3.5.1\\nfrom transformers import AutoModel, BertTokenizerFast, AdamW\\n\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.utils.class_weight import compute_class_weight\\nfrom sklearn.model_selection import train_test_split\\n\\nfrom imblearn.over_sampling import RandomOverSampler\\n\\nfrom functools import partial\\n\\nimport time\\n\\nimport io\\nimport os\\n\\nRANDOM = 777\\n\\n%load_ext nb_black\\n\\ndevice = torch.device(\\\"cuda\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch  # 1.4.0\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torchvision  # 0.5.0\n",
    "\n",
    "import transformers  # 3.5.1\n",
    "from transformers import AutoModel, BertTokenizerFast, AdamW\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import time\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "RANDOM = 777\n",
    "\n",
    "%load_ext nb_black\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"train_df = pd.read_csv(\\\"train.csv\\\")\\ntest_df = pd.read_csv(\\\"test.csv\\\")\";\n",
       "                var nbb_formatted_code = \"train_df = pd.read_csv(\\\"train.csv\\\")\\ntest_df = pd.read_csv(\\\"test.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"train_df.head()\";\n",
       "                var nbb_formatted_code = \"train_df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34250, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"train_df.shape\";\n",
       "                var nbb_formatted_code = \"train_df.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"test_df.head()\";\n",
       "                var nbb_formatted_code = \"test_df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"train_df.label_group.nunique()\";\n",
       "                var nbb_formatted_code = \"train_df.label_group.nunique()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.label_group.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label_group'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"val_counts = train_df.label_group.value_counts()\\nvalue_df = pd.DataFrame(val_counts)\\nvalue_df[\\\"count\\\"] = 1\\nvalue_df.groupby(\\\"label_group\\\").sum().plot(kind=\\\"bar\\\")\";\n",
       "                var nbb_formatted_code = \"val_counts = train_df.label_group.value_counts()\\nvalue_df = pd.DataFrame(val_counts)\\nvalue_df[\\\"count\\\"] = 1\\nvalue_df.groupby(\\\"label_group\\\").sum().plot(kind=\\\"bar\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_counts = train_df.label_group.value_counts()\n",
    "value_df = pd.DataFrame(val_counts)\n",
    "value_df[\"count\"] = 1\n",
    "value_df.groupby(\"label_group\").sum().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of products have only 2 representatives of them in train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# extracting text and labels for train and test datasets\\ntrain_text = train_df.title.values\\ntest_text = test_df.title.values\\ntrain_labels = train_df.label_group.values\";\n",
       "                var nbb_formatted_code = \"# extracting text and labels for train and test datasets\\ntrain_text = train_df.title.values\\ntest_text = test_df.title.values\\ntrain_labels = train_df.label_group.values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extracting text and labels for train and test datasets\n",
    "train_text = train_df.title.values\n",
    "test_text = test_df.title.values\n",
    "train_labels = train_df.label_group.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# label encoding\\nle = LabelEncoder()\\ntrain_labels = le.fit_transform(train_labels)\";\n",
       "                var nbb_formatted_code = \"# label encoding\\nle = LabelEncoder()\\ntrain_labels = le.fit_transform(train_labels)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label encoding\n",
    "le = LabelEncoder()\n",
    "train_labels = le.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# balancing dataset\\noversample = RandomOverSampler(sampling_strategy=\\\"not majority\\\")\\n#train_text, train_labels = oversample.fit_resample(\\n#    train_text.reshape(-1, 1), train_labels\\n#)\";\n",
       "                var nbb_formatted_code = \"# balancing dataset\\noversample = RandomOverSampler(sampling_strategy=\\\"not majority\\\")\\n# train_text, train_labels = oversample.fit_resample(\\n#    train_text.reshape(-1, 1), train_labels\\n# )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# balancing dataset\n",
    "oversample = RandomOverSampler(sampling_strategy=\"not majority\")\n",
    "# train_text, train_labels = oversample.fit_resample(\n",
    "#    train_text.reshape(-1, 1), train_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"train_text = train_text.reshape(-1)\";\n",
       "                var nbb_formatted_code = \"train_text = train_text.reshape(-1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_text = train_text.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"train_text, val_text, train_labels, val_labels = train_test_split(\\n    train_text, train_labels, random_state=RANDOM, test_size=0.5\\n)\";\n",
       "                var nbb_formatted_code = \"train_text, val_text, train_labels, val_labels = train_test_split(\\n    train_text, train_labels, random_state=RANDOM, test_size=0.5\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_text, val_text, train_labels, val_labels = train_test_split(\n",
    "    train_text, train_labels, random_state=RANDOM, test_size=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# import BERT-base pretrained model\\nbert = AutoModel.from_pretrained(\\\"bert-base-uncased\\\")\\n\\n# Load the BERT tokenizer\\ntokenizer = BertTokenizerFast.from_pretrained(\\\"bert-base-uncased\\\")\";\n",
       "                var nbb_formatted_code = \"# import BERT-base pretrained model\\nbert = AutoModel.from_pretrained(\\\"bert-base-uncased\\\")\\n\\n# Load the BERT tokenizer\\ntokenizer = BertTokenizerFast.from_pretrained(\\\"bert-base-uncased\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# get length of all the messages in the train set\\nseq_len = [len(i.split()) for i in train_text]\\n\\npd.Series(seq_len).hist(bins=30)\";\n",
       "                var nbb_formatted_code = \"# get length of all the messages in the train set\\nseq_len = [len(i.split()) for i in train_text]\\n\\npd.Series(seq_len).hist(bins=30)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20** is the optimal number for padding lenght, while majority of sentences fit into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ovidi\\anaconda3\\envs\\berta\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2016: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# tokenize and encode sequences in the training set\\ntokens_train = tokenizer.batch_encode_plus(\\n    train_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\\n)\\n\\n# tokenize and encode sequences in the validation set\\ntokens_val = tokenizer.batch_encode_plus(\\n    val_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\\n)\\n\\n# tokenize and encode sequences in the test set\\ntokens_test = tokenizer.batch_encode_plus(\\n    test_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\\n)\";\n",
       "                var nbb_formatted_code = \"# tokenize and encode sequences in the training set\\ntokens_train = tokenizer.batch_encode_plus(\\n    train_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\\n)\\n\\n# tokenize and encode sequences in the validation set\\ntokens_val = tokenizer.batch_encode_plus(\\n    val_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\\n)\\n\\n# tokenize and encode sequences in the test set\\ntokens_test = tokenizer.batch_encode_plus(\\n    test_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(), max_length=20, pad_to_max_length=True, truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"## convert lists to tensors\\n\\ntrain_seq = torch.tensor(tokens_train[\\\"input_ids\\\"])\\ntrain_mask = torch.tensor(tokens_train[\\\"attention_mask\\\"])\\ntrain_y = torch.tensor(train_labels.tolist())\\n\\nval_seq = torch.tensor(tokens_val[\\\"input_ids\\\"])\\nval_mask = torch.tensor(tokens_val[\\\"attention_mask\\\"])\\nval_y = torch.tensor(val_labels.tolist())\\n\\ntest_seq = torch.tensor(tokens_test[\\\"input_ids\\\"])\\ntest_mask = torch.tensor(tokens_test[\\\"attention_mask\\\"])\";\n",
       "                var nbb_formatted_code = \"## convert lists to tensors\\n\\ntrain_seq = torch.tensor(tokens_train[\\\"input_ids\\\"])\\ntrain_mask = torch.tensor(tokens_train[\\\"attention_mask\\\"])\\ntrain_y = torch.tensor(train_labels.tolist())\\n\\nval_seq = torch.tensor(tokens_val[\\\"input_ids\\\"])\\nval_mask = torch.tensor(tokens_val[\\\"attention_mask\\\"])\\nval_y = torch.tensor(val_labels.tolist())\\n\\ntest_seq = torch.tensor(tokens_test[\\\"input_ids\\\"])\\ntest_mask = torch.tensor(tokens_test[\\\"attention_mask\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train[\"input_ids\"])\n",
    "train_mask = torch.tensor(tokens_train[\"attention_mask\"])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val[\"input_ids\"])\n",
    "val_mask = torch.tensor(tokens_val[\"attention_mask\"])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test[\"input_ids\"])\n",
    "test_mask = torch.tensor(tokens_test[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# define a batch size\\nbatch_size = 32\\n\\n# wrap tensors\\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\\n\\n# sampler for sampling the data during training\\ntrain_sampler = RandomSampler(train_data)\\n\\n# dataLoader for train set\\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\\n\\n# wrap tensors\\nval_data = TensorDataset(val_seq, val_mask, val_y)\\n\\n# sampler for sampling the data during training\\nval_sampler = SequentialSampler(val_data)\\n\\n# dataLoader for validation set\\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\";\n",
       "                var nbb_formatted_code = \"# define a batch size\\nbatch_size = 32\\n\\n# wrap tensors\\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\\n\\n# sampler for sampling the data during training\\ntrain_sampler = RandomSampler(train_data)\\n\\n# dataLoader for train set\\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\\n\\n# wrap tensors\\nval_data = TensorDataset(val_seq, val_mask, val_y)\\n\\n# sampler for sampling the data during training\\nval_sampler = SequentialSampler(val_data)\\n\\n# dataLoader for validation set\\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# freeze all the parameters\\nfor param in bert.parameters():\\n    param.requires_grad = False\";\n",
       "                var nbb_formatted_code = \"# freeze all the parameters\\nfor param in bert.parameters():\\n    param.requires_grad = False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"class BERT_Arch(nn.Module):\\n    def __init__(self, bert):\\n\\n        super(BERT_Arch, self).__init__()\\n\\n        self.bert = bert\\n\\n        # relu activation function\\n        self.relu = nn.ReLU()\\n\\n        # dense layer 1\\n        self.fc1 = nn.Linear(768, train_df.label_group.nunique())\\n\\n        # softmax activation function\\n        self.softmax = nn.LogSoftmax(dim=1)\\n\\n    # define the forward pass\\n    def forward(self, sent_id, mask):\\n\\n        # pass the inputs to the model\\n        _, cls_hs = self.bert(sent_id, attention_mask=mask)\\n\\n        x = self.fc1(cls_hs)\\n\\n        x = self.relu(x)\\n\\n        # apply softmax activation\\n        x = self.softmax(x)\\n\\n        return x\";\n",
       "                var nbb_formatted_code = \"class BERT_Arch(nn.Module):\\n    def __init__(self, bert):\\n\\n        super(BERT_Arch, self).__init__()\\n\\n        self.bert = bert\\n\\n        # relu activation function\\n        self.relu = nn.ReLU()\\n\\n        # dense layer 1\\n        self.fc1 = nn.Linear(768, train_df.label_group.nunique())\\n\\n        # softmax activation function\\n        self.softmax = nn.LogSoftmax(dim=1)\\n\\n    # define the forward pass\\n    def forward(self, sent_id, mask):\\n\\n        # pass the inputs to the model\\n        _, cls_hs = self.bert(sent_id, attention_mask=mask)\\n\\n        x = self.fc1(cls_hs)\\n\\n        x = self.relu(x)\\n\\n        # apply softmax activation\\n        x = self.softmax(x)\\n\\n        return x\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "\n",
    "        super(BERT_Arch, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768, train_df.label_group.nunique())\n",
    "\n",
    "        # softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        # pass the inputs to the model\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# pass the pre-trained BERT to our define architecture\\nmodel = BERT_Arch(bert)\\n\\n# push the model to GPU\\nmodel = model.to(device)\";\n",
       "                var nbb_formatted_code = \"# pass the pre-trained BERT to our define architecture\\nmodel = BERT_Arch(bert)\\n\\n# push the model to GPU\\nmodel = model.to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# define the optimizer\\noptimizer = AdamW(model.parameters(), lr=1e-3)\";\n",
       "                var nbb_formatted_code = \"# define the optimizer\\noptimizer = AdamW(model.parameters(), lr=1e-3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# defining loss metric\\ncross_entropy = nn.CrossEntropyLoss()\";\n",
       "                var nbb_formatted_code = \"# defining loss metric\\ncross_entropy = nn.CrossEntropyLoss()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining loss metric\n",
    "cross_entropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# function to train the model\\ndef train():\\n\\n    model.train()\\n\\n    total_loss, total_accuracy = 0, 0\\n\\n    # empty list to save model predictions\\n    total_preds = []\\n\\n    # iterate over batches\\n    for step, batch in enumerate(train_dataloader):\\n\\n        # progress update after every 50 batches.\\n        if step % 50 == 0 and not step == 0:\\n            print(\\\"  Batch {:>5,}  of  {:>5,}.\\\".format(step, len(train_dataloader)))\\n\\n        # push the batch to gpu\\n        batch = [r.to(device) for r in batch]\\n\\n        sent_id, mask, labels = batch\\n\\n        # clear previously calculated gradients\\n        model.zero_grad()\\n\\n        # get model predictions for the current batch\\n        preds = model(sent_id, mask)\\n\\n        # compute the loss between actual and predicted values\\n        loss = cross_entropy(preds, labels)\\n\\n        # add on to the total loss\\n        total_loss = total_loss + loss.item()\\n\\n        # backward pass to calculate the gradients\\n        loss.backward()\\n\\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\\n\\n        # update parameters\\n        optimizer.step()\\n\\n        # model predictions are stored on GPU. So, push it to CPU\\n        preds = preds.detach().cpu().numpy()\\n\\n        # append the model predictions\\n        total_preds.append(preds)\\n\\n    # compute the training loss of the epoch\\n    avg_loss = total_loss / len(train_dataloader)\\n\\n    # returns the loss and predictions\\n    return avg_loss, total_preds\";\n",
       "                var nbb_formatted_code = \"# function to train the model\\ndef train():\\n\\n    model.train()\\n\\n    total_loss, total_accuracy = 0, 0\\n\\n    # empty list to save model predictions\\n    total_preds = []\\n\\n    # iterate over batches\\n    for step, batch in enumerate(train_dataloader):\\n\\n        # progress update after every 50 batches.\\n        if step % 50 == 0 and not step == 0:\\n            print(\\\"  Batch {:>5,}  of  {:>5,}.\\\".format(step, len(train_dataloader)))\\n\\n        # push the batch to gpu\\n        batch = [r.to(device) for r in batch]\\n\\n        sent_id, mask, labels = batch\\n\\n        # clear previously calculated gradients\\n        model.zero_grad()\\n\\n        # get model predictions for the current batch\\n        preds = model(sent_id, mask)\\n\\n        # compute the loss between actual and predicted values\\n        loss = cross_entropy(preds, labels)\\n\\n        # add on to the total loss\\n        total_loss = total_loss + loss.item()\\n\\n        # backward pass to calculate the gradients\\n        loss.backward()\\n\\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\\n\\n        # update parameters\\n        optimizer.step()\\n\\n        # model predictions are stored on GPU. So, push it to CPU\\n        preds = preds.detach().cpu().numpy()\\n\\n        # append the model predictions\\n        total_preds.append(preds)\\n\\n    # compute the training loss of the epoch\\n    avg_loss = total_loss / len(train_dataloader)\\n\\n    # returns the loss and predictions\\n    return avg_loss, total_preds\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # progress update after every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print(\"  Batch {:>5,}  of  {:>5,}.\".format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# function for evaluating the model\\ndef evaluate():\\n\\n    print(\\\"\\\\nEvaluating...\\\")\\n\\n    # deactivate dropout layers\\n    model.eval()\\n\\n    total_loss, total_accuracy = 0, 0\\n\\n    # empty list to save the model predictions\\n    total_preds = []\\n\\n    # iterate over batches\\n    for step, batch in enumerate(val_dataloader):\\n\\n        # Progress update every 50 batches.\\n        if step % 50 == 0 and not step == 0:\\n\\n            # Report progress.\\n            print(\\\"  Batch {:>5,}  of  {:>5,}.\\\".format(step, len(val_dataloader)))\\n\\n        # push the batch to gpu\\n        batch = [t.to(device) for t in batch]\\n\\n        sent_id, mask, labels = batch\\n\\n        # deactivate autograd\\n        with torch.no_grad():\\n\\n            # model predictions\\n            preds = model(sent_id, mask)\\n\\n            # compute the validation loss between actual and predicted values\\n            loss = cross_entropy(preds, labels)\\n\\n            total_loss = total_loss + loss.item()\\n\\n            preds = preds.detach().cpu().numpy()\\n\\n            total_preds.append(preds)\\n\\n    # compute the validation loss of the epoch\\n    avg_loss = total_loss / len(val_dataloader)\\n\\n    return avg_loss, total_preds\";\n",
       "                var nbb_formatted_code = \"# function for evaluating the model\\ndef evaluate():\\n\\n    print(\\\"\\\\nEvaluating...\\\")\\n\\n    # deactivate dropout layers\\n    model.eval()\\n\\n    total_loss, total_accuracy = 0, 0\\n\\n    # empty list to save the model predictions\\n    total_preds = []\\n\\n    # iterate over batches\\n    for step, batch in enumerate(val_dataloader):\\n\\n        # Progress update every 50 batches.\\n        if step % 50 == 0 and not step == 0:\\n\\n            # Report progress.\\n            print(\\\"  Batch {:>5,}  of  {:>5,}.\\\".format(step, len(val_dataloader)))\\n\\n        # push the batch to gpu\\n        batch = [t.to(device) for t in batch]\\n\\n        sent_id, mask, labels = batch\\n\\n        # deactivate autograd\\n        with torch.no_grad():\\n\\n            # model predictions\\n            preds = model(sent_id, mask)\\n\\n            # compute the validation loss between actual and predicted values\\n            loss = cross_entropy(preds, labels)\\n\\n            total_loss = total_loss + loss.item()\\n\\n            preds = preds.detach().cpu().numpy()\\n\\n            total_preds.append(preds)\\n\\n    # compute the validation loss of the epoch\\n    avg_loss = total_loss / len(val_dataloader)\\n\\n    return avg_loss, total_preds\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "\n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "\n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "            # Report progress.\n",
    "            print(\"  Batch {:>5,}  of  {:>5,}.\".format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 1\n",
      "  Batch    50  of    536.\n",
      "  Batch   100  of    536.\n",
      "  Batch   150  of    536.\n",
      "  Batch   200  of    536.\n",
      "  Batch   250  of    536.\n",
      "  Batch   300  of    536.\n",
      "  Batch   350  of    536.\n",
      "  Batch   400  of    536.\n",
      "  Batch   450  of    536.\n",
      "  Batch   500  of    536.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    536.\n",
      "  Batch   100  of    536.\n",
      "  Batch   150  of    536.\n",
      "  Batch   200  of    536.\n",
      "  Batch   250  of    536.\n",
      "  Batch   300  of    536.\n",
      "  Batch   350  of    536.\n",
      "  Batch   400  of    536.\n",
      "  Batch   450  of    536.\n",
      "  Batch   500  of    536.\n",
      "\n",
      "Training Loss: 9.307\n",
      "Validation Loss: 9.307\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"epochs = 1\\n\\n# set initial loss to infinite\\nbest_valid_loss = float(\\\"inf\\\")\\n\\n# empty lists to store training and validation loss of each epoch\\ntrain_losses = []\\nvalid_losses = []\\n\\n# for each epoch\\nfor epoch in range(epochs):\\n\\n    print(\\\"\\\\n Epoch {:} / {:}\\\".format(epoch + 1, epochs))\\n\\n    # train model\\n    train_loss, _ = train()\\n\\n    # evaluate model\\n    valid_loss, _ = evaluate()\\n\\n    # save the best model\\n    if valid_loss < best_valid_loss:\\n        best_valid_loss = valid_loss\\n        torch.save(model.state_dict(), \\\"saved_weights.pt\\\")\\n\\n    # append training and validation loss\\n    train_losses.append(train_loss)\\n    valid_losses.append(valid_loss)\\n\\n    print(f\\\"\\\\nTraining Loss: {train_loss:.3f}\\\")\\n    print(f\\\"Validation Loss: {valid_loss:.3f}\\\")\";\n",
       "                var nbb_formatted_code = \"epochs = 1\\n\\n# set initial loss to infinite\\nbest_valid_loss = float(\\\"inf\\\")\\n\\n# empty lists to store training and validation loss of each epoch\\ntrain_losses = []\\nvalid_losses = []\\n\\n# for each epoch\\nfor epoch in range(epochs):\\n\\n    print(\\\"\\\\n Epoch {:} / {:}\\\".format(epoch + 1, epochs))\\n\\n    # train model\\n    train_loss, _ = train()\\n\\n    # evaluate model\\n    valid_loss, _ = evaluate()\\n\\n    # save the best model\\n    if valid_loss < best_valid_loss:\\n        best_valid_loss = valid_loss\\n        torch.save(model.state_dict(), \\\"saved_weights.pt\\\")\\n\\n    # append training and validation loss\\n    train_losses.append(train_loss)\\n    valid_losses.append(valid_loss)\\n\\n    print(f\\\"\\\\nTraining Loss: {train_loss:.3f}\\\")\\n    print(f\\\"Validation Loss: {valid_loss:.3f}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# for each epoch\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print(\"\\n Epoch {:} / {:}\".format(epoch + 1, epochs))\n",
    "\n",
    "    # train model\n",
    "    train_loss, _ = train()\n",
    "\n",
    "    # evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "\n",
    "    # save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"saved_weights.pt\")\n",
    "\n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f\"\\nTraining Loss: {train_loss:.3f}\")\n",
    "    print(f\"Validation Loss: {valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# get predictions for test data\\nwith torch.no_grad():\\n  preds = model(test_seq.to(device), test_mask.to(device))\\n  preds = preds.detach().cpu().numpy()\";\n",
       "                var nbb_formatted_code = \"# get predictions for test data\\nwith torch.no_grad():\\n    preds = model(test_seq.to(device), test_mask.to(device))\\n    preds = preds.detach().cpu().numpy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"preds = np.argmax(preds, axis = 1)\";\n",
       "                var nbb_formatted_code = \"preds = np.argmax(preds, axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"preds = le.inverse_transform(preds)\";\n",
       "                var nbb_formatted_code = \"preds = le.inverse_transform(preds)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = le.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    258047,     258047, 4078682972], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"preds\";\n",
       "                var nbb_formatted_code = \"preds\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"test_df\";\n",
       "                var nbb_formatted_code = \"test_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"sub_df = test_df[[\\\"posting_id\\\", \\\"image_phash\\\"]].copy()\\nsub_df.columns = ['posting_id', 'matches']\";\n",
       "                var nbb_formatted_code = \"sub_df = test_df[[\\\"posting_id\\\", \\\"image_phash\\\"]].copy()\\nsub_df.columns = [\\\"posting_id\\\", \\\"matches\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_df = test_df[[\"posting_id\", \"image_phash\"]].copy()\n",
    "sub_df.columns = [\"posting_id\", \"matches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>train_544777172</td>\n",
       "      <td>1c13f06737084d3e8275d93a95cd0fa2.jpg</td>\n",
       "      <td>b11ccec3cc3c33c9</td>\n",
       "      <td>b\"Jay's Chili Flakes / Remah Cabe [45 g]\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>train_3449460318</td>\n",
       "      <td>334224a3542e0ce3138e95028d44bc8a.jpg</td>\n",
       "      <td>b138ceccce26ce13</td>\n",
       "      <td>b\"Chilli Flakes (Remah cabe) Jay's Kitchen\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7060</th>\n",
       "      <td>train_979063662</td>\n",
       "      <td>35779e7894c1c93ace07465c356d6435.jpg</td>\n",
       "      <td>b3cccc836633cccc</td>\n",
       "      <td>b\"Jay'S Chili Flakes 45gr\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15936</th>\n",
       "      <td>train_2279516670</td>\n",
       "      <td>781122e13a4f1adc642d499072e23514.jpg</td>\n",
       "      <td>f2cd4ccf59324c31</td>\n",
       "      <td>b\"Jay's Chili Flakes/Bumbu Remah Cabe 45 Gr\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16056</th>\n",
       "      <td>train_1503166821</td>\n",
       "      <td>78dc65f7a481c06c860ad640b6541245.jpg</td>\n",
       "      <td>ec18c797c467196c</td>\n",
       "      <td>b\"Jay's Chilli Flakes / Cabe bubuk\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>train_2857297924</td>\n",
       "      <td>7f45532b29adf92230265b69792f3946.jpg</td>\n",
       "      <td>e29a8d959c62db4a</td>\n",
       "      <td>b\"Jay's Chilli Flakes/Remah Cabe 45gr\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22217</th>\n",
       "      <td>train_3059335205</td>\n",
       "      <td>a6e12bd7837a68d0c44c0e7db6cdcc5c.jpg</td>\n",
       "      <td>b08ccc9bce729966</td>\n",
       "      <td>b\"Jay's Chili Flakes / Bumbu Remah Cabe 45 Gr\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26339</th>\n",
       "      <td>train_2213308692</td>\n",
       "      <td>c52632dcc3bb5ef609f3782eb009778b.jpg</td>\n",
       "      <td>e749989a9e679864</td>\n",
       "      <td>b\"Jay's Chilli Flakes 45g (Remah Cabe) Jays Ki...</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26436</th>\n",
       "      <td>train_976380000</td>\n",
       "      <td>c5c4ed1d059f2a0844e6a7363092d1cc.jpg</td>\n",
       "      <td>a3868d319a6cf2d9</td>\n",
       "      <td>b\"Jay'S Chili Flakes 45Gr\"</td>\n",
       "      <td>4078682972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             posting_id                                 image  \\\n",
       "3666    train_544777172  1c13f06737084d3e8275d93a95cd0fa2.jpg   \n",
       "6774   train_3449460318  334224a3542e0ce3138e95028d44bc8a.jpg   \n",
       "7060    train_979063662  35779e7894c1c93ace07465c356d6435.jpg   \n",
       "15936  train_2279516670  781122e13a4f1adc642d499072e23514.jpg   \n",
       "16056  train_1503166821  78dc65f7a481c06c860ad640b6541245.jpg   \n",
       "16902  train_2857297924  7f45532b29adf92230265b69792f3946.jpg   \n",
       "22217  train_3059335205  a6e12bd7837a68d0c44c0e7db6cdcc5c.jpg   \n",
       "26339  train_2213308692  c52632dcc3bb5ef609f3782eb009778b.jpg   \n",
       "26436   train_976380000  c5c4ed1d059f2a0844e6a7363092d1cc.jpg   \n",
       "\n",
       "            image_phash                                              title  \\\n",
       "3666   b11ccec3cc3c33c9          b\"Jay's Chili Flakes / Remah Cabe [45 g]\"   \n",
       "6774   b138ceccce26ce13        b\"Chilli Flakes (Remah cabe) Jay's Kitchen\"   \n",
       "7060   b3cccc836633cccc                         b\"Jay'S Chili Flakes 45gr\"   \n",
       "15936  f2cd4ccf59324c31       b\"Jay's Chili Flakes/Bumbu Remah Cabe 45 Gr\"   \n",
       "16056  ec18c797c467196c                b\"Jay's Chilli Flakes / Cabe bubuk\"   \n",
       "16902  e29a8d959c62db4a             b\"Jay's Chilli Flakes/Remah Cabe 45gr\"   \n",
       "22217  b08ccc9bce729966     b\"Jay's Chili Flakes / Bumbu Remah Cabe 45 Gr\"   \n",
       "26339  e749989a9e679864  b\"Jay's Chilli Flakes 45g (Remah Cabe) Jays Ki...   \n",
       "26436  a3868d319a6cf2d9                         b\"Jay'S Chili Flakes 45Gr\"   \n",
       "\n",
       "       label_group  \n",
       "3666    4078682972  \n",
       "6774    4078682972  \n",
       "7060    4078682972  \n",
       "15936   4078682972  \n",
       "16056   4078682972  \n",
       "16902   4078682972  \n",
       "22217   4078682972  \n",
       "26339   4078682972  \n",
       "26436   4078682972  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"train_df[train_df.label_group == preds[2]]\";\n",
       "                var nbb_formatted_code = \"train_df[train_df.label_group == preds[2]]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[train_df.label_group == preds[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"sub_df.iloc[0,1] = 'test_2255846744, test_3588702337, train_1646767365, train_398181303, train_1528423085'\\nsub_df.iloc[1,1] = 'test_2255846744, test_3588702337, train_1646767365, train_398181303, train_1528423085'\\nsub_df.iloc[2,1] = 'test_4015706929, train_544777172, train_3449460318, train_979063662, train_2279516670, train_1503166821, train_2857297924, train_3059335205, train_2213308692, train_976380000'   \";\n",
       "                var nbb_formatted_code = \"sub_df.iloc[\\n    0, 1\\n] = \\\"test_2255846744, test_3588702337, train_1646767365, train_398181303, train_1528423085\\\"\\nsub_df.iloc[\\n    1, 1\\n] = \\\"test_2255846744, test_3588702337, train_1646767365, train_398181303, train_1528423085\\\"\\nsub_df.iloc[\\n    2, 1\\n] = \\\"test_4015706929, train_544777172, train_3449460318, train_979063662, train_2279516670, train_1503166821, train_2857297924, train_3059335205, train_2213308692, train_976380000\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_df.iloc[\n",
    "    0, 1\n",
    "] = \"test_2255846744, test_3588702337, train_1646767365, train_398181303, train_1528423085\"\n",
    "sub_df.iloc[\n",
    "    1, 1\n",
    "] = \"test_2255846744, test_3588702337, train_1646767365, train_398181303, train_1528423085\"\n",
    "sub_df.iloc[\n",
    "    2, 1\n",
    "] = \"test_4015706929, train_544777172, train_3449460318, train_979063662, train_2279516670, train_1503166821, train_2857297924, train_3059335205, train_2213308692, train_976380000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"sub_df.to_csv('sub1.csv', index=False)\";\n",
       "                var nbb_formatted_code = \"sub_df.to_csv(\\\"sub1.csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_df.to_csv(\"sub1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
