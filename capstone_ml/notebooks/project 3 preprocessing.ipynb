{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport warnings\\n\\nfrom autoimpute.imputations import SingleImputer\\nfrom sklearn.experimental import enable_iterative_imputer\\n\\nfrom sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\\nfrom sklearn.preprocessing import (\\n    PolynomialFeatures,\\n    OneHotEncoder,\\n    StandardScaler,\\n    MinMaxScaler,\\n    MaxAbsScaler,\\n    RobustScaler,\\n    Normalizer,\\n)\\nfrom imblearn.under_sampling import RandomUnderSampler\\nfrom sklearn.neighbors import KNeighborsClassifier\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport warnings\\n\\nfrom autoimpute.imputations import SingleImputer\\nfrom sklearn.experimental import enable_iterative_imputer\\n\\nfrom sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\\nfrom sklearn.preprocessing import (\\n    PolynomialFeatures,\\n    OneHotEncoder,\\n    StandardScaler,\\n    MinMaxScaler,\\n    MaxAbsScaler,\\n    RobustScaler,\\n    Normalizer,\\n)\\nfrom imblearn.under_sampling import RandomUnderSampler\\nfrom sklearn.neighbors import KNeighborsClassifier\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from autoimpute.imputations import SingleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.preprocessing import (\n",
    "    PolynomialFeatures,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    RobustScaler,\n",
    "    Normalizer,\n",
    ")\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"train_df = pd.read_csv(\\\"merged_train.csv\\\")\\ntest_df = pd.read_csv(\\\"merged_test.csv\\\")\";\n",
       "                var nbb_formatted_code = \"train_df = pd.read_csv(\\\"merged_train.csv\\\")\\ntest_df = pd.read_csv(\\\"merged_test.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"merged_train.csv\")\n",
    "test_df = pd.read_csv(\"merged_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# extracting lists for numerical and categorical features\\nnumerical_features = train_df.select_dtypes(np.number).columns.to_list()[2:]\\ncategorical_features = train_df.select_dtypes(object).columns.to_list()\";\n",
       "                var nbb_formatted_code = \"# extracting lists for numerical and categorical features\\nnumerical_features = train_df.select_dtypes(np.number).columns.to_list()[2:]\\ncategorical_features = train_df.select_dtypes(object).columns.to_list()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extracting lists for numerical and categorical features\n",
    "numerical_features = train_df.select_dtypes(np.number).columns.to_list()[2:]\n",
    "categorical_features = train_df.select_dtypes(object).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# imputing numerical features\\nimputer = SimpleImputer(missing_values=np.nan, strategy=\\\"constant\\\")\\n\\ntrain_df[numerical_features] = imputer.fit_transform(train_df[numerical_features])\\ntest_df[numerical_features] = imputer.transform(test_df[numerical_features])\";\n",
       "                var nbb_formatted_code = \"# imputing numerical features\\nimputer = SimpleImputer(missing_values=np.nan, strategy=\\\"constant\\\")\\n\\ntrain_df[numerical_features] = imputer.fit_transform(train_df[numerical_features])\\ntest_df[numerical_features] = imputer.transform(test_df[numerical_features])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imputing numerical features\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"constant\")\n",
    "\n",
    "train_df[numerical_features] = imputer.fit_transform(train_df[numerical_features])\n",
    "test_df[numerical_features] = imputer.transform(test_df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# imputing categorical features\\nimputer = SimpleImputer(missing_values=np.nan, strategy=\\\"constant\\\")\\n\\ntrain_df[categorical_features] = imputer.fit_transform(train_df[categorical_features])\\ntest_df[categorical_features] = imputer.transform(test_df[categorical_features])\";\n",
       "                var nbb_formatted_code = \"# imputing categorical features\\nimputer = SimpleImputer(missing_values=np.nan, strategy=\\\"constant\\\")\\n\\ntrain_df[categorical_features] = imputer.fit_transform(train_df[categorical_features])\\ntest_df[categorical_features] = imputer.transform(test_df[categorical_features])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imputing categorical features\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"constant\")\n",
    "\n",
    "train_df[categorical_features] = imputer.fit_transform(train_df[categorical_features])\n",
    "test_df[categorical_features] = imputer.transform(test_df[categorical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 Feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-4-1** Creating additional features. Here I have two problems:\n",
    "1. Majority of existing features have really low correlation coefficient. I don't really need lots of poor quality features.\n",
    "2. Dataset is huge in size. So in order to prevent MemoryLoss and crashes, I will do everything small steps.\n",
    "\n",
    "I'm planning to generate these features: 1/X, X^2, X^3, X*Y, X/Y, X+Y, X-Y. Before feature is implemented, its correlation coeficient will be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def create_reversed_feature(series: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A creates new feature A**(-1) and return it as series\\\"\\\"\\\"\\n    rev_series = np.power(series, -1)\\n    return rev_series\\n\\n\\ndef create_squared_feature(series: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A creates new feature A**2 and return it as series\\\"\\\"\\\"\\n    sq_series = np.power(series, 2)\\n    return sq_series\\n\\n\\ndef create_cubic_feature(series: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A creates new feature A**3 and return it as series\\\"\\\"\\\"\\n    cub_series = np.power(series, 3)\\n    return cub_series\\n\\n\\ndef create_product_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A*B and return it as series\\\"\\\"\\\"\\n    product_series = np.multiply(series1, series2)\\n    return product_series\\n\\n\\ndef create_division_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A/B and return it as series\\\"\\\"\\\"\\n    div_series = np.divide(series1, (series2 + 0.0000001))\\n    return div_series\\n\\n\\ndef create_addition_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A+B and return it as series\\\"\\\"\\\"\\n    add_series = np.add(series1, series2)\\n    return add_series\\n\\n\\ndef create_subtraction_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A-B and return it as series\\\"\\\"\\\"\\n    sub_series = np.subtract(series1, series2)\\n    return sub_series\";\n",
       "                var nbb_formatted_code = \"def create_reversed_feature(series: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A creates new feature A**(-1) and return it as series\\\"\\\"\\\"\\n    rev_series = np.power(series, -1)\\n    return rev_series\\n\\n\\ndef create_squared_feature(series: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A creates new feature A**2 and return it as series\\\"\\\"\\\"\\n    sq_series = np.power(series, 2)\\n    return sq_series\\n\\n\\ndef create_cubic_feature(series: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A creates new feature A**3 and return it as series\\\"\\\"\\\"\\n    cub_series = np.power(series, 3)\\n    return cub_series\\n\\n\\ndef create_product_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A*B and return it as series\\\"\\\"\\\"\\n    product_series = np.multiply(series1, series2)\\n    return product_series\\n\\n\\ndef create_division_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A/B and return it as series\\\"\\\"\\\"\\n    div_series = np.divide(series1, (series2 + 0.0000001))\\n    return div_series\\n\\n\\ndef create_addition_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A+B and return it as series\\\"\\\"\\\"\\n    add_series = np.add(series1, series2)\\n    return add_series\\n\\n\\ndef create_subtraction_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\\n    \\\"\\\"\\\"From feature A and B creates new feature A-B and return it as series\\\"\\\"\\\"\\n    sub_series = np.subtract(series1, series2)\\n    return sub_series\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_reversed_feature(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"From feature A creates new feature A**(-1) and return it as series\"\"\"\n",
    "    rev_series = np.power(series, -1)\n",
    "    return rev_series\n",
    "\n",
    "\n",
    "def create_squared_feature(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"From feature A creates new feature A**2 and return it as series\"\"\"\n",
    "    sq_series = np.power(series, 2)\n",
    "    return sq_series\n",
    "\n",
    "\n",
    "def create_cubic_feature(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"From feature A creates new feature A**3 and return it as series\"\"\"\n",
    "    cub_series = np.power(series, 3)\n",
    "    return cub_series\n",
    "\n",
    "\n",
    "def create_product_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\n",
    "    \"\"\"From feature A and B creates new feature A*B and return it as series\"\"\"\n",
    "    product_series = np.multiply(series1, series2)\n",
    "    return product_series\n",
    "\n",
    "\n",
    "def create_division_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\n",
    "    \"\"\"From feature A and B creates new feature A/B and return it as series\"\"\"\n",
    "    div_series = np.divide(series1, (series2 + 0.0000001))\n",
    "    return div_series\n",
    "\n",
    "\n",
    "def create_addition_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\n",
    "    \"\"\"From feature A and B creates new feature A+B and return it as series\"\"\"\n",
    "    add_series = np.add(series1, series2)\n",
    "    return add_series\n",
    "\n",
    "\n",
    "def create_subtraction_feature(series1: pd.Series, series2: pd.Series) -> pd.Series:\n",
    "    \"\"\"From feature A and B creates new feature A-B and return it as series\"\"\"\n",
    "    sub_series = np.subtract(series1, series2)\n",
    "    return sub_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# looping through functions which needs one series as argument:\\nfor feature in numerical_features:\\n    # reverse part\\n    train_rev_series = create_reversed_feature(train_df[feature])\\n    # those who will not have correlation coefficient of 0.05 will not be implemented\\n    if train_df[\\\"TARGET\\\"].corr(train_rev_series) >= 0.05:\\n        test_rev_series = create_reversed_feature(test_df[feature])\\n        rev_feature_name = str(feature) + \\\"_reversed\\\"\\n        test_df[rev_feature_name] = test_rev_series\\n        train_df[rev_feature_name] = train_rev_series\\n\\n    # square part\\n    train_sq_series = create_squared_feature(train_df[feature])\\n    # those who will not have correlation coefficient of 0.05 will not be implemented\\n    if train_df[\\\"TARGET\\\"].corr(train_sq_series) >= 0.05:\\n        test_sq_series = create_squared_feature(test_df[feature])\\n        sq_feature_name = str(feature) + \\\"^2\\\"\\n        test_df[sq_feature_name] = test_sq_series\\n        train_df[sq_feature_name] = train_sq_series\\n\\n    # cubic part\\n    train_cub_series = create_cubic_feature(train_df[feature])\\n    # those who will not have correlation coefficient of 0.05 will not be implemented\\n    if train_df[\\\"TARGET\\\"].corr(train_cub_series) >= 0.05:\\n        test_cub_series = create_cubic_feature(test_df[feature])\\n        cub_feature_name = str(feature) + \\\"^3\\\"\\n        test_df[cub_feature_name] = test_cub_series\\n        train_df[cub_feature_name] = train_cub_series\";\n",
       "                var nbb_formatted_code = \"# looping through functions which needs one series as argument:\\nfor feature in numerical_features:\\n    # reverse part\\n    train_rev_series = create_reversed_feature(train_df[feature])\\n    # those who will not have correlation coefficient of 0.05 will not be implemented\\n    if train_df[\\\"TARGET\\\"].corr(train_rev_series) >= 0.05:\\n        test_rev_series = create_reversed_feature(test_df[feature])\\n        rev_feature_name = str(feature) + \\\"_reversed\\\"\\n        test_df[rev_feature_name] = test_rev_series\\n        train_df[rev_feature_name] = train_rev_series\\n\\n    # square part\\n    train_sq_series = create_squared_feature(train_df[feature])\\n    # those who will not have correlation coefficient of 0.05 will not be implemented\\n    if train_df[\\\"TARGET\\\"].corr(train_sq_series) >= 0.05:\\n        test_sq_series = create_squared_feature(test_df[feature])\\n        sq_feature_name = str(feature) + \\\"^2\\\"\\n        test_df[sq_feature_name] = test_sq_series\\n        train_df[sq_feature_name] = train_sq_series\\n\\n    # cubic part\\n    train_cub_series = create_cubic_feature(train_df[feature])\\n    # those who will not have correlation coefficient of 0.05 will not be implemented\\n    if train_df[\\\"TARGET\\\"].corr(train_cub_series) >= 0.05:\\n        test_cub_series = create_cubic_feature(test_df[feature])\\n        cub_feature_name = str(feature) + \\\"^3\\\"\\n        test_df[cub_feature_name] = test_cub_series\\n        train_df[cub_feature_name] = train_cub_series\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looping through functions which needs one series as argument:\n",
    "for feature in numerical_features:\n",
    "    # reverse part\n",
    "    train_rev_series = create_reversed_feature(train_df[feature])\n",
    "    # those who will not have correlation coefficient of 0.05 will not be implemented\n",
    "    if train_df[\"TARGET\"].corr(train_rev_series) >= 0.05:\n",
    "        test_rev_series = create_reversed_feature(test_df[feature])\n",
    "        rev_feature_name = str(feature) + \"_reversed\"\n",
    "        test_df[rev_feature_name] = test_rev_series\n",
    "        train_df[rev_feature_name] = train_rev_series\n",
    "\n",
    "    # square part\n",
    "    train_sq_series = create_squared_feature(train_df[feature])\n",
    "    # those who will not have correlation coefficient of 0.05 will not be implemented\n",
    "    if train_df[\"TARGET\"].corr(train_sq_series) >= 0.05:\n",
    "        test_sq_series = create_squared_feature(test_df[feature])\n",
    "        sq_feature_name = str(feature) + \"^2\"\n",
    "        test_df[sq_feature_name] = test_sq_series\n",
    "        train_df[sq_feature_name] = train_sq_series\n",
    "\n",
    "    # cubic part\n",
    "    train_cub_series = create_cubic_feature(train_df[feature])\n",
    "    # those who will not have correlation coefficient of 0.05 will not be implemented\n",
    "    if train_df[\"TARGET\"].corr(train_cub_series) >= 0.05:\n",
    "        test_cub_series = create_cubic_feature(test_df[feature])\n",
    "        cub_feature_name = str(feature) + \"^3\"\n",
    "        test_df[cub_feature_name] = test_cub_series\n",
    "        train_df[cub_feature_name] = train_cub_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# looping through functions which needs two series as arguments:\\nfor feature1 in numerical_features:\\n    for feature2 in numerical_features:\\n        if (\\n            feature1 != feature2\\n        ):  # in order to eliminate duplicates or irrelevant manipulations\\n            # product part\\n            train_product_series = create_product_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_product_series) >= 0.1:\\n                test_product_series = create_product_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                product_feature_name = str(feature1) + \\\"*\\\" + str(feature2)\\n                test_df[product_feature_name] = test_product_series\\n                train_df[product_feature_name] = train_product_series\\n\\n            # division part\\n            train_division_series = create_division_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_division_series) >= 0.1:\\n                test_division_series = create_division_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                division_feature_name = str(feature1) + \\\"/\\\" + str(feature2)\\n                test_df[division_feature_name] = test_division_series\\n                train_df[division_feature_name] = train_division_series\\n\\n            # addition part\\n            train_addition_series = create_addition_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_addition_series) >= 0.1:\\n                test_addition_series = create_addition_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                addition_feature_name = str(feature1) + \\\"+\\\" + str(feature2)\\n                test_df[addition_feature_name] = test_addition_series\\n                train_df[addition_feature_name] = train_addition_series\\n\\n            # subtraction part\\n            train_subtraction_series = create_subtraction_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_subtraction_series) >= 0.1:\\n                test_subtraction_series = create_subtraction_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                subtraction_feature_name = str(feature1) + \\\"-\\\" + str(feature2)\\n                test_df[subtraction_feature_name] = test_subtraction_series\\n                train_df[subtraction_feature_name] = train_subtraction_series\";\n",
       "                var nbb_formatted_code = \"# looping through functions which needs two series as arguments:\\nfor feature1 in numerical_features:\\n    for feature2 in numerical_features:\\n        if (\\n            feature1 != feature2\\n        ):  # in order to eliminate duplicates or irrelevant manipulations\\n            # product part\\n            train_product_series = create_product_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_product_series) >= 0.1:\\n                test_product_series = create_product_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                product_feature_name = str(feature1) + \\\"*\\\" + str(feature2)\\n                test_df[product_feature_name] = test_product_series\\n                train_df[product_feature_name] = train_product_series\\n\\n            # division part\\n            train_division_series = create_division_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_division_series) >= 0.1:\\n                test_division_series = create_division_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                division_feature_name = str(feature1) + \\\"/\\\" + str(feature2)\\n                test_df[division_feature_name] = test_division_series\\n                train_df[division_feature_name] = train_division_series\\n\\n            # addition part\\n            train_addition_series = create_addition_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_addition_series) >= 0.1:\\n                test_addition_series = create_addition_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                addition_feature_name = str(feature1) + \\\"+\\\" + str(feature2)\\n                test_df[addition_feature_name] = test_addition_series\\n                train_df[addition_feature_name] = train_addition_series\\n\\n            # subtraction part\\n            train_subtraction_series = create_subtraction_feature(\\n                train_df[feature1], train_df[feature2]\\n            )\\n            # those who will not have correlation coefficient of 0.1 will not be implemented\\n            if train_df[\\\"TARGET\\\"].corr(train_subtraction_series) >= 0.1:\\n                test_subtraction_series = create_subtraction_feature(\\n                    test_df[feature1], test_df[feature2]\\n                )\\n                subtraction_feature_name = str(feature1) + \\\"-\\\" + str(feature2)\\n                test_df[subtraction_feature_name] = test_subtraction_series\\n                train_df[subtraction_feature_name] = train_subtraction_series\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looping through functions which needs two series as arguments:\n",
    "for feature1 in numerical_features:\n",
    "    for feature2 in numerical_features:\n",
    "        if (\n",
    "            feature1 != feature2\n",
    "        ):  # in order to eliminate duplicates or irrelevant manipulations\n",
    "            # product part\n",
    "            train_product_series = create_product_feature(\n",
    "                train_df[feature1], train_df[feature2]\n",
    "            )\n",
    "            # those who will not have correlation coefficient of 0.1 will not be implemented\n",
    "            if train_df[\"TARGET\"].corr(train_product_series) >= 0.1:\n",
    "                test_product_series = create_product_feature(\n",
    "                    test_df[feature1], test_df[feature2]\n",
    "                )\n",
    "                product_feature_name = str(feature1) + \"*\" + str(feature2)\n",
    "                test_df[product_feature_name] = test_product_series\n",
    "                train_df[product_feature_name] = train_product_series\n",
    "\n",
    "            # division part\n",
    "            train_division_series = create_division_feature(\n",
    "                train_df[feature1], train_df[feature2]\n",
    "            )\n",
    "            # those who will not have correlation coefficient of 0.1 will not be implemented\n",
    "            if train_df[\"TARGET\"].corr(train_division_series) >= 0.1:\n",
    "                test_division_series = create_division_feature(\n",
    "                    test_df[feature1], test_df[feature2]\n",
    "                )\n",
    "                division_feature_name = str(feature1) + \"/\" + str(feature2)\n",
    "                test_df[division_feature_name] = test_division_series\n",
    "                train_df[division_feature_name] = train_division_series\n",
    "\n",
    "            # addition part\n",
    "            train_addition_series = create_addition_feature(\n",
    "                train_df[feature1], train_df[feature2]\n",
    "            )\n",
    "            # those who will not have correlation coefficient of 0.1 will not be implemented\n",
    "            if train_df[\"TARGET\"].corr(train_addition_series) >= 0.1:\n",
    "                test_addition_series = create_addition_feature(\n",
    "                    test_df[feature1], test_df[feature2]\n",
    "                )\n",
    "                addition_feature_name = str(feature1) + \"+\" + str(feature2)\n",
    "                test_df[addition_feature_name] = test_addition_series\n",
    "                train_df[addition_feature_name] = train_addition_series\n",
    "\n",
    "            # subtraction part\n",
    "            train_subtraction_series = create_subtraction_feature(\n",
    "                train_df[feature1], train_df[feature2]\n",
    "            )\n",
    "            # those who will not have correlation coefficient of 0.1 will not be implemented\n",
    "            if train_df[\"TARGET\"].corr(train_subtraction_series) >= 0.1:\n",
    "                test_subtraction_series = create_subtraction_feature(\n",
    "                    test_df[feature1], test_df[feature2]\n",
    "                )\n",
    "                subtraction_feature_name = str(feature1) + \"-\" + str(feature2)\n",
    "                test_df[subtraction_feature_name] = test_subtraction_series\n",
    "                train_df[subtraction_feature_name] = train_subtraction_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-4-2** Creating relevant feature inspired by Kaggle grandmasters ([source link](https://github.com/rishabhrao1997/Home-Credit-Default-Risk/blob/main/Feature%20Engineering%20and%20Modelling.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# additional feature which will be used\\nfor data in [train_df, test_df]:\\n    data[\\\"CREDIT_ANNUITY_RATIO\\\"] = data[\\\"AMT_CREDIT_x\\\"] / (\\n        data[\\\"AMT_ANNUITY_x\\\"] + 0.00001\\n    )\\n\\n# KNN feature (which has high correlation with target)\\nknn = KNeighborsClassifier(500, n_jobs=-1)\\ntrain_data_for_neighbors = train_df[\\n    [\\\"EXT_SOURCE_1\\\", \\\"EXT_SOURCE_2\\\", \\\"EXT_SOURCE_3\\\", \\\"CREDIT_ANNUITY_RATIO\\\"]\\n]\\ntrain_target = train_df.TARGET\\ntest_data_for_neighbors = test_df[\\n    [\\\"EXT_SOURCE_1\\\", \\\"EXT_SOURCE_2\\\", \\\"EXT_SOURCE_3\\\", \\\"CREDIT_ANNUITY_RATIO\\\"]\\n]\\n\\nknn.fit(train_data_for_neighbors, train_target)\\n\\ntrain_500_neighbors = knn.kneighbors(train_data_for_neighbors)[1]\\ntest_500_neighbors = knn.kneighbors(test_data_for_neighbors)[1]\\n\\ntrain_df[\\\"TARGET_NEIGHBORS_500_MEAN\\\"] = [\\n    train_df[\\\"TARGET\\\"].iloc[ele].mean() for ele in train_500_neighbors\\n]\\ntest_df[\\\"TARGET_NEIGHBORS_500_MEAN\\\"] = [\\n    train_df[\\\"TARGET\\\"].iloc[ele].mean() for ele in test_500_neighbors\\n]\";\n",
       "                var nbb_formatted_code = \"# additional feature which will be used\\nfor data in [train_df, test_df]:\\n    data[\\\"CREDIT_ANNUITY_RATIO\\\"] = data[\\\"AMT_CREDIT_x\\\"] / (\\n        data[\\\"AMT_ANNUITY_x\\\"] + 0.00001\\n    )\\n\\n# KNN feature (which has high correlation with target)\\nknn = KNeighborsClassifier(500, n_jobs=-1)\\ntrain_data_for_neighbors = train_df[\\n    [\\\"EXT_SOURCE_1\\\", \\\"EXT_SOURCE_2\\\", \\\"EXT_SOURCE_3\\\", \\\"CREDIT_ANNUITY_RATIO\\\"]\\n]\\ntrain_target = train_df.TARGET\\ntest_data_for_neighbors = test_df[\\n    [\\\"EXT_SOURCE_1\\\", \\\"EXT_SOURCE_2\\\", \\\"EXT_SOURCE_3\\\", \\\"CREDIT_ANNUITY_RATIO\\\"]\\n]\\n\\nknn.fit(train_data_for_neighbors, train_target)\\n\\ntrain_500_neighbors = knn.kneighbors(train_data_for_neighbors)[1]\\ntest_500_neighbors = knn.kneighbors(test_data_for_neighbors)[1]\\n\\ntrain_df[\\\"TARGET_NEIGHBORS_500_MEAN\\\"] = [\\n    train_df[\\\"TARGET\\\"].iloc[ele].mean() for ele in train_500_neighbors\\n]\\ntest_df[\\\"TARGET_NEIGHBORS_500_MEAN\\\"] = [\\n    train_df[\\\"TARGET\\\"].iloc[ele].mean() for ele in test_500_neighbors\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# additional feature which will be used\n",
    "for data in [train_df, test_df]:\n",
    "    data[\"CREDIT_ANNUITY_RATIO\"] = data[\"AMT_CREDIT_x\"] / (\n",
    "        data[\"AMT_ANNUITY_x\"] + 0.00001\n",
    "    )\n",
    "\n",
    "# KNN feature (which has high correlation with target)\n",
    "knn = KNeighborsClassifier(500, n_jobs=-1)\n",
    "train_data_for_neighbors = train_df[\n",
    "    [\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\", \"CREDIT_ANNUITY_RATIO\"]\n",
    "]\n",
    "train_target = train_df.TARGET\n",
    "test_data_for_neighbors = test_df[\n",
    "    [\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\", \"CREDIT_ANNUITY_RATIO\"]\n",
    "]\n",
    "\n",
    "knn.fit(train_data_for_neighbors, train_target)\n",
    "\n",
    "train_500_neighbors = knn.kneighbors(train_data_for_neighbors)[1]\n",
    "test_500_neighbors = knn.kneighbors(test_data_for_neighbors)[1]\n",
    "\n",
    "train_df[\"TARGET_NEIGHBORS_500_MEAN\"] = [\n",
    "    train_df[\"TARGET\"].iloc[ele].mean() for ele in train_500_neighbors\n",
    "]\n",
    "test_df[\"TARGET_NEIGHBORS_500_MEAN\"] = [\n",
    "    train_df[\"TARGET\"].iloc[ele].mean() for ele in test_500_neighbors\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-4-3** Applying one hot encoding to categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# creating encoder\\nohe = OneHotEncoder(handle_unknown=\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"# creating encoder\\nohe = OneHotEncoder(handle_unknown=\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating encoder\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# creating encoded values in dataframes\\ntrain_df = train_df.join(\\n    pd.DataFrame(ohe.fit_transform(train_df[categorical_features]).toarray())\\n)\\ntest_df = test_df.join(\\n    pd.DataFrame(ohe.transform(test_df[categorical_features]).toarray())\\n)\";\n",
       "                var nbb_formatted_code = \"# creating encoded values in dataframes\\ntrain_df = train_df.join(\\n    pd.DataFrame(ohe.fit_transform(train_df[categorical_features]).toarray())\\n)\\ntest_df = test_df.join(\\n    pd.DataFrame(ohe.transform(test_df[categorical_features]).toarray())\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating encoded values in dataframes\n",
    "train_df = train_df.join(\n",
    "    pd.DataFrame(ohe.fit_transform(train_df[categorical_features]).toarray())\n",
    ")\n",
    "test_df = test_df.join(\n",
    "    pd.DataFrame(ohe.transform(test_df[categorical_features]).toarray())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# dropping categorical columns (not encoded)\\ntrain_df = train_df.drop(categorical_features, axis=1)\\ntest_df = test_df.drop(categorical_features, axis=1)\";\n",
       "                var nbb_formatted_code = \"# dropping categorical columns (not encoded)\\ntrain_df = train_df.drop(categorical_features, axis=1)\\ntest_df = test_df.drop(categorical_features, axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dropping categorical columns (not encoded)\n",
    "train_df = train_df.drop(categorical_features, axis=1)\n",
    "test_df = test_df.drop(categorical_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-4-4** Scaling features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563 562\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"print(train_df.shape[1], test_df.shape[1])\";\n",
       "                var nbb_formatted_code = \"print(train_df.shape[1], test_df.shape[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_df.shape[1], test_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# scaling will be done in small batches\\nbatches = [(100 * x) + 1 for x in range(5)]\\nbatches.append(563)\\n\\nfor counter in range(len(batches) - 1):\\n    scaler = MinMaxScaler()\\n    train_df.iloc[\\n        :, batches[counter] + 1 : batches[counter + 1] + 1\\n    ] = scaler.fit_transform(\\n        train_df.iloc[:, batches[counter] + 1 : batches[counter + 1] + 1]\\n    )\\n    test_df.iloc[:, batches[counter] : batches[counter + 1]] = scaler.transform(\\n        test_df.iloc[:, batches[counter] : batches[counter + 1]]\\n    )\";\n",
       "                var nbb_formatted_code = \"# scaling will be done in small batches\\nbatches = [(100 * x) + 1 for x in range(5)]\\nbatches.append(563)\\n\\nfor counter in range(len(batches) - 1):\\n    scaler = MinMaxScaler()\\n    train_df.iloc[\\n        :, batches[counter] + 1 : batches[counter + 1] + 1\\n    ] = scaler.fit_transform(\\n        train_df.iloc[:, batches[counter] + 1 : batches[counter + 1] + 1]\\n    )\\n    test_df.iloc[:, batches[counter] : batches[counter + 1]] = scaler.transform(\\n        test_df.iloc[:, batches[counter] : batches[counter + 1]]\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scaling will be done in small batches\n",
    "batches = [(100 * x) + 1 for x in range(5)]\n",
    "batches.append(563)\n",
    "\n",
    "for counter in range(len(batches) - 1):\n",
    "    scaler = MinMaxScaler()\n",
    "    train_df.iloc[\n",
    "        :, batches[counter] + 1 : batches[counter + 1] + 1\n",
    "    ] = scaler.fit_transform(\n",
    "        train_df.iloc[:, batches[counter] + 1 : batches[counter + 1] + 1]\n",
    "    )\n",
    "    test_df.iloc[:, batches[counter] : batches[counter + 1]] = scaler.transform(\n",
    "        test_df.iloc[:, batches[counter] : batches[counter + 1]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-4-5** Undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# reducing size of train_df using UnderSampler and balancing target distribution\\nundersample = RandomUnderSampler(sampling_strategy=\\\"majority\\\")\\n\\n# fit and apply the transform\\nX_under, y_under = undersample.fit_resample(train_df.iloc[:, 2:], train_df.iloc[:, 1])\\n\\n# saving to pd DataFrame\\nunder_train_df = pd.DataFrame()\\nunder_train_df[\\\"TARGET\\\"] = y_under\\nunder_train_df[[str(x) for x in range(1, 562)]] = X_under\";\n",
       "                var nbb_formatted_code = \"# reducing size of train_df using UnderSampler and balancing target distribution\\nundersample = RandomUnderSampler(sampling_strategy=\\\"majority\\\")\\n\\n# fit and apply the transform\\nX_under, y_under = undersample.fit_resample(train_df.iloc[:, 2:], train_df.iloc[:, 1])\\n\\n# saving to pd DataFrame\\nunder_train_df = pd.DataFrame()\\nunder_train_df[\\\"TARGET\\\"] = y_under\\nunder_train_df[[str(x) for x in range(1, 562)]] = X_under\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reducing size of train_df using UnderSampler and balancing target distribution\n",
    "undersample = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "\n",
    "# fit and apply the transform\n",
    "X_under, y_under = undersample.fit_resample(train_df.iloc[:, 2:], train_df.iloc[:, 1])\n",
    "\n",
    "# saving to pd DataFrame\n",
    "under_train_df = pd.DataFrame()\n",
    "under_train_df[\"TARGET\"] = y_under\n",
    "under_train_df[[str(x) for x in range(1, 562)]] = X_under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-4-6** Saving train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train1.csv\", index=False)\n",
    "test_df.to_csv(\"test1.csv\", index=False)\n",
    "under_train_df.to_csv(\"train_under1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
