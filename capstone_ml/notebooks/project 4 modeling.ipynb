{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport warnings\\n\\nfrom sklearn.feature_selection import SelectFromModel\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import (\\n    KFold,\\n    cross_val_score,\\n    train_test_split,\\n    GridSearchCV,\\n    StratifiedKFold,\\n)\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import (\\n    confusion_matrix,\\n    accuracy_score,\\n    precision_score,\\n    recall_score,\\n    f1_score,\\n    roc_auc_score,\\n)\\nfrom lightgbm import LGBMClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.dummy import DummyClassifier\\n\\nfrom bayes_opt import BayesianOptimization\\nfrom skopt import BayesSearchCV\\nimport lightgbm as lgb\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%load_ext nb_black\\n\\nRANDOM_STATE = 7\\n\\nplt.style.use(\\\"ggplot\\\")\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport warnings\\n\\nfrom sklearn.feature_selection import SelectFromModel\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import (\\n    KFold,\\n    cross_val_score,\\n    train_test_split,\\n    GridSearchCV,\\n    StratifiedKFold,\\n)\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import (\\n    confusion_matrix,\\n    accuracy_score,\\n    precision_score,\\n    recall_score,\\n    f1_score,\\n    roc_auc_score,\\n)\\nfrom lightgbm import LGBMClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.dummy import DummyClassifier\\n\\nfrom bayes_opt import BayesianOptimization\\nfrom skopt import BayesSearchCV\\nimport lightgbm as lgb\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n%load_ext nb_black\\n\\nRANDOM_STATE = 7\\n\\nplt.style.use(\\\"ggplot\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt import BayesSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext nb_black\n",
    "\n",
    "RANDOM_STATE = 7\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"train_df = pd.read_csv(\\\"train.csv\\\")\\ntest_df = pd.read_csv(\\\"test.csv\\\")\\nunder_train_df = pd.read_csv(\\\"train_under.csv\\\")\";\n",
       "                var nbb_formatted_code = \"train_df = pd.read_csv(\\\"train.csv\\\")\\ntest_df = pd.read_csv(\\\"test.csv\\\")\\nunder_train_df = pd.read_csv(\\\"train_under.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "under_train_df = pd.read_csv(\"train_under.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5 Modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# extracting X and y from dataframes (unbalanced dataset)\\nX = train_df.iloc[:, 2:].values\\ny = train_df.TARGET.values\\n\\n# extracting X and y from dataframes (balanced dataset)\\nX_under = under_train_df.iloc[:, 1:].values\\ny_under = under_train_df.TARGET.values\\n\\n# extracting X from test dataframe\\nX_val = test_df.iloc[:, 1:].values\";\n",
       "                var nbb_formatted_code = \"# extracting X and y from dataframes (unbalanced dataset)\\nX = train_df.iloc[:, 2:].values\\ny = train_df.TARGET.values\\n\\n# extracting X and y from dataframes (balanced dataset)\\nX_under = under_train_df.iloc[:, 1:].values\\ny_under = under_train_df.TARGET.values\\n\\n# extracting X from test dataframe\\nX_val = test_df.iloc[:, 1:].values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extracting X and y from dataframes (unbalanced dataset)\n",
    "X = train_df.iloc[:, 2:].values\n",
    "y = train_df.TARGET.values\n",
    "\n",
    "# extracting X and y from dataframes (balanced dataset)\n",
    "X_under = under_train_df.iloc[:, 1:].values\n",
    "y_under = under_train_df.TARGET.values\n",
    "\n",
    "# extracting X from test dataframe\n",
    "X_val = test_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# splitting X and y to train and test\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.25, random_state=RANDOM_STATE\\n)\\n\\nX_train_under, X_test_under, y_train_under, y_test_under = train_test_split(\\n    X_under, y_under, test_size=0.2, random_state=RANDOM_STATE\\n)\";\n",
       "                var nbb_formatted_code = \"# splitting X and y to train and test\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.25, random_state=RANDOM_STATE\\n)\\n\\nX_train_under, X_test_under, y_train_under, y_test_under = train_test_split(\\n    X_under, y_under, test_size=0.2, random_state=RANDOM_STATE\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# splitting X and y to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(\n",
    "    X_under, y_under, test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-1** Building baseline model - Dummy Classifier and finding its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"dummy_clf = DummyClassifier(strategy=\\\"most_frequent\\\")\\ndummy_clf.fit(X_train, y_train)\\n\\ny_pred = dummy_clf.predict(X_test)\";\n",
       "                var nbb_formatted_code = \"dummy_clf = DummyClassifier(strategy=\\\"most_frequent\\\")\\ndummy_clf.fit(X_train, y_train)\\n\\ny_pred = dummy_clf.predict(X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dummy_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def clf_performance_metrics(y_test: np.array, y_pred: np.array) -> tuple:\\n    \\\"\\\"\\\"By giving y_test and y_pred, returns classifiers accuracy, precision, recall, f1\\\"\\\"\\\"\\n    accuracy = accuracy_score(y_test, y_pred)\\n    precision = precision_score(y_test, y_pred)\\n    recall = recall_score(y_test, y_pred)\\n    f1 = f1_score(y_test, y_pred)\\n    return accuracy, precision, recall, f1\";\n",
       "                var nbb_formatted_code = \"def clf_performance_metrics(y_test: np.array, y_pred: np.array) -> tuple:\\n    \\\"\\\"\\\"By giving y_test and y_pred, returns classifiers accuracy, precision, recall, f1\\\"\\\"\\\"\\n    accuracy = accuracy_score(y_test, y_pred)\\n    precision = precision_score(y_test, y_pred)\\n    recall = recall_score(y_test, y_pred)\\n    f1 = f1_score(y_test, y_pred)\\n    return accuracy, precision, recall, f1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clf_performance_metrics(y_test: np.array, y_pred: np.array) -> tuple:\n",
    "    \"\"\"By giving y_test and y_pred, returns classifiers accuracy, precision, recall, f1\"\"\"\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9192486797263196, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"perf_metrics = clf_performance_metrics(y_test, y_pred)\\nperf_metrics\";\n",
       "                var nbb_formatted_code = \"perf_metrics = clf_performance_metrics(y_test, y_pred)\\nperf_metrics\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf_metrics = clf_performance_metrics(y_test, y_pred)\n",
    "perf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"y_proba = dummy_clf.predict_proba(X_val)\";\n",
       "                var nbb_formatted_code = \"y_proba = dummy_clf.predict_proba(X_val)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_proba = dummy_clf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def to_csv(y_pred_proba: list, csv_name: str) -> None:\\n    \\\"\\\"\\\"Saves predictions to csv file with specified name\\\"\\\"\\\"\\n    df = pd.DataFrame()\\n    df[\\\"SK_ID_CURR\\\"] = test_df.SK_ID_CURR\\n    df[\\\"TARGET\\\"] = y_pred_proba\\n    df.to_csv(csv_name + \\\".csv\\\", index=False)\";\n",
       "                var nbb_formatted_code = \"def to_csv(y_pred_proba: list, csv_name: str) -> None:\\n    \\\"\\\"\\\"Saves predictions to csv file with specified name\\\"\\\"\\\"\\n    df = pd.DataFrame()\\n    df[\\\"SK_ID_CURR\\\"] = test_df.SK_ID_CURR\\n    df[\\\"TARGET\\\"] = y_pred_proba\\n    df.to_csv(csv_name + \\\".csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_csv(y_pred_proba: list, csv_name: str) -> None:\n",
    "    \"\"\"Saves predictions to csv file with specified name\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df[\"SK_ID_CURR\"] = test_df.SK_ID_CURR\n",
    "    df[\"TARGET\"] = y_pred_proba\n",
    "    df.to_csv(csv_name + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"to_csv(y_proba[:, 1], \\\"dummy\\\")\";\n",
       "                var nbb_formatted_code = \"to_csv(y_proba[:, 1], \\\"dummy\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_csv(y_proba[:, 1], \"dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-2** Creating dataframe to keep tracking information about model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"models_df = pd.DataFrame(\\n    columns=[\\n        \\\"model\\\",\\n        \\\"balanced_dataset\\\",\\n        \\\"features\\\",\\n        \\\"hyperparameters\\\",\\n        \\\"accuracy\\\",\\n        \\\"precision\\\",\\n        \\\"recall\\\",\\n        \\\"f1\\\",\\n        \\\"Kaggle\\\",\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"models_df = pd.DataFrame(\\n    columns=[\\n        \\\"model\\\",\\n        \\\"balanced_dataset\\\",\\n        \\\"features\\\",\\n        \\\"hyperparameters\\\",\\n        \\\"accuracy\\\",\\n        \\\"precision\\\",\\n        \\\"recall\\\",\\n        \\\"f1\\\",\\n        \\\"Kaggle\\\",\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"model\",\n",
    "        \"balanced_dataset\",\n",
    "        \"features\",\n",
    "        \"hyperparameters\",\n",
    "        \"accuracy\",\n",
    "        \"precision\",\n",
    "        \"recall\",\n",
    "        \"f1\",\n",
    "        \"Kaggle\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"new_row = {\\n    \\\"model\\\": \\\"DummyClassifier\\\",\\n    \\\"balanced_dataset\\\": False,\\n    \\\"features\\\": \\\"All\\\",\\n    \\\"hyperparameters\\\": None,\\n    \\\"accuracy\\\": perf_metrics[0],\\n    \\\"precision\\\": perf_metrics[1],\\n    \\\"recall\\\": perf_metrics[2],\\n    \\\"f1\\\": perf_metrics[3],\\n    \\\"Kaggle\\\": 0.5,\\n}\\nmodels_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_formatted_code = \"new_row = {\\n    \\\"model\\\": \\\"DummyClassifier\\\",\\n    \\\"balanced_dataset\\\": False,\\n    \\\"features\\\": \\\"All\\\",\\n    \\\"hyperparameters\\\": None,\\n    \\\"accuracy\\\": perf_metrics[0],\\n    \\\"precision\\\": perf_metrics[1],\\n    \\\"recall\\\": perf_metrics[2],\\n    \\\"f1\\\": perf_metrics[3],\\n    \\\"Kaggle\\\": 0.5,\\n}\\nmodels_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_row = {\n",
    "    \"model\": \"DummyClassifier\",\n",
    "    \"balanced_dataset\": False,\n",
    "    \"features\": \"All\",\n",
    "    \"hyperparameters\": None,\n",
    "    \"accuracy\": perf_metrics[0],\n",
    "    \"precision\": perf_metrics[1],\n",
    "    \"recall\": perf_metrics[2],\n",
    "    \"f1\": perf_metrics[3],\n",
    "    \"Kaggle\": 0.5,\n",
    "}\n",
    "models_df = models_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-3** Building basic models without selector and hyperparameters tuning on unbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# 5 models will be used: LogisticReg, RFC, KNNC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    KNeighborsClassifier(),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\nmodel_names = [\\\"logreg\\\", \\\"rfc\\\", \\\"knn\\\", \\\"lgbm\\\"]\\n\\nfor counter in range(len(models)):\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train, y_train)\\n    y_pred = model.predict(X_test)\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test, y_pred)\\n    y_proba = model.predict_proba(X_val)\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": False,\\n        \\\"features\\\": \\\"All\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_formatted_code = \"# 5 models will be used: LogisticReg, RFC, KNNC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    KNeighborsClassifier(),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\nmodel_names = [\\\"logreg\\\", \\\"rfc\\\", \\\"knn\\\", \\\"lgbm\\\"]\\n\\nfor counter in range(len(models)):\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train, y_train)\\n    y_pred = model.predict(X_test)\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test, y_pred)\\n    y_proba = model.predict_proba(X_val)\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": False,\\n        \\\"features\\\": \\\"All\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 models will be used: LogisticReg, RFC, KNNC, LightGBM\n",
    "models = [\n",
    "    LogisticRegression(random_state=RANDOM_STATE),\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    KNeighborsClassifier(),\n",
    "    LGBMClassifier(random_state=RANDOM_STATE),\n",
    "]\n",
    "model_names = [\"logreg\", \"rfc\", \"knn\", \"lgbm\"]\n",
    "\n",
    "for counter in range(len(models)):\n",
    "    # training model\n",
    "    model = models[counter]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # measuring performance\n",
    "    perf_metrics = clf_performance_metrics(y_test, y_pred)\n",
    "    y_proba = model.predict_proba(X_val)\n",
    "\n",
    "    # saving to csv\n",
    "    to_csv(y_proba[:, 1], \"kaggle_\" + model_names[counter] + str(1))\n",
    "\n",
    "    # exporting performance data to models_df\n",
    "    new_row = {\n",
    "        \"model\": model_names[counter],\n",
    "        \"balanced_dataset\": False,\n",
    "        \"features\": \"All\",\n",
    "        \"hyperparameters\": None,\n",
    "        \"accuracy\": perf_metrics[0],\n",
    "        \"precision\": perf_metrics[1],\n",
    "        \"recall\": perf_metrics[2],\n",
    "        \"f1\": perf_metrics[3],\n",
    "        \"Kaggle\": None,\n",
    "    }\n",
    "    models_df = models_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[1:5, -1] = [0.7539, 0.7174, 0.5871, 0.7731]\";\n",
       "                var nbb_formatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[1:5, -1] = [0.7539, 0.7174, 0.5871, 0.7731]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updating Kaggle scores\n",
    "models_df.iloc[1:5, -1] = [0.7539, 0.7174, 0.5871, 0.7731]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>False</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.919249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logreg</td>\n",
       "      <td>False</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.919522</td>\n",
       "      <td>0.520154</td>\n",
       "      <td>0.043653</td>\n",
       "      <td>0.080547</td>\n",
       "      <td>0.7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rfc</td>\n",
       "      <td>False</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.919418</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.7174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>False</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.911535</td>\n",
       "      <td>0.218424</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>0.063352</td>\n",
       "      <td>0.5871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>False</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.920003</td>\n",
       "      <td>0.590625</td>\n",
       "      <td>0.030445</td>\n",
       "      <td>0.057904</td>\n",
       "      <td>0.7731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model balanced_dataset features hyperparameters  accuracy  \\\n",
       "0  DummyClassifier            False      All            None  0.919249   \n",
       "1           logreg            False      All            None  0.919522   \n",
       "2              rfc            False      All            None  0.919418   \n",
       "3              knn            False      All            None  0.911535   \n",
       "4             lgbm            False      All            None  0.920003   \n",
       "\n",
       "   precision    recall        f1  Kaggle  \n",
       "0   0.000000  0.000000  0.000000     0.5  \n",
       "1   0.520154  0.043653  0.080547  0.7539  \n",
       "2   0.551181  0.011276  0.022099  0.7174  \n",
       "3   0.218424  0.037049  0.063352  0.5871  \n",
       "4   0.590625  0.030445  0.057904  0.7731  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"models_df[models_df.balanced_dataset == False]\";\n",
       "                var nbb_formatted_code = \"models_df[models_df.balanced_dataset == False]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_df[models_df.balanced_dataset == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBM won the fight so far, however score needs to be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-4** Building basic models without selector and hyperparameters tuning on balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# 4 models will be used: LogisticReg, RFC, KNNC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    KNeighborsClassifier(),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\n\\nfor counter in range(len(models)):\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train_under, y_train_under)\\n    y_pred = model.predict(X_test_under)\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test_under, y_pred)\\n    y_proba = model.predict_proba(X_val)\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_bal_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": True,\\n        \\\"features\\\": \\\"All\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_formatted_code = \"# 4 models will be used: LogisticReg, RFC, KNNC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    KNeighborsClassifier(),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\n\\nfor counter in range(len(models)):\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train_under, y_train_under)\\n    y_pred = model.predict(X_test_under)\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test_under, y_pred)\\n    y_proba = model.predict_proba(X_val)\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_bal_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": True,\\n        \\\"features\\\": \\\"All\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4 models will be used: LogisticReg, RFC, KNNC, LightGBM\n",
    "models = [\n",
    "    LogisticRegression(random_state=RANDOM_STATE),\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    KNeighborsClassifier(),\n",
    "    LGBMClassifier(random_state=RANDOM_STATE),\n",
    "]\n",
    "\n",
    "for counter in range(len(models)):\n",
    "    # training model\n",
    "    model = models[counter]\n",
    "    model.fit(X_train_under, y_train_under)\n",
    "    y_pred = model.predict(X_test_under)\n",
    "\n",
    "    # measuring performance\n",
    "    perf_metrics = clf_performance_metrics(y_test_under, y_pred)\n",
    "    y_proba = model.predict_proba(X_val)\n",
    "\n",
    "    # saving to csv\n",
    "    to_csv(y_proba[:, 1], \"kaggle_bal_\" + model_names[counter] + str(1))\n",
    "\n",
    "    # exporting performance data to models_df\n",
    "    new_row = {\n",
    "        \"model\": model_names[counter],\n",
    "        \"balanced_dataset\": True,\n",
    "        \"features\": \"All\",\n",
    "        \"hyperparameters\": None,\n",
    "        \"accuracy\": perf_metrics[0],\n",
    "        \"precision\": perf_metrics[1],\n",
    "        \"recall\": perf_metrics[2],\n",
    "        \"f1\": perf_metrics[3],\n",
    "        \"Kaggle\": None,\n",
    "    }\n",
    "    models_df = models_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[5:, -1] = [0.7591, 0.7358, 0.6452, 0.7707]\";\n",
       "                var nbb_formatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[5:, -1] = [0.7591, 0.7358, 0.6452, 0.7707]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updating Kaggle scores\n",
    "models_df.iloc[5:, -1] = [0.7591, 0.7358, 0.6452, 0.7707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logreg</td>\n",
       "      <td>True</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.701309</td>\n",
       "      <td>0.708428</td>\n",
       "      <td>0.689116</td>\n",
       "      <td>0.698638</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfc</td>\n",
       "      <td>True</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.682175</td>\n",
       "      <td>0.686167</td>\n",
       "      <td>0.677090</td>\n",
       "      <td>0.681598</td>\n",
       "      <td>0.7358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.611078</td>\n",
       "      <td>0.607109</td>\n",
       "      <td>0.640208</td>\n",
       "      <td>0.623220</td>\n",
       "      <td>0.6452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>True</td>\n",
       "      <td>All</td>\n",
       "      <td>None</td>\n",
       "      <td>0.713293</td>\n",
       "      <td>0.715320</td>\n",
       "      <td>0.713169</td>\n",
       "      <td>0.714243</td>\n",
       "      <td>0.7707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model balanced_dataset features hyperparameters  accuracy  precision  \\\n",
       "5  logreg             True      All            None  0.701309   0.708428   \n",
       "6     rfc             True      All            None  0.682175   0.686167   \n",
       "7     knn             True      All            None  0.611078   0.607109   \n",
       "8    lgbm             True      All            None  0.713293   0.715320   \n",
       "\n",
       "     recall        f1  Kaggle  \n",
       "5  0.689116  0.698638  0.7591  \n",
       "6  0.677090  0.681598  0.7358  \n",
       "7  0.640208  0.623220  0.6452  \n",
       "8  0.713169  0.714243  0.7707  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"models_df[models_df.balanced_dataset == True]\";\n",
       "                var nbb_formatted_code = \"models_df[models_df.balanced_dataset == True]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_df[models_df.balanced_dataset == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle score improved: RFC, KNN, Logistic Regression\n",
    "\n",
    "Kaggle score dropped: LightGBM\n",
    "\n",
    "Still need to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-5** Models with features selectors on unbalanced dataset. KNeighborsClassifier does not work with the selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# 3 models will be used: LogisticReg, RFC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\nmodel_names = [\\\"logreg\\\", \\\"rfc\\\", \\\"lgbm\\\"]\\n\\nfor counter in range(len(models)):\\n    # training selector\\n    try:\\n        selector = SelectFromModel(models[counter])\\n        selector.fit(X_train, y_train)\\n    except:\\n        selector = SelectFromModel(LogisticRegression())\\n        selector.fit(X_train, y_train)\\n\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train[:, selector.get_support()], y_train)\\n    y_pred = model.predict(X_test[:, selector.get_support()])\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test, y_pred)\\n    y_proba = model.predict_proba(X_val[:, selector.get_support()])\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_sel_un_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": False,\\n        \\\"features\\\": \\\"Selected\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_formatted_code = \"# 3 models will be used: LogisticReg, RFC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\nmodel_names = [\\\"logreg\\\", \\\"rfc\\\", \\\"lgbm\\\"]\\n\\nfor counter in range(len(models)):\\n    # training selector\\n    try:\\n        selector = SelectFromModel(models[counter])\\n        selector.fit(X_train, y_train)\\n    except:\\n        selector = SelectFromModel(LogisticRegression())\\n        selector.fit(X_train, y_train)\\n\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train[:, selector.get_support()], y_train)\\n    y_pred = model.predict(X_test[:, selector.get_support()])\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test, y_pred)\\n    y_proba = model.predict_proba(X_val[:, selector.get_support()])\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_sel_un_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": False,\\n        \\\"features\\\": \\\"Selected\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3 models will be used: LogisticReg, RFC, LightGBM\n",
    "models = [\n",
    "    LogisticRegression(random_state=RANDOM_STATE),\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    LGBMClassifier(random_state=RANDOM_STATE),\n",
    "]\n",
    "model_names = [\"logreg\", \"rfc\", \"lgbm\"]\n",
    "\n",
    "for counter in range(len(models)):\n",
    "    # training selector\n",
    "    try:\n",
    "        selector = SelectFromModel(models[counter])\n",
    "        selector.fit(X_train, y_train)\n",
    "    except:\n",
    "        selector = SelectFromModel(LogisticRegression())\n",
    "        selector.fit(X_train, y_train)\n",
    "\n",
    "    # training model\n",
    "    model = models[counter]\n",
    "    model.fit(X_train[:, selector.get_support()], y_train)\n",
    "    y_pred = model.predict(X_test[:, selector.get_support()])\n",
    "\n",
    "    # measuring performance\n",
    "    perf_metrics = clf_performance_metrics(y_test, y_pred)\n",
    "    y_proba = model.predict_proba(X_val[:, selector.get_support()])\n",
    "\n",
    "    # saving to csv\n",
    "    to_csv(y_proba[:, 1], \"kaggle_sel_un_\" + model_names[counter] + str(1))\n",
    "\n",
    "    # exporting performance data to models_df\n",
    "    new_row = {\n",
    "        \"model\": model_names[counter],\n",
    "        \"balanced_dataset\": False,\n",
    "        \"features\": \"Selected\",\n",
    "        \"hyperparameters\": None,\n",
    "        \"accuracy\": perf_metrics[0],\n",
    "        \"precision\": perf_metrics[1],\n",
    "        \"recall\": perf_metrics[2],\n",
    "        \"f1\": perf_metrics[3],\n",
    "        \"Kaggle\": None,\n",
    "    }\n",
    "    models_df = models_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[9:, -1] = [0.7554, 0.7124, 0.7733]\";\n",
       "                var nbb_formatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[9:, -1] = [0.7554, 0.7124, 0.7733]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updating Kaggle scores\n",
    "models_df.iloc[9:, -1] = [0.7554, 0.7124, 0.7733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logreg</td>\n",
       "      <td>False</td>\n",
       "      <td>Selected</td>\n",
       "      <td>None</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>0.528067</td>\n",
       "      <td>0.040915</td>\n",
       "      <td>0.075946</td>\n",
       "      <td>0.7554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rfc</td>\n",
       "      <td>False</td>\n",
       "      <td>Selected</td>\n",
       "      <td>None</td>\n",
       "      <td>0.919444</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.022415</td>\n",
       "      <td>0.7124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>False</td>\n",
       "      <td>Selected</td>\n",
       "      <td>None</td>\n",
       "      <td>0.919860</td>\n",
       "      <td>0.569733</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.058671</td>\n",
       "      <td>0.7733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model balanced_dataset  features hyperparameters  accuracy  precision  \\\n",
       "9   logreg            False  Selected            None  0.919600   0.528067   \n",
       "10     rfc            False  Selected            None  0.919444   0.559055   \n",
       "11    lgbm            False  Selected            None  0.919860   0.569733   \n",
       "\n",
       "      recall        f1  Kaggle  \n",
       "9   0.040915  0.075946  0.7554  \n",
       "10  0.011437  0.022415  0.7124  \n",
       "11  0.030928  0.058671  0.7733  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"models_df[models_df.features == \\\"Selected\\\"]\";\n",
       "                var nbb_formatted_code = \"models_df[models_df.features == \\\"Selected\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_df[models_df.features == \"Selected\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-6** Models with features selectors on balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# 3 models will be used: LogisticReg, RFC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\nmodel_names = [\\\"logreg\\\", \\\"rfc\\\", \\\"lgbm\\\"]\\n\\nfor counter in range(len(models)):\\n    # training selector\\n    try:\\n        selector = SelectFromModel(models[counter])\\n        selector.fit(X_train_under, y_train_under)\\n    except:\\n        selector = SelectFromModel(LogisticRegression())\\n        selector.fit(X_train_under, y_train_under)\\n\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train_under[:, selector.get_support()], y_train_under)\\n    y_pred = model.predict(X_test_under[:, selector.get_support()])\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test_under, y_pred)\\n    y_proba = model.predict_proba(X_val[:, selector.get_support()])\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_sel_bal_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": True,\\n        \\\"features\\\": \\\"Selected\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_formatted_code = \"# 3 models will be used: LogisticReg, RFC, LightGBM\\nmodels = [\\n    LogisticRegression(random_state=RANDOM_STATE),\\n    RandomForestClassifier(random_state=RANDOM_STATE),\\n    LGBMClassifier(random_state=RANDOM_STATE),\\n]\\nmodel_names = [\\\"logreg\\\", \\\"rfc\\\", \\\"lgbm\\\"]\\n\\nfor counter in range(len(models)):\\n    # training selector\\n    try:\\n        selector = SelectFromModel(models[counter])\\n        selector.fit(X_train_under, y_train_under)\\n    except:\\n        selector = SelectFromModel(LogisticRegression())\\n        selector.fit(X_train_under, y_train_under)\\n\\n    # training model\\n    model = models[counter]\\n    model.fit(X_train_under[:, selector.get_support()], y_train_under)\\n    y_pred = model.predict(X_test_under[:, selector.get_support()])\\n\\n    # measuring performance\\n    perf_metrics = clf_performance_metrics(y_test_under, y_pred)\\n    y_proba = model.predict_proba(X_val[:, selector.get_support()])\\n\\n    # saving to csv\\n    to_csv(y_proba[:, 1], \\\"kaggle_sel_bal_\\\" + model_names[counter] + str(1))\\n\\n    # exporting performance data to models_df\\n    new_row = {\\n        \\\"model\\\": model_names[counter],\\n        \\\"balanced_dataset\\\": True,\\n        \\\"features\\\": \\\"Selected\\\",\\n        \\\"hyperparameters\\\": None,\\n        \\\"accuracy\\\": perf_metrics[0],\\n        \\\"precision\\\": perf_metrics[1],\\n        \\\"recall\\\": perf_metrics[2],\\n        \\\"f1\\\": perf_metrics[3],\\n        \\\"Kaggle\\\": None,\\n    }\\n    models_df = models_df.append(new_row, ignore_index=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3 models will be used: LogisticReg, RFC, LightGBM\n",
    "models = [\n",
    "    LogisticRegression(random_state=RANDOM_STATE),\n",
    "    RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    LGBMClassifier(random_state=RANDOM_STATE),\n",
    "]\n",
    "model_names = [\"logreg\", \"rfc\", \"lgbm\"]\n",
    "\n",
    "for counter in range(len(models)):\n",
    "    # training selector\n",
    "    try:\n",
    "        selector = SelectFromModel(models[counter])\n",
    "        selector.fit(X_train_under, y_train_under)\n",
    "    except:\n",
    "        selector = SelectFromModel(LogisticRegression())\n",
    "        selector.fit(X_train_under, y_train_under)\n",
    "\n",
    "    # training model\n",
    "    model = models[counter]\n",
    "    model.fit(X_train_under[:, selector.get_support()], y_train_under)\n",
    "    y_pred = model.predict(X_test_under[:, selector.get_support()])\n",
    "\n",
    "    # measuring performance\n",
    "    perf_metrics = clf_performance_metrics(y_test_under, y_pred)\n",
    "    y_proba = model.predict_proba(X_val[:, selector.get_support()])\n",
    "\n",
    "    # saving to csv\n",
    "    to_csv(y_proba[:, 1], \"kaggle_sel_bal_\" + model_names[counter] + str(1))\n",
    "\n",
    "    # exporting performance data to models_df\n",
    "    new_row = {\n",
    "        \"model\": model_names[counter],\n",
    "        \"balanced_dataset\": True,\n",
    "        \"features\": \"Selected\",\n",
    "        \"hyperparameters\": None,\n",
    "        \"accuracy\": perf_metrics[0],\n",
    "        \"precision\": perf_metrics[1],\n",
    "        \"recall\": perf_metrics[2],\n",
    "        \"f1\": perf_metrics[3],\n",
    "        \"Kaggle\": None,\n",
    "    }\n",
    "    models_df = models_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[12:15, -1] = [0.7574, 0.7407, 0.7706]\";\n",
       "                var nbb_formatted_code = \"# updating Kaggle scores\\nmodels_df.iloc[12:15, -1] = [0.7574, 0.7407, 0.7706]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# updating Kaggle scores\n",
    "models_df.iloc[12:15, -1] = [0.7574, 0.7407, 0.7706]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>balanced_dataset</th>\n",
       "      <th>features</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Kaggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>logreg</td>\n",
       "      <td>True</td>\n",
       "      <td>Selected</td>\n",
       "      <td>None</td>\n",
       "      <td>0.699799</td>\n",
       "      <td>0.707781</td>\n",
       "      <td>0.685508</td>\n",
       "      <td>0.696467</td>\n",
       "      <td>0.7574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rfc</td>\n",
       "      <td>True</td>\n",
       "      <td>Selected</td>\n",
       "      <td>None</td>\n",
       "      <td>0.692447</td>\n",
       "      <td>0.700103</td>\n",
       "      <td>0.678493</td>\n",
       "      <td>0.689129</td>\n",
       "      <td>0.7407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>True</td>\n",
       "      <td>Selected</td>\n",
       "      <td>None</td>\n",
       "      <td>0.709164</td>\n",
       "      <td>0.711496</td>\n",
       "      <td>0.708358</td>\n",
       "      <td>0.709924</td>\n",
       "      <td>0.7706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model balanced_dataset  features hyperparameters  accuracy  precision  \\\n",
       "12  logreg             True  Selected            None  0.699799   0.707781   \n",
       "13     rfc             True  Selected            None  0.692447   0.700103   \n",
       "14    lgbm             True  Selected            None  0.709164   0.711496   \n",
       "\n",
       "      recall        f1  Kaggle  \n",
       "12  0.685508  0.696467  0.7574  \n",
       "13  0.678493  0.689129  0.7407  \n",
       "14  0.708358  0.709924  0.7706  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"models_df[(models_df.features == \\\"Selected\\\") & (models_df.balanced_dataset == True)]\";\n",
       "                var nbb_formatted_code = \"models_df[(models_df.features == \\\"Selected\\\") & (models_df.balanced_dataset == True)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_df[(models_df.features == \"Selected\") & (models_df.balanced_dataset == True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBM worked best without selector and with imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-7** LGBM hyperparameters tuning using Bayesian Optimization (GridSearch does not work because model is not from ScikitLearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"def lgbm_evaluation(\\n    num_leaves,\\n    max_depth,\\n    min_split_gain,\\n    min_child_weight,\\n    min_child_samples,\\n    reg_alpha,\\n    reg_lambda,\\n):\\n    \\\"\\\"\\\"\\n    Objective function for Bayesian Optimization of LightGBM's Hyperparamters. Takes the hyperparameters as input, and\\n    returns the Cross-Validation AUC as output.\\n\\n    Inputs: Hyperparamters to be tuned.\\n        num_leaves, max_depth, min_split_gain, min_child_weight,\\n        min_child_samples, subsample, reg_alpha, reg_lambda\\n\\n    Returns:\\n        CV ROC-AUC Score\\n    \\\"\\\"\\\"\\n\\n    params = {\\n        \\\"objective\\\": \\\"binary\\\",\\n        \\\"boosting_type\\\": \\\"gbdt\\\",\\n        \\\"learning_rate\\\": 0.005,\\n        \\\"n_estimators\\\": 10000,\\n        \\\"n_jobs\\\": -1,\\n        \\\"num_leaves\\\": int(round(num_leaves)),\\n        \\\"max_depth\\\": int(round(max_depth)),\\n        \\\"min_split_gain\\\": min_split_gain,\\n        \\\"min_child_weight\\\": min_child_weight,\\n        \\\"min_child_samples\\\": int(round(min_child_samples)),\\n        \\\"reg_alpha\\\": reg_alpha,\\n        \\\"reg_lambda\\\": reg_lambda,\\n        \\\"verbosity\\\": -1,\\n        \\\"seed\\\": RANDOM_STATE,\\n    }\\n    stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\\n\\n    cv_preds = np.zeros(X_train.shape[0])\\n    for train_indices, cv_indices in stratified_cv.split(X_train, y_train):\\n\\n        x_tr = X_train.iloc[train_indices]\\n        y_tr = y_train.iloc[train_indices]\\n        x_cv = X_train.iloc[cv_indices]\\n        y_cv = y_train.iloc[cv_indices]\\n\\n        lgbm_clf = lgb.LGBMClassifier(**params)\\n        lgbm_clf.fit(\\n            x_tr,\\n            y_tr,\\n            eval_set=[(x_cv, y_cv)],\\n            eval_metric=\\\"auc\\\",\\n            verbose=False,\\n            early_stopping_rounds=200,\\n        )\\n\\n        cv_preds[cv_indices] = lgbm_clf.predict_proba(\\n            x_cv, num_iteration=lgbm_clf.best_iteration_\\n        )[:, 1]\\n\\n    return roc_auc_score(target_train, cv_preds)\";\n",
       "                var nbb_formatted_code = \"def lgbm_evaluation(\\n    num_leaves,\\n    max_depth,\\n    min_split_gain,\\n    min_child_weight,\\n    min_child_samples,\\n    reg_alpha,\\n    reg_lambda,\\n):\\n    \\\"\\\"\\\"\\n    Objective function for Bayesian Optimization of LightGBM's Hyperparamters. Takes the hyperparameters as input, and\\n    returns the Cross-Validation AUC as output.\\n\\n    Inputs: Hyperparamters to be tuned.\\n        num_leaves, max_depth, min_split_gain, min_child_weight,\\n        min_child_samples, subsample, reg_alpha, reg_lambda\\n\\n    Returns:\\n        CV ROC-AUC Score\\n    \\\"\\\"\\\"\\n\\n    params = {\\n        \\\"objective\\\": \\\"binary\\\",\\n        \\\"boosting_type\\\": \\\"gbdt\\\",\\n        \\\"learning_rate\\\": 0.005,\\n        \\\"n_estimators\\\": 10000,\\n        \\\"n_jobs\\\": -1,\\n        \\\"num_leaves\\\": int(round(num_leaves)),\\n        \\\"max_depth\\\": int(round(max_depth)),\\n        \\\"min_split_gain\\\": min_split_gain,\\n        \\\"min_child_weight\\\": min_child_weight,\\n        \\\"min_child_samples\\\": int(round(min_child_samples)),\\n        \\\"reg_alpha\\\": reg_alpha,\\n        \\\"reg_lambda\\\": reg_lambda,\\n        \\\"verbosity\\\": -1,\\n        \\\"seed\\\": RANDOM_STATE,\\n    }\\n    stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\\n\\n    cv_preds = np.zeros(X_train.shape[0])\\n    for train_indices, cv_indices in stratified_cv.split(X_train, y_train):\\n\\n        x_tr = X_train.iloc[train_indices]\\n        y_tr = y_train.iloc[train_indices]\\n        x_cv = X_train.iloc[cv_indices]\\n        y_cv = y_train.iloc[cv_indices]\\n\\n        lgbm_clf = lgb.LGBMClassifier(**params)\\n        lgbm_clf.fit(\\n            x_tr,\\n            y_tr,\\n            eval_set=[(x_cv, y_cv)],\\n            eval_metric=\\\"auc\\\",\\n            verbose=False,\\n            early_stopping_rounds=200,\\n        )\\n\\n        cv_preds[cv_indices] = lgbm_clf.predict_proba(\\n            x_cv, num_iteration=lgbm_clf.best_iteration_\\n        )[:, 1]\\n\\n    return roc_auc_score(target_train, cv_preds)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lgbm_evaluation(\n",
    "    num_leaves,\n",
    "    max_depth,\n",
    "    min_split_gain,\n",
    "    min_child_weight,\n",
    "    min_child_samples,\n",
    "    reg_alpha,\n",
    "    reg_lambda,\n",
    "):\n",
    "    \"\"\"\n",
    "    Objective function for Bayesian Optimization of LightGBM's Hyperparamters. Takes the hyperparameters as input, and\n",
    "    returns the Cross-Validation AUC as output.\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": 0.005,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"n_jobs\": -1,\n",
    "        \"num_leaves\": int(round(num_leaves)),\n",
    "        \"max_depth\": int(round(max_depth)),\n",
    "        \"min_split_gain\": min_split_gain,\n",
    "        \"min_child_weight\": min_child_weight,\n",
    "        \"min_child_samples\": int(round(min_child_samples)),\n",
    "        \"reg_alpha\": reg_alpha,\n",
    "        \"reg_lambda\": reg_lambda,\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "    }\n",
    "    stratified_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    cv_preds = np.zeros(X_train.shape[0])\n",
    "    for train_indices, cv_indices in stratified_cv.split(X_train, y_train):\n",
    "\n",
    "        x_tr = X_train.iloc[train_indices]\n",
    "        y_tr = y_train.iloc[train_indices]\n",
    "        x_cv = X_train.iloc[cv_indices]\n",
    "        y_cv = y_train.iloc[cv_indices]\n",
    "\n",
    "        lgbm_clf = lgb.LGBMClassifier(**params)\n",
    "        lgbm_clf.fit(\n",
    "            x_tr,\n",
    "            y_tr,\n",
    "            eval_set=[(x_cv, y_cv)],\n",
    "            eval_metric=\"auc\",\n",
    "            verbose=False,\n",
    "            early_stopping_rounds=200,\n",
    "        )\n",
    "\n",
    "        cv_preds[cv_indices] = lgbm_clf.predict_proba(\n",
    "            x_cv, num_iteration=lgbm_clf.best_iteration_\n",
    "        )[:, 1]\n",
    "\n",
    "    return roc_auc_score(target_train, cv_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"bopt_lgbm = BayesianOptimization(\\n    lgbm_evaluation,\\n    {\\n        \\\"num_leaves\\\": (25, 50),\\n        \\\"max_depth\\\": (4, 11),\\n        \\\"min_split_gain\\\": (0, 0.1),\\n        \\\"min_child_weight\\\": (5, 80),\\n        \\\"min_child_samples\\\": (5, 80),\\n        \\\"reg_alpha\\\": (0.001, 0.3),\\n        \\\"reg_lambda\\\": (0.001, 0.3),\\n    },\\n    random_state=RANDOM_STATE,\\n)\\n\\n# bayesian_optimization = bopt_lgbm.maximize(n_iter=6, init_points=4)\";\n",
       "                var nbb_formatted_code = \"bopt_lgbm = BayesianOptimization(\\n    lgbm_evaluation,\\n    {\\n        \\\"num_leaves\\\": (25, 50),\\n        \\\"max_depth\\\": (4, 11),\\n        \\\"min_split_gain\\\": (0, 0.1),\\n        \\\"min_child_weight\\\": (5, 80),\\n        \\\"min_child_samples\\\": (5, 80),\\n        \\\"reg_alpha\\\": (0.001, 0.3),\\n        \\\"reg_lambda\\\": (0.001, 0.3),\\n    },\\n    random_state=RANDOM_STATE,\\n)\\n\\n# bayesian_optimization = bopt_lgbm.maximize(n_iter=6, init_points=4)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bopt_lgbm = BayesianOptimization(\n",
    "    lgbm_evaluation,\n",
    "    {\n",
    "        \"num_leaves\": (25, 50),\n",
    "        \"max_depth\": (4, 11),\n",
    "        \"min_split_gain\": (0, 0.1),\n",
    "        \"min_child_weight\": (5, 80),\n",
    "        \"min_child_samples\": (5, 80),\n",
    "        \"reg_alpha\": (0.001, 0.3),\n",
    "        \"reg_lambda\": (0.001, 0.3),\n",
    "    },\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# bayesian_optimization = bopt_lgbm.maximize(n_iter=6, init_points=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"#extracting the best parameters\\ntarget_values = []\\n#for result in bopt_lgbm.res:\\n    #target_values.append(result['target'])\\n    #if result['target'] == max(target_values):\\n        #best_params = result['params']\\n\\n#print(\\\"Best Hyperparameters obtained are:\\\\n\\\")\\n#print(best_params)\";\n",
       "                var nbb_formatted_code = \"# extracting the best parameters\\ntarget_values = []\\n# for result in bopt_lgbm.res:\\n# target_values.append(result['target'])\\n# if result['target'] == max(target_values):\\n# best_params = result['params']\\n\\n# print(\\\"Best Hyperparameters obtained are:\\\\n\\\")\\n# print(best_params)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extracting the best parameters\n",
    "target_values = []\n",
    "# for result in bopt_lgbm.res:\n",
    "# target_values.append(result['target'])\n",
    "# if result['target'] == max(target_values):\n",
    "# best_params = result['params']\n",
    "\n",
    "# print(\"Best Hyperparameters obtained are:\\n\")\n",
    "# print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-5-8** Training on optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"params = {\\n    \\\"learning_rate\\\": 0.01,\\n    \\\"n_estimators\\\": 4750,\\n    \\\"n_jobs\\\": -1,\\n    \\\"objective\\\": \\\"binary\\\",\\n    \\\"num_leaves\\\": 39,\\n    \\\"max_depth\\\": 10,\\n    \\\"boosting_type\\\": \\\"gbdt\\\",\\n    \\\"min_split_gain\\\": 0.030820727751758883,\\n    \\\"min_child_weight\\\": 30.074868967458226,\\n    \\\"min_child_samples\\\": 31,\\n    \\\"reg_alpha\\\": 0.15663020002553255,\\n    \\\"reg_lambda\\\": 0.22503178038757748,\\n    \\\"verbosity\\\": -1,\\n    \\\"metric\\\": \\\"auc\\\",\\n    \\\"seed\\\": RANDOM_STATE,\\n    \\\"feature_fraction\\\": 0.1,\\n}\";\n",
       "                var nbb_formatted_code = \"params = {\\n    \\\"learning_rate\\\": 0.01,\\n    \\\"n_estimators\\\": 4750,\\n    \\\"n_jobs\\\": -1,\\n    \\\"objective\\\": \\\"binary\\\",\\n    \\\"num_leaves\\\": 39,\\n    \\\"max_depth\\\": 10,\\n    \\\"boosting_type\\\": \\\"gbdt\\\",\\n    \\\"min_split_gain\\\": 0.030820727751758883,\\n    \\\"min_child_weight\\\": 30.074868967458226,\\n    \\\"min_child_samples\\\": 31,\\n    \\\"reg_alpha\\\": 0.15663020002553255,\\n    \\\"reg_lambda\\\": 0.22503178038757748,\\n    \\\"verbosity\\\": -1,\\n    \\\"metric\\\": \\\"auc\\\",\\n    \\\"seed\\\": RANDOM_STATE,\\n    \\\"feature_fraction\\\": 0.1,\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"n_estimators\": 4750,\n",
    "    \"n_jobs\": -1,\n",
    "    \"objective\": \"binary\",\n",
    "    \"num_leaves\": 39,\n",
    "    \"max_depth\": 10,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"min_split_gain\": 0.030820727751758883,\n",
    "    \"min_child_weight\": 30.074868967458226,\n",
    "    \"min_child_samples\": 31,\n",
    "    \"reg_alpha\": 0.15663020002553255,\n",
    "    \"reg_lambda\": 0.22503178038757748,\n",
    "    \"verbosity\": -1,\n",
    "    \"metric\": \"auc\",\n",
    "    \"seed\": RANDOM_STATE,\n",
    "    \"feature_fraction\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"training_dataset = lgb.Dataset(X_train, label=y_train)\\ntesting_dataset = lgb.Dataset(X_test, label=y_test)\";\n",
       "                var nbb_formatted_code = \"training_dataset = lgb.Dataset(X_train, label=y_train)\\ntesting_dataset = lgb.Dataset(X_test, label=y_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_dataset = lgb.Dataset(X_train, label=y_train)\n",
    "testing_dataset = lgb.Dataset(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.71691\tvalid_1's auc: 0.710271\n",
      "[2]\ttraining's auc: 0.75442\tvalid_1's auc: 0.747887\n",
      "[3]\ttraining's auc: 0.750402\tvalid_1's auc: 0.742777\n",
      "[4]\ttraining's auc: 0.748001\tvalid_1's auc: 0.740192\n",
      "[5]\ttraining's auc: 0.745851\tvalid_1's auc: 0.738076\n",
      "[6]\ttraining's auc: 0.7445\tvalid_1's auc: 0.736491\n",
      "[7]\ttraining's auc: 0.742605\tvalid_1's auc: 0.734697\n",
      "[8]\ttraining's auc: 0.742075\tvalid_1's auc: 0.734509\n",
      "[9]\ttraining's auc: 0.742135\tvalid_1's auc: 0.734483\n",
      "[10]\ttraining's auc: 0.747942\tvalid_1's auc: 0.740503\n",
      "[11]\ttraining's auc: 0.746659\tvalid_1's auc: 0.739327\n",
      "[12]\ttraining's auc: 0.745487\tvalid_1's auc: 0.73825\n",
      "[13]\ttraining's auc: 0.74501\tvalid_1's auc: 0.737577\n",
      "[14]\ttraining's auc: 0.744366\tvalid_1's auc: 0.736924\n",
      "[15]\ttraining's auc: 0.744075\tvalid_1's auc: 0.736677\n",
      "[16]\ttraining's auc: 0.743421\tvalid_1's auc: 0.736059\n",
      "[17]\ttraining's auc: 0.742956\tvalid_1's auc: 0.735528\n",
      "[18]\ttraining's auc: 0.746151\tvalid_1's auc: 0.738805\n",
      "[19]\ttraining's auc: 0.746103\tvalid_1's auc: 0.738836\n",
      "[20]\ttraining's auc: 0.745596\tvalid_1's auc: 0.738338\n",
      "[21]\ttraining's auc: 0.745378\tvalid_1's auc: 0.738182\n",
      "[22]\ttraining's auc: 0.74519\tvalid_1's auc: 0.737937\n",
      "[23]\ttraining's auc: 0.745342\tvalid_1's auc: 0.738023\n",
      "[24]\ttraining's auc: 0.745335\tvalid_1's auc: 0.73819\n",
      "[25]\ttraining's auc: 0.745132\tvalid_1's auc: 0.738048\n",
      "[26]\ttraining's auc: 0.745059\tvalid_1's auc: 0.737976\n",
      "[27]\ttraining's auc: 0.744631\tvalid_1's auc: 0.737492\n",
      "[28]\ttraining's auc: 0.744563\tvalid_1's auc: 0.737564\n",
      "[29]\ttraining's auc: 0.744623\tvalid_1's auc: 0.737497\n",
      "[30]\ttraining's auc: 0.744482\tvalid_1's auc: 0.737339\n",
      "[31]\ttraining's auc: 0.744733\tvalid_1's auc: 0.737631\n",
      "[32]\ttraining's auc: 0.74467\tvalid_1's auc: 0.737389\n",
      "[33]\ttraining's auc: 0.744885\tvalid_1's auc: 0.737576\n",
      "[34]\ttraining's auc: 0.744635\tvalid_1's auc: 0.737355\n",
      "[35]\ttraining's auc: 0.744753\tvalid_1's auc: 0.737543\n",
      "[36]\ttraining's auc: 0.744817\tvalid_1's auc: 0.737584\n",
      "[37]\ttraining's auc: 0.744961\tvalid_1's auc: 0.737633\n",
      "[38]\ttraining's auc: 0.745083\tvalid_1's auc: 0.737811\n",
      "[39]\ttraining's auc: 0.746642\tvalid_1's auc: 0.739412\n",
      "[40]\ttraining's auc: 0.746744\tvalid_1's auc: 0.739469\n",
      "[41]\ttraining's auc: 0.746792\tvalid_1's auc: 0.739367\n",
      "[42]\ttraining's auc: 0.748119\tvalid_1's auc: 0.740706\n",
      "[43]\ttraining's auc: 0.747985\tvalid_1's auc: 0.740522\n",
      "[44]\ttraining's auc: 0.74782\tvalid_1's auc: 0.740363\n",
      "[45]\ttraining's auc: 0.747924\tvalid_1's auc: 0.740378\n",
      "[46]\ttraining's auc: 0.747851\tvalid_1's auc: 0.74033\n",
      "[47]\ttraining's auc: 0.747775\tvalid_1's auc: 0.740253\n",
      "[48]\ttraining's auc: 0.748081\tvalid_1's auc: 0.740428\n",
      "[49]\ttraining's auc: 0.74809\tvalid_1's auc: 0.740364\n",
      "[50]\ttraining's auc: 0.74803\tvalid_1's auc: 0.740255\n",
      "[51]\ttraining's auc: 0.74808\tvalid_1's auc: 0.740244\n",
      "[52]\ttraining's auc: 0.748127\tvalid_1's auc: 0.740238\n",
      "[53]\ttraining's auc: 0.748077\tvalid_1's auc: 0.740158\n",
      "[54]\ttraining's auc: 0.748288\tvalid_1's auc: 0.740285\n",
      "[55]\ttraining's auc: 0.748518\tvalid_1's auc: 0.740404\n",
      "[56]\ttraining's auc: 0.748605\tvalid_1's auc: 0.740481\n",
      "[57]\ttraining's auc: 0.748492\tvalid_1's auc: 0.740369\n",
      "[58]\ttraining's auc: 0.749508\tvalid_1's auc: 0.741355\n",
      "[59]\ttraining's auc: 0.749583\tvalid_1's auc: 0.741285\n",
      "[60]\ttraining's auc: 0.749591\tvalid_1's auc: 0.741304\n",
      "[61]\ttraining's auc: 0.749593\tvalid_1's auc: 0.741211\n",
      "[62]\ttraining's auc: 0.749749\tvalid_1's auc: 0.741258\n",
      "[63]\ttraining's auc: 0.749787\tvalid_1's auc: 0.741216\n",
      "[64]\ttraining's auc: 0.749776\tvalid_1's auc: 0.741202\n",
      "[65]\ttraining's auc: 0.749922\tvalid_1's auc: 0.741304\n",
      "[66]\ttraining's auc: 0.749976\tvalid_1's auc: 0.741242\n",
      "[67]\ttraining's auc: 0.750087\tvalid_1's auc: 0.741332\n",
      "[68]\ttraining's auc: 0.750316\tvalid_1's auc: 0.741542\n",
      "[69]\ttraining's auc: 0.751201\tvalid_1's auc: 0.742425\n",
      "[70]\ttraining's auc: 0.751995\tvalid_1's auc: 0.743199\n",
      "[71]\ttraining's auc: 0.752011\tvalid_1's auc: 0.743227\n",
      "[72]\ttraining's auc: 0.75207\tvalid_1's auc: 0.743273\n",
      "[73]\ttraining's auc: 0.752156\tvalid_1's auc: 0.743331\n",
      "[74]\ttraining's auc: 0.752182\tvalid_1's auc: 0.743248\n",
      "[75]\ttraining's auc: 0.752362\tvalid_1's auc: 0.743353\n",
      "[76]\ttraining's auc: 0.752344\tvalid_1's auc: 0.743287\n",
      "[77]\ttraining's auc: 0.752383\tvalid_1's auc: 0.743262\n",
      "[78]\ttraining's auc: 0.75243\tvalid_1's auc: 0.7432\n",
      "[79]\ttraining's auc: 0.752488\tvalid_1's auc: 0.743162\n",
      "[80]\ttraining's auc: 0.752523\tvalid_1's auc: 0.743136\n",
      "[81]\ttraining's auc: 0.753246\tvalid_1's auc: 0.743849\n",
      "[82]\ttraining's auc: 0.753331\tvalid_1's auc: 0.743831\n",
      "[83]\ttraining's auc: 0.753981\tvalid_1's auc: 0.744473\n",
      "[84]\ttraining's auc: 0.753986\tvalid_1's auc: 0.744438\n",
      "[85]\ttraining's auc: 0.754038\tvalid_1's auc: 0.744438\n",
      "[86]\ttraining's auc: 0.754131\tvalid_1's auc: 0.744476\n",
      "[87]\ttraining's auc: 0.754145\tvalid_1's auc: 0.744472\n",
      "[88]\ttraining's auc: 0.754203\tvalid_1's auc: 0.744483\n",
      "[89]\ttraining's auc: 0.754336\tvalid_1's auc: 0.744583\n",
      "[90]\ttraining's auc: 0.754982\tvalid_1's auc: 0.745217\n",
      "[91]\ttraining's auc: 0.755029\tvalid_1's auc: 0.745228\n",
      "[92]\ttraining's auc: 0.755044\tvalid_1's auc: 0.745183\n",
      "[93]\ttraining's auc: 0.755112\tvalid_1's auc: 0.745189\n",
      "[94]\ttraining's auc: 0.755302\tvalid_1's auc: 0.745369\n",
      "[95]\ttraining's auc: 0.755404\tvalid_1's auc: 0.745383\n",
      "[96]\ttraining's auc: 0.755471\tvalid_1's auc: 0.7454\n",
      "[97]\ttraining's auc: 0.755604\tvalid_1's auc: 0.745431\n",
      "[98]\ttraining's auc: 0.755706\tvalid_1's auc: 0.745482\n",
      "[99]\ttraining's auc: 0.755875\tvalid_1's auc: 0.745602\n",
      "[100]\ttraining's auc: 0.755989\tvalid_1's auc: 0.745668\n",
      "[101]\ttraining's auc: 0.756107\tvalid_1's auc: 0.745717\n",
      "[102]\ttraining's auc: 0.756181\tvalid_1's auc: 0.745706\n",
      "[103]\ttraining's auc: 0.756328\tvalid_1's auc: 0.745812\n",
      "[104]\ttraining's auc: 0.75636\tvalid_1's auc: 0.745822\n",
      "[105]\ttraining's auc: 0.756429\tvalid_1's auc: 0.745845\n",
      "[106]\ttraining's auc: 0.75645\tvalid_1's auc: 0.745823\n",
      "[107]\ttraining's auc: 0.756585\tvalid_1's auc: 0.745922\n",
      "[108]\ttraining's auc: 0.757126\tvalid_1's auc: 0.74642\n",
      "[109]\ttraining's auc: 0.757234\tvalid_1's auc: 0.746501\n",
      "[110]\ttraining's auc: 0.757275\tvalid_1's auc: 0.746537\n",
      "[111]\ttraining's auc: 0.757375\tvalid_1's auc: 0.746582\n",
      "[112]\ttraining's auc: 0.757904\tvalid_1's auc: 0.747056\n",
      "[113]\ttraining's auc: 0.757985\tvalid_1's auc: 0.747089\n",
      "[114]\ttraining's auc: 0.758054\tvalid_1's auc: 0.747155\n",
      "[115]\ttraining's auc: 0.758192\tvalid_1's auc: 0.747263\n",
      "[116]\ttraining's auc: 0.758307\tvalid_1's auc: 0.747352\n",
      "[117]\ttraining's auc: 0.758826\tvalid_1's auc: 0.74784\n",
      "[118]\ttraining's auc: 0.758938\tvalid_1's auc: 0.74796\n",
      "[119]\ttraining's auc: 0.759058\tvalid_1's auc: 0.748041\n",
      "[120]\ttraining's auc: 0.759107\tvalid_1's auc: 0.748069\n",
      "[121]\ttraining's auc: 0.759186\tvalid_1's auc: 0.748114\n",
      "[122]\ttraining's auc: 0.759653\tvalid_1's auc: 0.748557\n",
      "[123]\ttraining's auc: 0.759715\tvalid_1's auc: 0.748588\n",
      "[124]\ttraining's auc: 0.759823\tvalid_1's auc: 0.748656\n",
      "[125]\ttraining's auc: 0.759932\tvalid_1's auc: 0.748714\n",
      "[126]\ttraining's auc: 0.760053\tvalid_1's auc: 0.748789\n",
      "[127]\ttraining's auc: 0.760484\tvalid_1's auc: 0.749206\n",
      "[128]\ttraining's auc: 0.76064\tvalid_1's auc: 0.749341\n",
      "[129]\ttraining's auc: 0.760685\tvalid_1's auc: 0.749372\n",
      "[130]\ttraining's auc: 0.761109\tvalid_1's auc: 0.74978\n",
      "[131]\ttraining's auc: 0.761294\tvalid_1's auc: 0.749912\n",
      "[132]\ttraining's auc: 0.761438\tvalid_1's auc: 0.750005\n",
      "[133]\ttraining's auc: 0.76152\tvalid_1's auc: 0.750067\n",
      "[134]\ttraining's auc: 0.761885\tvalid_1's auc: 0.750444\n",
      "[135]\ttraining's auc: 0.762086\tvalid_1's auc: 0.750594\n",
      "[136]\ttraining's auc: 0.762142\tvalid_1's auc: 0.750607\n",
      "[137]\ttraining's auc: 0.762199\tvalid_1's auc: 0.750655\n",
      "[138]\ttraining's auc: 0.76224\tvalid_1's auc: 0.750682\n",
      "[139]\ttraining's auc: 0.762501\tvalid_1's auc: 0.750889\n",
      "[140]\ttraining's auc: 0.762613\tvalid_1's auc: 0.750964\n",
      "[141]\ttraining's auc: 0.762704\tvalid_1's auc: 0.751006\n",
      "[142]\ttraining's auc: 0.76275\tvalid_1's auc: 0.751015\n",
      "[143]\ttraining's auc: 0.762901\tvalid_1's auc: 0.751087\n",
      "[144]\ttraining's auc: 0.762966\tvalid_1's auc: 0.75112\n",
      "[145]\ttraining's auc: 0.763082\tvalid_1's auc: 0.751198\n",
      "[146]\ttraining's auc: 0.763194\tvalid_1's auc: 0.751306\n",
      "[147]\ttraining's auc: 0.763239\tvalid_1's auc: 0.751328\n",
      "[148]\ttraining's auc: 0.763322\tvalid_1's auc: 0.751371\n",
      "[149]\ttraining's auc: 0.763361\tvalid_1's auc: 0.751385\n",
      "[150]\ttraining's auc: 0.763743\tvalid_1's auc: 0.751742\n",
      "[151]\ttraining's auc: 0.763891\tvalid_1's auc: 0.751842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152]\ttraining's auc: 0.763973\tvalid_1's auc: 0.751868\n",
      "[153]\ttraining's auc: 0.764115\tvalid_1's auc: 0.751957\n",
      "[154]\ttraining's auc: 0.764188\tvalid_1's auc: 0.751988\n",
      "[155]\ttraining's auc: 0.764395\tvalid_1's auc: 0.752166\n",
      "[156]\ttraining's auc: 0.764468\tvalid_1's auc: 0.752212\n",
      "[157]\ttraining's auc: 0.764686\tvalid_1's auc: 0.75238\n",
      "[158]\ttraining's auc: 0.764782\tvalid_1's auc: 0.752429\n",
      "[159]\ttraining's auc: 0.764885\tvalid_1's auc: 0.75247\n",
      "[160]\ttraining's auc: 0.765054\tvalid_1's auc: 0.752604\n",
      "[161]\ttraining's auc: 0.765179\tvalid_1's auc: 0.752678\n",
      "[162]\ttraining's auc: 0.765268\tvalid_1's auc: 0.752711\n",
      "[163]\ttraining's auc: 0.765357\tvalid_1's auc: 0.752764\n",
      "[164]\ttraining's auc: 0.765397\tvalid_1's auc: 0.752777\n",
      "[165]\ttraining's auc: 0.765698\tvalid_1's auc: 0.753057\n",
      "[166]\ttraining's auc: 0.765998\tvalid_1's auc: 0.753335\n",
      "[167]\ttraining's auc: 0.766074\tvalid_1's auc: 0.753381\n",
      "[168]\ttraining's auc: 0.766171\tvalid_1's auc: 0.753461\n",
      "[169]\ttraining's auc: 0.766192\tvalid_1's auc: 0.753466\n",
      "[170]\ttraining's auc: 0.766243\tvalid_1's auc: 0.753497\n",
      "[171]\ttraining's auc: 0.766313\tvalid_1's auc: 0.753526\n",
      "[172]\ttraining's auc: 0.766387\tvalid_1's auc: 0.75357\n",
      "[173]\ttraining's auc: 0.766502\tvalid_1's auc: 0.753637\n",
      "[174]\ttraining's auc: 0.766594\tvalid_1's auc: 0.753664\n",
      "[175]\ttraining's auc: 0.766895\tvalid_1's auc: 0.753954\n",
      "[176]\ttraining's auc: 0.767106\tvalid_1's auc: 0.754112\n",
      "[177]\ttraining's auc: 0.767188\tvalid_1's auc: 0.754165\n",
      "[178]\ttraining's auc: 0.767319\tvalid_1's auc: 0.754258\n",
      "[179]\ttraining's auc: 0.767382\tvalid_1's auc: 0.754288\n",
      "[180]\ttraining's auc: 0.767501\tvalid_1's auc: 0.754358\n",
      "[181]\ttraining's auc: 0.767662\tvalid_1's auc: 0.754485\n",
      "[182]\ttraining's auc: 0.767733\tvalid_1's auc: 0.754525\n",
      "[183]\ttraining's auc: 0.767805\tvalid_1's auc: 0.754558\n",
      "[184]\ttraining's auc: 0.768025\tvalid_1's auc: 0.754735\n",
      "[185]\ttraining's auc: 0.768141\tvalid_1's auc: 0.754826\n",
      "[186]\ttraining's auc: 0.768202\tvalid_1's auc: 0.754856\n",
      "[187]\ttraining's auc: 0.768317\tvalid_1's auc: 0.754909\n",
      "[188]\ttraining's auc: 0.768444\tvalid_1's auc: 0.754987\n",
      "[189]\ttraining's auc: 0.768491\tvalid_1's auc: 0.755002\n",
      "[190]\ttraining's auc: 0.768557\tvalid_1's auc: 0.755067\n",
      "[191]\ttraining's auc: 0.768653\tvalid_1's auc: 0.755094\n",
      "[192]\ttraining's auc: 0.768957\tvalid_1's auc: 0.755384\n",
      "[193]\ttraining's auc: 0.76902\tvalid_1's auc: 0.755385\n",
      "[194]\ttraining's auc: 0.769187\tvalid_1's auc: 0.755484\n",
      "[195]\ttraining's auc: 0.769304\tvalid_1's auc: 0.755537\n",
      "[196]\ttraining's auc: 0.769425\tvalid_1's auc: 0.755603\n",
      "[197]\ttraining's auc: 0.769489\tvalid_1's auc: 0.755634\n",
      "[198]\ttraining's auc: 0.769588\tvalid_1's auc: 0.755705\n",
      "[199]\ttraining's auc: 0.769674\tvalid_1's auc: 0.75574\n",
      "[200]\ttraining's auc: 0.769801\tvalid_1's auc: 0.755806\n",
      "[201]\ttraining's auc: 0.769949\tvalid_1's auc: 0.755905\n",
      "[202]\ttraining's auc: 0.770202\tvalid_1's auc: 0.756143\n",
      "[203]\ttraining's auc: 0.770296\tvalid_1's auc: 0.756202\n",
      "[204]\ttraining's auc: 0.770386\tvalid_1's auc: 0.756263\n",
      "[205]\ttraining's auc: 0.770485\tvalid_1's auc: 0.756311\n",
      "[206]\ttraining's auc: 0.770579\tvalid_1's auc: 0.756359\n",
      "[207]\ttraining's auc: 0.770697\tvalid_1's auc: 0.756437\n",
      "[208]\ttraining's auc: 0.770796\tvalid_1's auc: 0.756493\n",
      "[209]\ttraining's auc: 0.770931\tvalid_1's auc: 0.756604\n",
      "[210]\ttraining's auc: 0.771179\tvalid_1's auc: 0.756836\n",
      "[211]\ttraining's auc: 0.771325\tvalid_1's auc: 0.756933\n",
      "[212]\ttraining's auc: 0.771432\tvalid_1's auc: 0.757\n",
      "[213]\ttraining's auc: 0.771518\tvalid_1's auc: 0.757027\n",
      "[214]\ttraining's auc: 0.771588\tvalid_1's auc: 0.757053\n",
      "[215]\ttraining's auc: 0.771673\tvalid_1's auc: 0.757113\n",
      "[216]\ttraining's auc: 0.771717\tvalid_1's auc: 0.757118\n",
      "[217]\ttraining's auc: 0.771787\tvalid_1's auc: 0.757162\n",
      "[218]\ttraining's auc: 0.772024\tvalid_1's auc: 0.757395\n",
      "[219]\ttraining's auc: 0.77214\tvalid_1's auc: 0.757471\n",
      "[220]\ttraining's auc: 0.772236\tvalid_1's auc: 0.757532\n",
      "[221]\ttraining's auc: 0.772357\tvalid_1's auc: 0.75763\n",
      "[222]\ttraining's auc: 0.772456\tvalid_1's auc: 0.757676\n",
      "[223]\ttraining's auc: 0.772553\tvalid_1's auc: 0.757718\n",
      "[224]\ttraining's auc: 0.772609\tvalid_1's auc: 0.757725\n",
      "[225]\ttraining's auc: 0.772731\tvalid_1's auc: 0.757814\n",
      "[226]\ttraining's auc: 0.772832\tvalid_1's auc: 0.757874\n",
      "[227]\ttraining's auc: 0.772972\tvalid_1's auc: 0.757994\n",
      "[228]\ttraining's auc: 0.773023\tvalid_1's auc: 0.758036\n",
      "[229]\ttraining's auc: 0.773135\tvalid_1's auc: 0.758125\n",
      "[230]\ttraining's auc: 0.773246\tvalid_1's auc: 0.758181\n",
      "[231]\ttraining's auc: 0.773321\tvalid_1's auc: 0.758238\n",
      "[232]\ttraining's auc: 0.773386\tvalid_1's auc: 0.758272\n",
      "[233]\ttraining's auc: 0.773538\tvalid_1's auc: 0.758401\n",
      "[234]\ttraining's auc: 0.773764\tvalid_1's auc: 0.758638\n",
      "[235]\ttraining's auc: 0.773859\tvalid_1's auc: 0.758663\n",
      "[236]\ttraining's auc: 0.774003\tvalid_1's auc: 0.758763\n",
      "[237]\ttraining's auc: 0.774064\tvalid_1's auc: 0.758789\n",
      "[238]\ttraining's auc: 0.774272\tvalid_1's auc: 0.758986\n",
      "[239]\ttraining's auc: 0.774358\tvalid_1's auc: 0.759033\n",
      "[240]\ttraining's auc: 0.774439\tvalid_1's auc: 0.759097\n",
      "[241]\ttraining's auc: 0.774535\tvalid_1's auc: 0.759159\n",
      "[242]\ttraining's auc: 0.774658\tvalid_1's auc: 0.759226\n",
      "[243]\ttraining's auc: 0.774814\tvalid_1's auc: 0.759359\n",
      "[244]\ttraining's auc: 0.774905\tvalid_1's auc: 0.759421\n",
      "[245]\ttraining's auc: 0.774979\tvalid_1's auc: 0.759443\n",
      "[246]\ttraining's auc: 0.775076\tvalid_1's auc: 0.759502\n",
      "[247]\ttraining's auc: 0.775124\tvalid_1's auc: 0.759511\n",
      "[248]\ttraining's auc: 0.775191\tvalid_1's auc: 0.759553\n",
      "[249]\ttraining's auc: 0.77541\tvalid_1's auc: 0.759739\n",
      "[250]\ttraining's auc: 0.775606\tvalid_1's auc: 0.759931\n",
      "[251]\ttraining's auc: 0.775692\tvalid_1's auc: 0.759985\n",
      "[252]\ttraining's auc: 0.775778\tvalid_1's auc: 0.76005\n",
      "[253]\ttraining's auc: 0.775882\tvalid_1's auc: 0.760128\n",
      "[254]\ttraining's auc: 0.776078\tvalid_1's auc: 0.760319\n",
      "[255]\ttraining's auc: 0.776164\tvalid_1's auc: 0.760352\n",
      "[256]\ttraining's auc: 0.776275\tvalid_1's auc: 0.760436\n",
      "[257]\ttraining's auc: 0.776383\tvalid_1's auc: 0.760514\n",
      "[258]\ttraining's auc: 0.776468\tvalid_1's auc: 0.760585\n",
      "[259]\ttraining's auc: 0.776542\tvalid_1's auc: 0.760611\n",
      "[260]\ttraining's auc: 0.776656\tvalid_1's auc: 0.760684\n",
      "[261]\ttraining's auc: 0.776744\tvalid_1's auc: 0.760709\n",
      "[262]\ttraining's auc: 0.776836\tvalid_1's auc: 0.760761\n",
      "[263]\ttraining's auc: 0.776941\tvalid_1's auc: 0.760852\n",
      "[264]\ttraining's auc: 0.777041\tvalid_1's auc: 0.760922\n",
      "[265]\ttraining's auc: 0.777156\tvalid_1's auc: 0.761005\n",
      "[266]\ttraining's auc: 0.777231\tvalid_1's auc: 0.761054\n",
      "[267]\ttraining's auc: 0.777326\tvalid_1's auc: 0.761091\n",
      "[268]\ttraining's auc: 0.777427\tvalid_1's auc: 0.761143\n",
      "[269]\ttraining's auc: 0.777483\tvalid_1's auc: 0.761171\n",
      "[270]\ttraining's auc: 0.777585\tvalid_1's auc: 0.761225\n",
      "[271]\ttraining's auc: 0.777719\tvalid_1's auc: 0.761309\n",
      "[272]\ttraining's auc: 0.77783\tvalid_1's auc: 0.761397\n",
      "[273]\ttraining's auc: 0.777956\tvalid_1's auc: 0.761478\n",
      "[274]\ttraining's auc: 0.77804\tvalid_1's auc: 0.761534\n",
      "[275]\ttraining's auc: 0.778141\tvalid_1's auc: 0.761618\n",
      "[276]\ttraining's auc: 0.77827\tvalid_1's auc: 0.761717\n",
      "[277]\ttraining's auc: 0.778339\tvalid_1's auc: 0.761761\n",
      "[278]\ttraining's auc: 0.778405\tvalid_1's auc: 0.761798\n",
      "[279]\ttraining's auc: 0.7785\tvalid_1's auc: 0.761875\n",
      "[280]\ttraining's auc: 0.778586\tvalid_1's auc: 0.761911\n",
      "[281]\ttraining's auc: 0.778685\tvalid_1's auc: 0.761988\n",
      "[282]\ttraining's auc: 0.778868\tvalid_1's auc: 0.762152\n",
      "[283]\ttraining's auc: 0.778963\tvalid_1's auc: 0.762201\n",
      "[284]\ttraining's auc: 0.779057\tvalid_1's auc: 0.762259\n",
      "[285]\ttraining's auc: 0.779135\tvalid_1's auc: 0.762293\n",
      "[286]\ttraining's auc: 0.779201\tvalid_1's auc: 0.762319\n",
      "[287]\ttraining's auc: 0.779298\tvalid_1's auc: 0.762382\n",
      "[288]\ttraining's auc: 0.779343\tvalid_1's auc: 0.762412\n",
      "[289]\ttraining's auc: 0.779412\tvalid_1's auc: 0.762437\n",
      "[290]\ttraining's auc: 0.779511\tvalid_1's auc: 0.76251\n",
      "[291]\ttraining's auc: 0.779573\tvalid_1's auc: 0.762535\n",
      "[292]\ttraining's auc: 0.779661\tvalid_1's auc: 0.762585\n",
      "[293]\ttraining's auc: 0.779747\tvalid_1's auc: 0.76263\n",
      "[294]\ttraining's auc: 0.779922\tvalid_1's auc: 0.762786\n",
      "[295]\ttraining's auc: 0.780003\tvalid_1's auc: 0.762836\n",
      "[296]\ttraining's auc: 0.780114\tvalid_1's auc: 0.762897\n",
      "[297]\ttraining's auc: 0.780288\tvalid_1's auc: 0.763061\n",
      "[298]\ttraining's auc: 0.780368\tvalid_1's auc: 0.763108\n",
      "[299]\ttraining's auc: 0.780457\tvalid_1's auc: 0.763157\n",
      "[300]\ttraining's auc: 0.78055\tvalid_1's auc: 0.763202\n",
      "[301]\ttraining's auc: 0.780617\tvalid_1's auc: 0.763252\n",
      "[302]\ttraining's auc: 0.78072\tvalid_1's auc: 0.763305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[303]\ttraining's auc: 0.780823\tvalid_1's auc: 0.763374\n",
      "[304]\ttraining's auc: 0.780881\tvalid_1's auc: 0.76338\n",
      "[305]\ttraining's auc: 0.780968\tvalid_1's auc: 0.763444\n",
      "[306]\ttraining's auc: 0.781145\tvalid_1's auc: 0.763598\n",
      "[307]\ttraining's auc: 0.781247\tvalid_1's auc: 0.763637\n",
      "[308]\ttraining's auc: 0.781327\tvalid_1's auc: 0.763686\n",
      "[309]\ttraining's auc: 0.781389\tvalid_1's auc: 0.763718\n",
      "[310]\ttraining's auc: 0.781475\tvalid_1's auc: 0.763771\n",
      "[311]\ttraining's auc: 0.781552\tvalid_1's auc: 0.763823\n",
      "[312]\ttraining's auc: 0.781717\tvalid_1's auc: 0.763958\n",
      "[313]\ttraining's auc: 0.781833\tvalid_1's auc: 0.764036\n",
      "[314]\ttraining's auc: 0.781983\tvalid_1's auc: 0.764166\n",
      "[315]\ttraining's auc: 0.782069\tvalid_1's auc: 0.764212\n",
      "[316]\ttraining's auc: 0.782225\tvalid_1's auc: 0.76435\n",
      "[317]\ttraining's auc: 0.782335\tvalid_1's auc: 0.764419\n",
      "[318]\ttraining's auc: 0.782432\tvalid_1's auc: 0.76449\n",
      "[319]\ttraining's auc: 0.782529\tvalid_1's auc: 0.764548\n",
      "[320]\ttraining's auc: 0.782605\tvalid_1's auc: 0.764595\n",
      "[321]\ttraining's auc: 0.782689\tvalid_1's auc: 0.764642\n",
      "[322]\ttraining's auc: 0.782807\tvalid_1's auc: 0.764701\n",
      "[323]\ttraining's auc: 0.78291\tvalid_1's auc: 0.764786\n",
      "[324]\ttraining's auc: 0.783002\tvalid_1's auc: 0.76483\n",
      "[325]\ttraining's auc: 0.783087\tvalid_1's auc: 0.764875\n",
      "[326]\ttraining's auc: 0.78318\tvalid_1's auc: 0.764955\n",
      "[327]\ttraining's auc: 0.783267\tvalid_1's auc: 0.764998\n",
      "[328]\ttraining's auc: 0.783318\tvalid_1's auc: 0.76502\n",
      "[329]\ttraining's auc: 0.783389\tvalid_1's auc: 0.765063\n",
      "[330]\ttraining's auc: 0.783521\tvalid_1's auc: 0.765173\n",
      "[331]\ttraining's auc: 0.78361\tvalid_1's auc: 0.765209\n",
      "[332]\ttraining's auc: 0.783684\tvalid_1's auc: 0.765242\n",
      "[333]\ttraining's auc: 0.783761\tvalid_1's auc: 0.76529\n",
      "[334]\ttraining's auc: 0.783916\tvalid_1's auc: 0.765427\n",
      "[335]\ttraining's auc: 0.783979\tvalid_1's auc: 0.765464\n",
      "[336]\ttraining's auc: 0.784041\tvalid_1's auc: 0.765501\n",
      "[337]\ttraining's auc: 0.784128\tvalid_1's auc: 0.765565\n",
      "[338]\ttraining's auc: 0.784279\tvalid_1's auc: 0.765697\n",
      "[339]\ttraining's auc: 0.784426\tvalid_1's auc: 0.765826\n",
      "[340]\ttraining's auc: 0.784493\tvalid_1's auc: 0.765868\n",
      "[341]\ttraining's auc: 0.78459\tvalid_1's auc: 0.765939\n",
      "[342]\ttraining's auc: 0.784676\tvalid_1's auc: 0.765992\n",
      "[343]\ttraining's auc: 0.784721\tvalid_1's auc: 0.765993\n",
      "[344]\ttraining's auc: 0.784801\tvalid_1's auc: 0.766059\n",
      "[345]\ttraining's auc: 0.784897\tvalid_1's auc: 0.766116\n",
      "[346]\ttraining's auc: 0.78497\tvalid_1's auc: 0.766145\n",
      "[347]\ttraining's auc: 0.785099\tvalid_1's auc: 0.766243\n",
      "[348]\ttraining's auc: 0.785187\tvalid_1's auc: 0.766317\n",
      "[349]\ttraining's auc: 0.785264\tvalid_1's auc: 0.766337\n",
      "[350]\ttraining's auc: 0.78535\tvalid_1's auc: 0.766385\n",
      "[351]\ttraining's auc: 0.785406\tvalid_1's auc: 0.766418\n",
      "[352]\ttraining's auc: 0.785485\tvalid_1's auc: 0.766477\n",
      "[353]\ttraining's auc: 0.785557\tvalid_1's auc: 0.766533\n",
      "[354]\ttraining's auc: 0.785631\tvalid_1's auc: 0.766565\n",
      "[355]\ttraining's auc: 0.785733\tvalid_1's auc: 0.766614\n",
      "[356]\ttraining's auc: 0.785783\tvalid_1's auc: 0.76662\n",
      "[357]\ttraining's auc: 0.78585\tvalid_1's auc: 0.766642\n",
      "[358]\ttraining's auc: 0.785921\tvalid_1's auc: 0.766692\n",
      "[359]\ttraining's auc: 0.785989\tvalid_1's auc: 0.766711\n",
      "[360]\ttraining's auc: 0.78607\tvalid_1's auc: 0.766745\n",
      "[361]\ttraining's auc: 0.786145\tvalid_1's auc: 0.766785\n",
      "[362]\ttraining's auc: 0.786277\tvalid_1's auc: 0.766883\n",
      "[363]\ttraining's auc: 0.786407\tvalid_1's auc: 0.766997\n",
      "[364]\ttraining's auc: 0.78649\tvalid_1's auc: 0.767044\n",
      "[365]\ttraining's auc: 0.786605\tvalid_1's auc: 0.767153\n",
      "[366]\ttraining's auc: 0.786661\tvalid_1's auc: 0.767189\n",
      "[367]\ttraining's auc: 0.78675\tvalid_1's auc: 0.767231\n",
      "[368]\ttraining's auc: 0.78683\tvalid_1's auc: 0.767273\n",
      "[369]\ttraining's auc: 0.786912\tvalid_1's auc: 0.767319\n",
      "[370]\ttraining's auc: 0.787039\tvalid_1's auc: 0.7674\n",
      "[371]\ttraining's auc: 0.787122\tvalid_1's auc: 0.767456\n",
      "[372]\ttraining's auc: 0.787214\tvalid_1's auc: 0.76751\n",
      "[373]\ttraining's auc: 0.787275\tvalid_1's auc: 0.767539\n",
      "[374]\ttraining's auc: 0.787349\tvalid_1's auc: 0.767577\n",
      "[375]\ttraining's auc: 0.787409\tvalid_1's auc: 0.767596\n",
      "[376]\ttraining's auc: 0.787485\tvalid_1's auc: 0.767642\n",
      "[377]\ttraining's auc: 0.787563\tvalid_1's auc: 0.76768\n",
      "[378]\ttraining's auc: 0.787619\tvalid_1's auc: 0.767715\n",
      "[379]\ttraining's auc: 0.787687\tvalid_1's auc: 0.767755\n",
      "[380]\ttraining's auc: 0.787762\tvalid_1's auc: 0.767787\n",
      "[381]\ttraining's auc: 0.787854\tvalid_1's auc: 0.767864\n",
      "[382]\ttraining's auc: 0.787961\tvalid_1's auc: 0.767935\n",
      "[383]\ttraining's auc: 0.788065\tvalid_1's auc: 0.768014\n",
      "[384]\ttraining's auc: 0.788195\tvalid_1's auc: 0.768107\n",
      "[385]\ttraining's auc: 0.788252\tvalid_1's auc: 0.768121\n",
      "[386]\ttraining's auc: 0.788307\tvalid_1's auc: 0.768137\n",
      "[387]\ttraining's auc: 0.78839\tvalid_1's auc: 0.768174\n",
      "[388]\ttraining's auc: 0.788466\tvalid_1's auc: 0.768211\n",
      "[389]\ttraining's auc: 0.788531\tvalid_1's auc: 0.768239\n",
      "[390]\ttraining's auc: 0.788593\tvalid_1's auc: 0.76827\n",
      "[391]\ttraining's auc: 0.788687\tvalid_1's auc: 0.76834\n",
      "[392]\ttraining's auc: 0.78876\tvalid_1's auc: 0.768385\n",
      "[393]\ttraining's auc: 0.788839\tvalid_1's auc: 0.768422\n",
      "[394]\ttraining's auc: 0.788955\tvalid_1's auc: 0.768518\n",
      "[395]\ttraining's auc: 0.789033\tvalid_1's auc: 0.768562\n",
      "[396]\ttraining's auc: 0.789103\tvalid_1's auc: 0.768584\n",
      "[397]\ttraining's auc: 0.789166\tvalid_1's auc: 0.768627\n",
      "[398]\ttraining's auc: 0.789241\tvalid_1's auc: 0.76867\n",
      "[399]\ttraining's auc: 0.789317\tvalid_1's auc: 0.768725\n",
      "[400]\ttraining's auc: 0.789393\tvalid_1's auc: 0.768768\n",
      "[401]\ttraining's auc: 0.789465\tvalid_1's auc: 0.7688\n",
      "[402]\ttraining's auc: 0.789535\tvalid_1's auc: 0.768847\n",
      "[403]\ttraining's auc: 0.789607\tvalid_1's auc: 0.768884\n",
      "[404]\ttraining's auc: 0.789672\tvalid_1's auc: 0.768908\n",
      "[405]\ttraining's auc: 0.789754\tvalid_1's auc: 0.76895\n",
      "[406]\ttraining's auc: 0.789816\tvalid_1's auc: 0.768972\n",
      "[407]\ttraining's auc: 0.789891\tvalid_1's auc: 0.769021\n",
      "[408]\ttraining's auc: 0.790007\tvalid_1's auc: 0.769083\n",
      "[409]\ttraining's auc: 0.79009\tvalid_1's auc: 0.769137\n",
      "[410]\ttraining's auc: 0.790189\tvalid_1's auc: 0.769215\n",
      "[411]\ttraining's auc: 0.790274\tvalid_1's auc: 0.769248\n",
      "[412]\ttraining's auc: 0.790362\tvalid_1's auc: 0.769296\n",
      "[413]\ttraining's auc: 0.790433\tvalid_1's auc: 0.769346\n",
      "[414]\ttraining's auc: 0.790511\tvalid_1's auc: 0.769383\n",
      "[415]\ttraining's auc: 0.79058\tvalid_1's auc: 0.769407\n",
      "[416]\ttraining's auc: 0.790645\tvalid_1's auc: 0.769433\n",
      "[417]\ttraining's auc: 0.790712\tvalid_1's auc: 0.769477\n",
      "[418]\ttraining's auc: 0.790775\tvalid_1's auc: 0.769488\n",
      "[419]\ttraining's auc: 0.790871\tvalid_1's auc: 0.769544\n",
      "[420]\ttraining's auc: 0.790935\tvalid_1's auc: 0.769564\n",
      "[421]\ttraining's auc: 0.791006\tvalid_1's auc: 0.769604\n",
      "[422]\ttraining's auc: 0.791113\tvalid_1's auc: 0.769659\n",
      "[423]\ttraining's auc: 0.791221\tvalid_1's auc: 0.769738\n",
      "[424]\ttraining's auc: 0.79129\tvalid_1's auc: 0.769775\n",
      "[425]\ttraining's auc: 0.79137\tvalid_1's auc: 0.769823\n",
      "[426]\ttraining's auc: 0.791441\tvalid_1's auc: 0.769846\n",
      "[427]\ttraining's auc: 0.791507\tvalid_1's auc: 0.769882\n",
      "[428]\ttraining's auc: 0.791574\tvalid_1's auc: 0.769897\n",
      "[429]\ttraining's auc: 0.791645\tvalid_1's auc: 0.769912\n",
      "[430]\ttraining's auc: 0.79174\tvalid_1's auc: 0.769995\n",
      "[431]\ttraining's auc: 0.791799\tvalid_1's auc: 0.770024\n",
      "[432]\ttraining's auc: 0.791865\tvalid_1's auc: 0.770061\n",
      "[433]\ttraining's auc: 0.791927\tvalid_1's auc: 0.7701\n",
      "[434]\ttraining's auc: 0.792013\tvalid_1's auc: 0.77014\n",
      "[435]\ttraining's auc: 0.792073\tvalid_1's auc: 0.77017\n",
      "[436]\ttraining's auc: 0.79214\tvalid_1's auc: 0.770196\n",
      "[437]\ttraining's auc: 0.792234\tvalid_1's auc: 0.770267\n",
      "[438]\ttraining's auc: 0.792326\tvalid_1's auc: 0.770338\n",
      "[439]\ttraining's auc: 0.792404\tvalid_1's auc: 0.770381\n",
      "[440]\ttraining's auc: 0.792466\tvalid_1's auc: 0.770404\n",
      "[441]\ttraining's auc: 0.792529\tvalid_1's auc: 0.770434\n",
      "[442]\ttraining's auc: 0.792635\tvalid_1's auc: 0.770505\n",
      "[443]\ttraining's auc: 0.792694\tvalid_1's auc: 0.770536\n",
      "[444]\ttraining's auc: 0.792767\tvalid_1's auc: 0.770572\n",
      "[445]\ttraining's auc: 0.792822\tvalid_1's auc: 0.770591\n",
      "[446]\ttraining's auc: 0.792935\tvalid_1's auc: 0.770672\n",
      "[447]\ttraining's auc: 0.792992\tvalid_1's auc: 0.770702\n",
      "[448]\ttraining's auc: 0.79306\tvalid_1's auc: 0.770737\n",
      "[449]\ttraining's auc: 0.793133\tvalid_1's auc: 0.770771\n",
      "[450]\ttraining's auc: 0.793192\tvalid_1's auc: 0.770809\n",
      "[451]\ttraining's auc: 0.793281\tvalid_1's auc: 0.770852\n",
      "[452]\ttraining's auc: 0.793356\tvalid_1's auc: 0.770895\n",
      "[453]\ttraining's auc: 0.793451\tvalid_1's auc: 0.770944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[454]\ttraining's auc: 0.793541\tvalid_1's auc: 0.771004\n",
      "[455]\ttraining's auc: 0.793596\tvalid_1's auc: 0.771027\n",
      "[456]\ttraining's auc: 0.793658\tvalid_1's auc: 0.771048\n",
      "[457]\ttraining's auc: 0.793715\tvalid_1's auc: 0.771065\n",
      "[458]\ttraining's auc: 0.793763\tvalid_1's auc: 0.771069\n",
      "[459]\ttraining's auc: 0.793815\tvalid_1's auc: 0.771087\n",
      "[460]\ttraining's auc: 0.793869\tvalid_1's auc: 0.771097\n",
      "[461]\ttraining's auc: 0.793954\tvalid_1's auc: 0.771156\n",
      "[462]\ttraining's auc: 0.794018\tvalid_1's auc: 0.771181\n",
      "[463]\ttraining's auc: 0.794092\tvalid_1's auc: 0.771219\n",
      "[464]\ttraining's auc: 0.794148\tvalid_1's auc: 0.771236\n",
      "[465]\ttraining's auc: 0.794239\tvalid_1's auc: 0.771301\n",
      "[466]\ttraining's auc: 0.79431\tvalid_1's auc: 0.771332\n",
      "[467]\ttraining's auc: 0.794361\tvalid_1's auc: 0.771358\n",
      "[468]\ttraining's auc: 0.794425\tvalid_1's auc: 0.771371\n",
      "[469]\ttraining's auc: 0.7945\tvalid_1's auc: 0.771405\n",
      "[470]\ttraining's auc: 0.794578\tvalid_1's auc: 0.771431\n",
      "[471]\ttraining's auc: 0.794654\tvalid_1's auc: 0.77147\n",
      "[472]\ttraining's auc: 0.79474\tvalid_1's auc: 0.771509\n",
      "[473]\ttraining's auc: 0.794788\tvalid_1's auc: 0.771532\n",
      "[474]\ttraining's auc: 0.794848\tvalid_1's auc: 0.771554\n",
      "[475]\ttraining's auc: 0.794914\tvalid_1's auc: 0.771584\n",
      "[476]\ttraining's auc: 0.794959\tvalid_1's auc: 0.7716\n",
      "[477]\ttraining's auc: 0.795047\tvalid_1's auc: 0.771645\n",
      "[478]\ttraining's auc: 0.795114\tvalid_1's auc: 0.771663\n",
      "[479]\ttraining's auc: 0.795192\tvalid_1's auc: 0.771696\n",
      "[480]\ttraining's auc: 0.795245\tvalid_1's auc: 0.77172\n",
      "[481]\ttraining's auc: 0.795314\tvalid_1's auc: 0.771746\n",
      "[482]\ttraining's auc: 0.79541\tvalid_1's auc: 0.771824\n",
      "[483]\ttraining's auc: 0.795473\tvalid_1's auc: 0.771861\n",
      "[484]\ttraining's auc: 0.79556\tvalid_1's auc: 0.771933\n",
      "[485]\ttraining's auc: 0.795621\tvalid_1's auc: 0.771963\n",
      "[486]\ttraining's auc: 0.795716\tvalid_1's auc: 0.77202\n",
      "[487]\ttraining's auc: 0.795785\tvalid_1's auc: 0.772057\n",
      "[488]\ttraining's auc: 0.795849\tvalid_1's auc: 0.772074\n",
      "[489]\ttraining's auc: 0.795914\tvalid_1's auc: 0.772101\n",
      "[490]\ttraining's auc: 0.795976\tvalid_1's auc: 0.772126\n",
      "[491]\ttraining's auc: 0.796027\tvalid_1's auc: 0.772136\n",
      "[492]\ttraining's auc: 0.7961\tvalid_1's auc: 0.772174\n",
      "[493]\ttraining's auc: 0.796173\tvalid_1's auc: 0.772228\n",
      "[494]\ttraining's auc: 0.796246\tvalid_1's auc: 0.772268\n",
      "[495]\ttraining's auc: 0.796309\tvalid_1's auc: 0.772304\n",
      "[496]\ttraining's auc: 0.79637\tvalid_1's auc: 0.772326\n",
      "[497]\ttraining's auc: 0.79644\tvalid_1's auc: 0.772367\n",
      "[498]\ttraining's auc: 0.796521\tvalid_1's auc: 0.772427\n",
      "[499]\ttraining's auc: 0.796575\tvalid_1's auc: 0.77244\n",
      "[500]\ttraining's auc: 0.79664\tvalid_1's auc: 0.772483\n",
      "[501]\ttraining's auc: 0.796699\tvalid_1's auc: 0.772514\n",
      "[502]\ttraining's auc: 0.796764\tvalid_1's auc: 0.772553\n",
      "[503]\ttraining's auc: 0.796823\tvalid_1's auc: 0.772583\n",
      "[504]\ttraining's auc: 0.796877\tvalid_1's auc: 0.772586\n",
      "[505]\ttraining's auc: 0.79696\tvalid_1's auc: 0.77263\n",
      "[506]\ttraining's auc: 0.797053\tvalid_1's auc: 0.772691\n",
      "[507]\ttraining's auc: 0.797102\tvalid_1's auc: 0.772715\n",
      "[508]\ttraining's auc: 0.797176\tvalid_1's auc: 0.772739\n",
      "[509]\ttraining's auc: 0.79724\tvalid_1's auc: 0.772769\n",
      "[510]\ttraining's auc: 0.797295\tvalid_1's auc: 0.772803\n",
      "[511]\ttraining's auc: 0.797359\tvalid_1's auc: 0.772838\n",
      "[512]\ttraining's auc: 0.797412\tvalid_1's auc: 0.772852\n",
      "[513]\ttraining's auc: 0.797468\tvalid_1's auc: 0.772874\n",
      "[514]\ttraining's auc: 0.797522\tvalid_1's auc: 0.772904\n",
      "[515]\ttraining's auc: 0.797579\tvalid_1's auc: 0.772936\n",
      "[516]\ttraining's auc: 0.797652\tvalid_1's auc: 0.772983\n",
      "[517]\ttraining's auc: 0.797724\tvalid_1's auc: 0.773013\n",
      "[518]\ttraining's auc: 0.797788\tvalid_1's auc: 0.77304\n",
      "[519]\ttraining's auc: 0.797863\tvalid_1's auc: 0.773087\n",
      "[520]\ttraining's auc: 0.797912\tvalid_1's auc: 0.773113\n",
      "[521]\ttraining's auc: 0.797982\tvalid_1's auc: 0.773146\n",
      "[522]\ttraining's auc: 0.798036\tvalid_1's auc: 0.773166\n",
      "[523]\ttraining's auc: 0.798107\tvalid_1's auc: 0.773208\n",
      "[524]\ttraining's auc: 0.798168\tvalid_1's auc: 0.773238\n",
      "[525]\ttraining's auc: 0.798242\tvalid_1's auc: 0.773273\n",
      "[526]\ttraining's auc: 0.798302\tvalid_1's auc: 0.773294\n",
      "[527]\ttraining's auc: 0.798364\tvalid_1's auc: 0.77333\n",
      "[528]\ttraining's auc: 0.798412\tvalid_1's auc: 0.773344\n",
      "[529]\ttraining's auc: 0.798481\tvalid_1's auc: 0.773378\n",
      "[530]\ttraining's auc: 0.79855\tvalid_1's auc: 0.773417\n",
      "[531]\ttraining's auc: 0.798593\tvalid_1's auc: 0.773424\n",
      "[532]\ttraining's auc: 0.798641\tvalid_1's auc: 0.773446\n",
      "[533]\ttraining's auc: 0.798715\tvalid_1's auc: 0.773484\n",
      "[534]\ttraining's auc: 0.798796\tvalid_1's auc: 0.773543\n",
      "[535]\ttraining's auc: 0.798863\tvalid_1's auc: 0.773569\n",
      "[536]\ttraining's auc: 0.798935\tvalid_1's auc: 0.773601\n",
      "[537]\ttraining's auc: 0.798995\tvalid_1's auc: 0.773618\n",
      "[538]\ttraining's auc: 0.79905\tvalid_1's auc: 0.773662\n",
      "[539]\ttraining's auc: 0.799093\tvalid_1's auc: 0.773677\n",
      "[540]\ttraining's auc: 0.799145\tvalid_1's auc: 0.773693\n",
      "[541]\ttraining's auc: 0.799196\tvalid_1's auc: 0.77371\n",
      "[542]\ttraining's auc: 0.799276\tvalid_1's auc: 0.773767\n",
      "[543]\ttraining's auc: 0.799336\tvalid_1's auc: 0.773798\n",
      "[544]\ttraining's auc: 0.799385\tvalid_1's auc: 0.773824\n",
      "[545]\ttraining's auc: 0.799478\tvalid_1's auc: 0.77389\n",
      "[546]\ttraining's auc: 0.799536\tvalid_1's auc: 0.773917\n",
      "[547]\ttraining's auc: 0.79959\tvalid_1's auc: 0.773948\n",
      "[548]\ttraining's auc: 0.799638\tvalid_1's auc: 0.773967\n",
      "[549]\ttraining's auc: 0.799701\tvalid_1's auc: 0.774002\n",
      "[550]\ttraining's auc: 0.799775\tvalid_1's auc: 0.774055\n",
      "[551]\ttraining's auc: 0.79983\tvalid_1's auc: 0.774071\n",
      "[552]\ttraining's auc: 0.799883\tvalid_1's auc: 0.774094\n",
      "[553]\ttraining's auc: 0.799929\tvalid_1's auc: 0.774102\n",
      "[554]\ttraining's auc: 0.799975\tvalid_1's auc: 0.774116\n",
      "[555]\ttraining's auc: 0.800046\tvalid_1's auc: 0.774142\n",
      "[556]\ttraining's auc: 0.800106\tvalid_1's auc: 0.774156\n",
      "[557]\ttraining's auc: 0.800163\tvalid_1's auc: 0.774186\n",
      "[558]\ttraining's auc: 0.800249\tvalid_1's auc: 0.774239\n",
      "[559]\ttraining's auc: 0.800311\tvalid_1's auc: 0.77428\n",
      "[560]\ttraining's auc: 0.800378\tvalid_1's auc: 0.774317\n",
      "[561]\ttraining's auc: 0.800445\tvalid_1's auc: 0.774355\n",
      "[562]\ttraining's auc: 0.800509\tvalid_1's auc: 0.774394\n",
      "[563]\ttraining's auc: 0.800571\tvalid_1's auc: 0.774422\n",
      "[564]\ttraining's auc: 0.800622\tvalid_1's auc: 0.774437\n",
      "[565]\ttraining's auc: 0.8007\tvalid_1's auc: 0.774473\n",
      "[566]\ttraining's auc: 0.800749\tvalid_1's auc: 0.774496\n",
      "[567]\ttraining's auc: 0.800804\tvalid_1's auc: 0.774513\n",
      "[568]\ttraining's auc: 0.800853\tvalid_1's auc: 0.774525\n",
      "[569]\ttraining's auc: 0.800899\tvalid_1's auc: 0.774542\n",
      "[570]\ttraining's auc: 0.800978\tvalid_1's auc: 0.774612\n",
      "[571]\ttraining's auc: 0.801031\tvalid_1's auc: 0.774638\n",
      "[572]\ttraining's auc: 0.80109\tvalid_1's auc: 0.774668\n",
      "[573]\ttraining's auc: 0.80115\tvalid_1's auc: 0.774683\n",
      "[574]\ttraining's auc: 0.8012\tvalid_1's auc: 0.774717\n",
      "[575]\ttraining's auc: 0.801258\tvalid_1's auc: 0.774735\n",
      "[576]\ttraining's auc: 0.80132\tvalid_1's auc: 0.774764\n",
      "[577]\ttraining's auc: 0.801385\tvalid_1's auc: 0.774802\n",
      "[578]\ttraining's auc: 0.801438\tvalid_1's auc: 0.774827\n",
      "[579]\ttraining's auc: 0.801494\tvalid_1's auc: 0.774855\n",
      "[580]\ttraining's auc: 0.801555\tvalid_1's auc: 0.77487\n",
      "[581]\ttraining's auc: 0.801624\tvalid_1's auc: 0.774915\n",
      "[582]\ttraining's auc: 0.801692\tvalid_1's auc: 0.774951\n",
      "[583]\ttraining's auc: 0.801758\tvalid_1's auc: 0.774985\n",
      "[584]\ttraining's auc: 0.801817\tvalid_1's auc: 0.775014\n",
      "[585]\ttraining's auc: 0.801865\tvalid_1's auc: 0.775027\n",
      "[586]\ttraining's auc: 0.801911\tvalid_1's auc: 0.775042\n",
      "[587]\ttraining's auc: 0.80197\tvalid_1's auc: 0.775063\n",
      "[588]\ttraining's auc: 0.802009\tvalid_1's auc: 0.775085\n",
      "[589]\ttraining's auc: 0.802059\tvalid_1's auc: 0.775099\n",
      "[590]\ttraining's auc: 0.802107\tvalid_1's auc: 0.775124\n",
      "[591]\ttraining's auc: 0.802162\tvalid_1's auc: 0.775144\n",
      "[592]\ttraining's auc: 0.80222\tvalid_1's auc: 0.775164\n",
      "[593]\ttraining's auc: 0.802267\tvalid_1's auc: 0.775179\n",
      "[594]\ttraining's auc: 0.802314\tvalid_1's auc: 0.775187\n",
      "[595]\ttraining's auc: 0.802367\tvalid_1's auc: 0.775209\n",
      "[596]\ttraining's auc: 0.802425\tvalid_1's auc: 0.77524\n",
      "[597]\ttraining's auc: 0.802482\tvalid_1's auc: 0.775258\n",
      "[598]\ttraining's auc: 0.80254\tvalid_1's auc: 0.775279\n",
      "[599]\ttraining's auc: 0.802606\tvalid_1's auc: 0.775306\n",
      "[600]\ttraining's auc: 0.802656\tvalid_1's auc: 0.775324\n",
      "[601]\ttraining's auc: 0.80271\tvalid_1's auc: 0.77533\n",
      "[602]\ttraining's auc: 0.802759\tvalid_1's auc: 0.775349\n",
      "[603]\ttraining's auc: 0.802814\tvalid_1's auc: 0.775369\n",
      "[604]\ttraining's auc: 0.802857\tvalid_1's auc: 0.775377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[605]\ttraining's auc: 0.802935\tvalid_1's auc: 0.775411\n",
      "[606]\ttraining's auc: 0.803002\tvalid_1's auc: 0.775432\n",
      "[607]\ttraining's auc: 0.803062\tvalid_1's auc: 0.775456\n",
      "[608]\ttraining's auc: 0.803112\tvalid_1's auc: 0.775465\n",
      "[609]\ttraining's auc: 0.803173\tvalid_1's auc: 0.775488\n",
      "[610]\ttraining's auc: 0.803239\tvalid_1's auc: 0.775514\n",
      "[611]\ttraining's auc: 0.803288\tvalid_1's auc: 0.77553\n",
      "[612]\ttraining's auc: 0.803334\tvalid_1's auc: 0.775548\n",
      "[613]\ttraining's auc: 0.803387\tvalid_1's auc: 0.775574\n",
      "[614]\ttraining's auc: 0.803441\tvalid_1's auc: 0.775595\n",
      "[615]\ttraining's auc: 0.803492\tvalid_1's auc: 0.775605\n",
      "[616]\ttraining's auc: 0.803531\tvalid_1's auc: 0.775604\n",
      "[617]\ttraining's auc: 0.803587\tvalid_1's auc: 0.775631\n",
      "[618]\ttraining's auc: 0.803653\tvalid_1's auc: 0.775687\n",
      "[619]\ttraining's auc: 0.803707\tvalid_1's auc: 0.775709\n",
      "[620]\ttraining's auc: 0.803764\tvalid_1's auc: 0.775748\n",
      "[621]\ttraining's auc: 0.803833\tvalid_1's auc: 0.775793\n",
      "[622]\ttraining's auc: 0.803886\tvalid_1's auc: 0.775811\n",
      "[623]\ttraining's auc: 0.803946\tvalid_1's auc: 0.775829\n",
      "[624]\ttraining's auc: 0.80399\tvalid_1's auc: 0.775851\n",
      "[625]\ttraining's auc: 0.804041\tvalid_1's auc: 0.77587\n",
      "[626]\ttraining's auc: 0.8041\tvalid_1's auc: 0.775894\n",
      "[627]\ttraining's auc: 0.80415\tvalid_1's auc: 0.775909\n",
      "[628]\ttraining's auc: 0.804222\tvalid_1's auc: 0.775952\n",
      "[629]\ttraining's auc: 0.804267\tvalid_1's auc: 0.775971\n",
      "[630]\ttraining's auc: 0.804329\tvalid_1's auc: 0.775995\n",
      "[631]\ttraining's auc: 0.804399\tvalid_1's auc: 0.776021\n",
      "[632]\ttraining's auc: 0.804459\tvalid_1's auc: 0.776034\n",
      "[633]\ttraining's auc: 0.804511\tvalid_1's auc: 0.776047\n",
      "[634]\ttraining's auc: 0.804575\tvalid_1's auc: 0.776097\n",
      "[635]\ttraining's auc: 0.80464\tvalid_1's auc: 0.776129\n",
      "[636]\ttraining's auc: 0.804695\tvalid_1's auc: 0.776146\n",
      "[637]\ttraining's auc: 0.804762\tvalid_1's auc: 0.776198\n",
      "[638]\ttraining's auc: 0.80482\tvalid_1's auc: 0.776237\n",
      "[639]\ttraining's auc: 0.804878\tvalid_1's auc: 0.776257\n",
      "[640]\ttraining's auc: 0.804932\tvalid_1's auc: 0.776268\n",
      "[641]\ttraining's auc: 0.804994\tvalid_1's auc: 0.776292\n",
      "[642]\ttraining's auc: 0.805058\tvalid_1's auc: 0.776303\n",
      "[643]\ttraining's auc: 0.805113\tvalid_1's auc: 0.776327\n",
      "[644]\ttraining's auc: 0.805172\tvalid_1's auc: 0.776354\n",
      "[645]\ttraining's auc: 0.805227\tvalid_1's auc: 0.776383\n",
      "[646]\ttraining's auc: 0.805273\tvalid_1's auc: 0.776401\n",
      "[647]\ttraining's auc: 0.805326\tvalid_1's auc: 0.776415\n",
      "[648]\ttraining's auc: 0.805376\tvalid_1's auc: 0.776433\n",
      "[649]\ttraining's auc: 0.805434\tvalid_1's auc: 0.776448\n",
      "[650]\ttraining's auc: 0.805504\tvalid_1's auc: 0.776492\n",
      "[651]\ttraining's auc: 0.805561\tvalid_1's auc: 0.776511\n",
      "[652]\ttraining's auc: 0.805626\tvalid_1's auc: 0.776566\n",
      "[653]\ttraining's auc: 0.805671\tvalid_1's auc: 0.776588\n",
      "[654]\ttraining's auc: 0.805738\tvalid_1's auc: 0.776619\n",
      "[655]\ttraining's auc: 0.805803\tvalid_1's auc: 0.776638\n",
      "[656]\ttraining's auc: 0.805855\tvalid_1's auc: 0.77666\n",
      "[657]\ttraining's auc: 0.80591\tvalid_1's auc: 0.776678\n",
      "[658]\ttraining's auc: 0.805971\tvalid_1's auc: 0.776726\n",
      "[659]\ttraining's auc: 0.806019\tvalid_1's auc: 0.776758\n",
      "[660]\ttraining's auc: 0.806062\tvalid_1's auc: 0.776765\n",
      "[661]\ttraining's auc: 0.806115\tvalid_1's auc: 0.77677\n",
      "[662]\ttraining's auc: 0.806167\tvalid_1's auc: 0.776785\n",
      "[663]\ttraining's auc: 0.806215\tvalid_1's auc: 0.7768\n",
      "[664]\ttraining's auc: 0.806267\tvalid_1's auc: 0.77682\n",
      "[665]\ttraining's auc: 0.806317\tvalid_1's auc: 0.776841\n",
      "[666]\ttraining's auc: 0.806362\tvalid_1's auc: 0.776852\n",
      "[667]\ttraining's auc: 0.806415\tvalid_1's auc: 0.776868\n",
      "[668]\ttraining's auc: 0.806479\tvalid_1's auc: 0.776888\n",
      "[669]\ttraining's auc: 0.806527\tvalid_1's auc: 0.776911\n",
      "[670]\ttraining's auc: 0.806586\tvalid_1's auc: 0.776968\n",
      "[671]\ttraining's auc: 0.806652\tvalid_1's auc: 0.777006\n",
      "[672]\ttraining's auc: 0.806707\tvalid_1's auc: 0.777029\n",
      "[673]\ttraining's auc: 0.806766\tvalid_1's auc: 0.777051\n",
      "[674]\ttraining's auc: 0.806816\tvalid_1's auc: 0.777064\n",
      "[675]\ttraining's auc: 0.806873\tvalid_1's auc: 0.777088\n",
      "[676]\ttraining's auc: 0.806919\tvalid_1's auc: 0.777096\n",
      "[677]\ttraining's auc: 0.806962\tvalid_1's auc: 0.777104\n",
      "[678]\ttraining's auc: 0.80702\tvalid_1's auc: 0.777114\n",
      "[679]\ttraining's auc: 0.807075\tvalid_1's auc: 0.777137\n",
      "[680]\ttraining's auc: 0.807126\tvalid_1's auc: 0.777139\n",
      "[681]\ttraining's auc: 0.807182\tvalid_1's auc: 0.777149\n",
      "[682]\ttraining's auc: 0.807232\tvalid_1's auc: 0.777157\n",
      "[683]\ttraining's auc: 0.807281\tvalid_1's auc: 0.77717\n",
      "[684]\ttraining's auc: 0.807344\tvalid_1's auc: 0.77719\n",
      "[685]\ttraining's auc: 0.807381\tvalid_1's auc: 0.777206\n",
      "[686]\ttraining's auc: 0.807449\tvalid_1's auc: 0.777225\n",
      "[687]\ttraining's auc: 0.807498\tvalid_1's auc: 0.77724\n",
      "[688]\ttraining's auc: 0.807545\tvalid_1's auc: 0.777256\n",
      "[689]\ttraining's auc: 0.807604\tvalid_1's auc: 0.777284\n",
      "[690]\ttraining's auc: 0.807656\tvalid_1's auc: 0.777308\n",
      "[691]\ttraining's auc: 0.807728\tvalid_1's auc: 0.777348\n",
      "[692]\ttraining's auc: 0.807788\tvalid_1's auc: 0.777374\n",
      "[693]\ttraining's auc: 0.807844\tvalid_1's auc: 0.777399\n",
      "[694]\ttraining's auc: 0.807906\tvalid_1's auc: 0.777451\n",
      "[695]\ttraining's auc: 0.807961\tvalid_1's auc: 0.777472\n",
      "[696]\ttraining's auc: 0.808001\tvalid_1's auc: 0.777482\n",
      "[697]\ttraining's auc: 0.808063\tvalid_1's auc: 0.777511\n",
      "[698]\ttraining's auc: 0.808097\tvalid_1's auc: 0.777516\n",
      "[699]\ttraining's auc: 0.808147\tvalid_1's auc: 0.777533\n",
      "[700]\ttraining's auc: 0.808191\tvalid_1's auc: 0.777548\n",
      "[701]\ttraining's auc: 0.808247\tvalid_1's auc: 0.77757\n",
      "[702]\ttraining's auc: 0.808301\tvalid_1's auc: 0.777582\n",
      "[703]\ttraining's auc: 0.808363\tvalid_1's auc: 0.777604\n",
      "[704]\ttraining's auc: 0.808416\tvalid_1's auc: 0.777628\n",
      "[705]\ttraining's auc: 0.808469\tvalid_1's auc: 0.777649\n",
      "[706]\ttraining's auc: 0.808521\tvalid_1's auc: 0.777659\n",
      "[707]\ttraining's auc: 0.808579\tvalid_1's auc: 0.777691\n",
      "[708]\ttraining's auc: 0.808624\tvalid_1's auc: 0.777714\n",
      "[709]\ttraining's auc: 0.808667\tvalid_1's auc: 0.777722\n",
      "[710]\ttraining's auc: 0.808707\tvalid_1's auc: 0.777731\n",
      "[711]\ttraining's auc: 0.808751\tvalid_1's auc: 0.777746\n",
      "[712]\ttraining's auc: 0.808799\tvalid_1's auc: 0.777756\n",
      "[713]\ttraining's auc: 0.808861\tvalid_1's auc: 0.777787\n",
      "[714]\ttraining's auc: 0.808907\tvalid_1's auc: 0.777793\n",
      "[715]\ttraining's auc: 0.808964\tvalid_1's auc: 0.777811\n",
      "[716]\ttraining's auc: 0.809016\tvalid_1's auc: 0.777838\n",
      "[717]\ttraining's auc: 0.80907\tvalid_1's auc: 0.777856\n",
      "[718]\ttraining's auc: 0.809122\tvalid_1's auc: 0.777871\n",
      "[719]\ttraining's auc: 0.809174\tvalid_1's auc: 0.777881\n",
      "[720]\ttraining's auc: 0.809222\tvalid_1's auc: 0.77789\n",
      "[721]\ttraining's auc: 0.809268\tvalid_1's auc: 0.777911\n",
      "[722]\ttraining's auc: 0.809316\tvalid_1's auc: 0.777933\n",
      "[723]\ttraining's auc: 0.809368\tvalid_1's auc: 0.777958\n",
      "[724]\ttraining's auc: 0.809415\tvalid_1's auc: 0.777975\n",
      "[725]\ttraining's auc: 0.809474\tvalid_1's auc: 0.777997\n",
      "[726]\ttraining's auc: 0.809519\tvalid_1's auc: 0.778011\n",
      "[727]\ttraining's auc: 0.809566\tvalid_1's auc: 0.77802\n",
      "[728]\ttraining's auc: 0.809612\tvalid_1's auc: 0.77804\n",
      "[729]\ttraining's auc: 0.80967\tvalid_1's auc: 0.778073\n",
      "[730]\ttraining's auc: 0.809718\tvalid_1's auc: 0.778086\n",
      "[731]\ttraining's auc: 0.80977\tvalid_1's auc: 0.778115\n",
      "[732]\ttraining's auc: 0.809811\tvalid_1's auc: 0.778125\n",
      "[733]\ttraining's auc: 0.809853\tvalid_1's auc: 0.778144\n",
      "[734]\ttraining's auc: 0.809914\tvalid_1's auc: 0.778183\n",
      "[735]\ttraining's auc: 0.809958\tvalid_1's auc: 0.778189\n",
      "[736]\ttraining's auc: 0.810026\tvalid_1's auc: 0.778204\n",
      "[737]\ttraining's auc: 0.810071\tvalid_1's auc: 0.778214\n",
      "[738]\ttraining's auc: 0.810128\tvalid_1's auc: 0.778259\n",
      "[739]\ttraining's auc: 0.810172\tvalid_1's auc: 0.77826\n",
      "[740]\ttraining's auc: 0.810221\tvalid_1's auc: 0.778274\n",
      "[741]\ttraining's auc: 0.810285\tvalid_1's auc: 0.778328\n",
      "[742]\ttraining's auc: 0.810348\tvalid_1's auc: 0.778352\n",
      "[743]\ttraining's auc: 0.81041\tvalid_1's auc: 0.778392\n",
      "[744]\ttraining's auc: 0.810469\tvalid_1's auc: 0.778407\n",
      "[745]\ttraining's auc: 0.810519\tvalid_1's auc: 0.778425\n",
      "[746]\ttraining's auc: 0.810574\tvalid_1's auc: 0.778447\n",
      "[747]\ttraining's auc: 0.810631\tvalid_1's auc: 0.778472\n",
      "[748]\ttraining's auc: 0.810689\tvalid_1's auc: 0.778489\n",
      "[749]\ttraining's auc: 0.810743\tvalid_1's auc: 0.778521\n",
      "[750]\ttraining's auc: 0.810779\tvalid_1's auc: 0.778533\n",
      "[751]\ttraining's auc: 0.810821\tvalid_1's auc: 0.778554\n",
      "[752]\ttraining's auc: 0.810858\tvalid_1's auc: 0.778559\n",
      "[753]\ttraining's auc: 0.810904\tvalid_1's auc: 0.778576\n",
      "[754]\ttraining's auc: 0.810948\tvalid_1's auc: 0.778577\n",
      "[755]\ttraining's auc: 0.810996\tvalid_1's auc: 0.778599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[756]\ttraining's auc: 0.811046\tvalid_1's auc: 0.778617\n",
      "[757]\ttraining's auc: 0.811101\tvalid_1's auc: 0.778624\n",
      "[758]\ttraining's auc: 0.811141\tvalid_1's auc: 0.778647\n",
      "[759]\ttraining's auc: 0.811201\tvalid_1's auc: 0.778667\n",
      "[760]\ttraining's auc: 0.81125\tvalid_1's auc: 0.778687\n",
      "[761]\ttraining's auc: 0.811292\tvalid_1's auc: 0.778703\n",
      "[762]\ttraining's auc: 0.811346\tvalid_1's auc: 0.77872\n",
      "[763]\ttraining's auc: 0.811405\tvalid_1's auc: 0.778749\n",
      "[764]\ttraining's auc: 0.811442\tvalid_1's auc: 0.778757\n",
      "[765]\ttraining's auc: 0.811493\tvalid_1's auc: 0.77879\n",
      "[766]\ttraining's auc: 0.81155\tvalid_1's auc: 0.778811\n",
      "[767]\ttraining's auc: 0.811615\tvalid_1's auc: 0.778839\n",
      "[768]\ttraining's auc: 0.811663\tvalid_1's auc: 0.778847\n",
      "[769]\ttraining's auc: 0.811709\tvalid_1's auc: 0.778866\n",
      "[770]\ttraining's auc: 0.811752\tvalid_1's auc: 0.778881\n",
      "[771]\ttraining's auc: 0.811805\tvalid_1's auc: 0.778914\n",
      "[772]\ttraining's auc: 0.811866\tvalid_1's auc: 0.778955\n",
      "[773]\ttraining's auc: 0.811926\tvalid_1's auc: 0.778987\n",
      "[774]\ttraining's auc: 0.811981\tvalid_1's auc: 0.779\n",
      "[775]\ttraining's auc: 0.812032\tvalid_1's auc: 0.779013\n",
      "[776]\ttraining's auc: 0.812071\tvalid_1's auc: 0.779023\n",
      "[777]\ttraining's auc: 0.812119\tvalid_1's auc: 0.779033\n",
      "[778]\ttraining's auc: 0.812169\tvalid_1's auc: 0.779051\n",
      "[779]\ttraining's auc: 0.812216\tvalid_1's auc: 0.779057\n",
      "[780]\ttraining's auc: 0.81226\tvalid_1's auc: 0.779069\n",
      "[781]\ttraining's auc: 0.812307\tvalid_1's auc: 0.779093\n",
      "[782]\ttraining's auc: 0.812353\tvalid_1's auc: 0.77911\n",
      "[783]\ttraining's auc: 0.812404\tvalid_1's auc: 0.779128\n",
      "[784]\ttraining's auc: 0.812444\tvalid_1's auc: 0.779133\n",
      "[785]\ttraining's auc: 0.812495\tvalid_1's auc: 0.779148\n",
      "[786]\ttraining's auc: 0.812545\tvalid_1's auc: 0.779162\n",
      "[787]\ttraining's auc: 0.812598\tvalid_1's auc: 0.779175\n",
      "[788]\ttraining's auc: 0.812648\tvalid_1's auc: 0.779186\n",
      "[789]\ttraining's auc: 0.812691\tvalid_1's auc: 0.7792\n",
      "[790]\ttraining's auc: 0.812728\tvalid_1's auc: 0.77921\n",
      "[791]\ttraining's auc: 0.812778\tvalid_1's auc: 0.779226\n",
      "[792]\ttraining's auc: 0.812828\tvalid_1's auc: 0.779256\n",
      "[793]\ttraining's auc: 0.81288\tvalid_1's auc: 0.779275\n",
      "[794]\ttraining's auc: 0.812927\tvalid_1's auc: 0.779277\n",
      "[795]\ttraining's auc: 0.812986\tvalid_1's auc: 0.779296\n",
      "[796]\ttraining's auc: 0.81303\tvalid_1's auc: 0.779313\n",
      "[797]\ttraining's auc: 0.813072\tvalid_1's auc: 0.779322\n",
      "[798]\ttraining's auc: 0.813121\tvalid_1's auc: 0.779336\n",
      "[799]\ttraining's auc: 0.813171\tvalid_1's auc: 0.779351\n",
      "[800]\ttraining's auc: 0.81322\tvalid_1's auc: 0.779374\n",
      "[801]\ttraining's auc: 0.813269\tvalid_1's auc: 0.779386\n",
      "[802]\ttraining's auc: 0.813316\tvalid_1's auc: 0.7794\n",
      "[803]\ttraining's auc: 0.813357\tvalid_1's auc: 0.779407\n",
      "[804]\ttraining's auc: 0.813407\tvalid_1's auc: 0.779433\n",
      "[805]\ttraining's auc: 0.813448\tvalid_1's auc: 0.779441\n",
      "[806]\ttraining's auc: 0.813502\tvalid_1's auc: 0.779461\n",
      "[807]\ttraining's auc: 0.813549\tvalid_1's auc: 0.779486\n",
      "[808]\ttraining's auc: 0.813605\tvalid_1's auc: 0.77951\n",
      "[809]\ttraining's auc: 0.813657\tvalid_1's auc: 0.779541\n",
      "[810]\ttraining's auc: 0.813706\tvalid_1's auc: 0.77955\n",
      "[811]\ttraining's auc: 0.813752\tvalid_1's auc: 0.779561\n",
      "[812]\ttraining's auc: 0.813794\tvalid_1's auc: 0.779576\n",
      "[813]\ttraining's auc: 0.813838\tvalid_1's auc: 0.779594\n",
      "[814]\ttraining's auc: 0.813877\tvalid_1's auc: 0.779606\n",
      "[815]\ttraining's auc: 0.813928\tvalid_1's auc: 0.779613\n",
      "[816]\ttraining's auc: 0.813978\tvalid_1's auc: 0.779631\n",
      "[817]\ttraining's auc: 0.81404\tvalid_1's auc: 0.779664\n",
      "[818]\ttraining's auc: 0.814086\tvalid_1's auc: 0.779681\n",
      "[819]\ttraining's auc: 0.814134\tvalid_1's auc: 0.779695\n",
      "[820]\ttraining's auc: 0.814182\tvalid_1's auc: 0.779712\n",
      "[821]\ttraining's auc: 0.814226\tvalid_1's auc: 0.779728\n",
      "[822]\ttraining's auc: 0.81428\tvalid_1's auc: 0.779736\n",
      "[823]\ttraining's auc: 0.814332\tvalid_1's auc: 0.779752\n",
      "[824]\ttraining's auc: 0.814369\tvalid_1's auc: 0.779751\n",
      "[825]\ttraining's auc: 0.81442\tvalid_1's auc: 0.779766\n",
      "[826]\ttraining's auc: 0.814468\tvalid_1's auc: 0.779791\n",
      "[827]\ttraining's auc: 0.814516\tvalid_1's auc: 0.779814\n",
      "[828]\ttraining's auc: 0.814565\tvalid_1's auc: 0.779823\n",
      "[829]\ttraining's auc: 0.814608\tvalid_1's auc: 0.779839\n",
      "[830]\ttraining's auc: 0.814662\tvalid_1's auc: 0.779848\n",
      "[831]\ttraining's auc: 0.814711\tvalid_1's auc: 0.779874\n",
      "[832]\ttraining's auc: 0.814748\tvalid_1's auc: 0.779885\n",
      "[833]\ttraining's auc: 0.814781\tvalid_1's auc: 0.779905\n",
      "[834]\ttraining's auc: 0.814843\tvalid_1's auc: 0.77993\n",
      "[835]\ttraining's auc: 0.81489\tvalid_1's auc: 0.779935\n",
      "[836]\ttraining's auc: 0.814948\tvalid_1's auc: 0.779957\n",
      "[837]\ttraining's auc: 0.81499\tvalid_1's auc: 0.779969\n",
      "[838]\ttraining's auc: 0.815047\tvalid_1's auc: 0.779993\n",
      "[839]\ttraining's auc: 0.8151\tvalid_1's auc: 0.780009\n",
      "[840]\ttraining's auc: 0.815155\tvalid_1's auc: 0.780026\n",
      "[841]\ttraining's auc: 0.815202\tvalid_1's auc: 0.780033\n",
      "[842]\ttraining's auc: 0.815249\tvalid_1's auc: 0.780057\n",
      "[843]\ttraining's auc: 0.815289\tvalid_1's auc: 0.780057\n",
      "[844]\ttraining's auc: 0.815339\tvalid_1's auc: 0.780066\n",
      "[845]\ttraining's auc: 0.815383\tvalid_1's auc: 0.780083\n",
      "[846]\ttraining's auc: 0.81544\tvalid_1's auc: 0.780096\n",
      "[847]\ttraining's auc: 0.815489\tvalid_1's auc: 0.780108\n",
      "[848]\ttraining's auc: 0.815532\tvalid_1's auc: 0.780115\n",
      "[849]\ttraining's auc: 0.815571\tvalid_1's auc: 0.780123\n",
      "[850]\ttraining's auc: 0.815626\tvalid_1's auc: 0.780139\n",
      "[851]\ttraining's auc: 0.815679\tvalid_1's auc: 0.780164\n",
      "[852]\ttraining's auc: 0.815727\tvalid_1's auc: 0.780182\n",
      "[853]\ttraining's auc: 0.815787\tvalid_1's auc: 0.780212\n",
      "[854]\ttraining's auc: 0.815842\tvalid_1's auc: 0.780231\n",
      "[855]\ttraining's auc: 0.815881\tvalid_1's auc: 0.780247\n",
      "[856]\ttraining's auc: 0.815925\tvalid_1's auc: 0.780262\n",
      "[857]\ttraining's auc: 0.815974\tvalid_1's auc: 0.780271\n",
      "[858]\ttraining's auc: 0.816015\tvalid_1's auc: 0.78029\n",
      "[859]\ttraining's auc: 0.816058\tvalid_1's auc: 0.780293\n",
      "[860]\ttraining's auc: 0.816116\tvalid_1's auc: 0.78031\n",
      "[861]\ttraining's auc: 0.816158\tvalid_1's auc: 0.780326\n",
      "[862]\ttraining's auc: 0.816207\tvalid_1's auc: 0.780346\n",
      "[863]\ttraining's auc: 0.816266\tvalid_1's auc: 0.780371\n",
      "[864]\ttraining's auc: 0.816308\tvalid_1's auc: 0.780375\n",
      "[865]\ttraining's auc: 0.816357\tvalid_1's auc: 0.780375\n",
      "[866]\ttraining's auc: 0.816401\tvalid_1's auc: 0.780386\n",
      "[867]\ttraining's auc: 0.816443\tvalid_1's auc: 0.780398\n",
      "[868]\ttraining's auc: 0.816489\tvalid_1's auc: 0.780412\n",
      "[869]\ttraining's auc: 0.81653\tvalid_1's auc: 0.780439\n",
      "[870]\ttraining's auc: 0.816579\tvalid_1's auc: 0.780461\n",
      "[871]\ttraining's auc: 0.816616\tvalid_1's auc: 0.780479\n",
      "[872]\ttraining's auc: 0.816659\tvalid_1's auc: 0.780495\n",
      "[873]\ttraining's auc: 0.816701\tvalid_1's auc: 0.780499\n",
      "[874]\ttraining's auc: 0.816758\tvalid_1's auc: 0.780515\n",
      "[875]\ttraining's auc: 0.816811\tvalid_1's auc: 0.780531\n",
      "[876]\ttraining's auc: 0.816858\tvalid_1's auc: 0.78054\n",
      "[877]\ttraining's auc: 0.816899\tvalid_1's auc: 0.780564\n",
      "[878]\ttraining's auc: 0.816944\tvalid_1's auc: 0.780593\n",
      "[879]\ttraining's auc: 0.816987\tvalid_1's auc: 0.780604\n",
      "[880]\ttraining's auc: 0.817033\tvalid_1's auc: 0.780609\n",
      "[881]\ttraining's auc: 0.817068\tvalid_1's auc: 0.780629\n",
      "[882]\ttraining's auc: 0.817118\tvalid_1's auc: 0.780658\n",
      "[883]\ttraining's auc: 0.817155\tvalid_1's auc: 0.780672\n",
      "[884]\ttraining's auc: 0.817194\tvalid_1's auc: 0.780681\n",
      "[885]\ttraining's auc: 0.817238\tvalid_1's auc: 0.780688\n",
      "[886]\ttraining's auc: 0.817284\tvalid_1's auc: 0.780693\n",
      "[887]\ttraining's auc: 0.817337\tvalid_1's auc: 0.780704\n",
      "[888]\ttraining's auc: 0.817365\tvalid_1's auc: 0.780708\n",
      "[889]\ttraining's auc: 0.817414\tvalid_1's auc: 0.780721\n",
      "[890]\ttraining's auc: 0.817466\tvalid_1's auc: 0.780734\n",
      "[891]\ttraining's auc: 0.817513\tvalid_1's auc: 0.780751\n",
      "[892]\ttraining's auc: 0.817564\tvalid_1's auc: 0.780772\n",
      "[893]\ttraining's auc: 0.817606\tvalid_1's auc: 0.780786\n",
      "[894]\ttraining's auc: 0.817651\tvalid_1's auc: 0.780794\n",
      "[895]\ttraining's auc: 0.817698\tvalid_1's auc: 0.780828\n",
      "[896]\ttraining's auc: 0.817746\tvalid_1's auc: 0.780839\n",
      "[897]\ttraining's auc: 0.8178\tvalid_1's auc: 0.780853\n",
      "[898]\ttraining's auc: 0.817841\tvalid_1's auc: 0.780863\n",
      "[899]\ttraining's auc: 0.817891\tvalid_1's auc: 0.780898\n",
      "[900]\ttraining's auc: 0.817935\tvalid_1's auc: 0.780925\n",
      "[901]\ttraining's auc: 0.817982\tvalid_1's auc: 0.78094\n",
      "[902]\ttraining's auc: 0.818023\tvalid_1's auc: 0.780948\n",
      "[903]\ttraining's auc: 0.818064\tvalid_1's auc: 0.780959\n",
      "[904]\ttraining's auc: 0.818111\tvalid_1's auc: 0.780959\n",
      "[905]\ttraining's auc: 0.818151\tvalid_1's auc: 0.78099\n",
      "[906]\ttraining's auc: 0.818189\tvalid_1's auc: 0.781012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[907]\ttraining's auc: 0.818223\tvalid_1's auc: 0.781011\n",
      "[908]\ttraining's auc: 0.818258\tvalid_1's auc: 0.781011\n",
      "[909]\ttraining's auc: 0.818302\tvalid_1's auc: 0.781027\n",
      "[910]\ttraining's auc: 0.818346\tvalid_1's auc: 0.781043\n",
      "[911]\ttraining's auc: 0.818388\tvalid_1's auc: 0.781049\n",
      "[912]\ttraining's auc: 0.818432\tvalid_1's auc: 0.781064\n",
      "[913]\ttraining's auc: 0.818473\tvalid_1's auc: 0.781094\n",
      "[914]\ttraining's auc: 0.81852\tvalid_1's auc: 0.781104\n",
      "[915]\ttraining's auc: 0.81857\tvalid_1's auc: 0.78111\n",
      "[916]\ttraining's auc: 0.818608\tvalid_1's auc: 0.781129\n",
      "[917]\ttraining's auc: 0.818651\tvalid_1's auc: 0.78114\n",
      "[918]\ttraining's auc: 0.818699\tvalid_1's auc: 0.781158\n",
      "[919]\ttraining's auc: 0.818747\tvalid_1's auc: 0.781162\n",
      "[920]\ttraining's auc: 0.818797\tvalid_1's auc: 0.781177\n",
      "[921]\ttraining's auc: 0.818838\tvalid_1's auc: 0.781197\n",
      "[922]\ttraining's auc: 0.81888\tvalid_1's auc: 0.781209\n",
      "[923]\ttraining's auc: 0.818923\tvalid_1's auc: 0.781226\n",
      "[924]\ttraining's auc: 0.818968\tvalid_1's auc: 0.781226\n",
      "[925]\ttraining's auc: 0.819012\tvalid_1's auc: 0.781235\n",
      "[926]\ttraining's auc: 0.819061\tvalid_1's auc: 0.781241\n",
      "[927]\ttraining's auc: 0.819111\tvalid_1's auc: 0.78125\n",
      "[928]\ttraining's auc: 0.819168\tvalid_1's auc: 0.781261\n",
      "[929]\ttraining's auc: 0.81921\tvalid_1's auc: 0.781274\n",
      "[930]\ttraining's auc: 0.819248\tvalid_1's auc: 0.781284\n",
      "[931]\ttraining's auc: 0.819296\tvalid_1's auc: 0.781301\n",
      "[932]\ttraining's auc: 0.819338\tvalid_1's auc: 0.781318\n",
      "[933]\ttraining's auc: 0.819379\tvalid_1's auc: 0.781328\n",
      "[934]\ttraining's auc: 0.819416\tvalid_1's auc: 0.781333\n",
      "[935]\ttraining's auc: 0.819461\tvalid_1's auc: 0.781346\n",
      "[936]\ttraining's auc: 0.819498\tvalid_1's auc: 0.781352\n",
      "[937]\ttraining's auc: 0.819539\tvalid_1's auc: 0.781374\n",
      "[938]\ttraining's auc: 0.81957\tvalid_1's auc: 0.781373\n",
      "[939]\ttraining's auc: 0.819615\tvalid_1's auc: 0.781379\n",
      "[940]\ttraining's auc: 0.819652\tvalid_1's auc: 0.781375\n",
      "[941]\ttraining's auc: 0.819693\tvalid_1's auc: 0.781384\n",
      "[942]\ttraining's auc: 0.819729\tvalid_1's auc: 0.781389\n",
      "[943]\ttraining's auc: 0.81977\tvalid_1's auc: 0.781407\n",
      "[944]\ttraining's auc: 0.819813\tvalid_1's auc: 0.781417\n",
      "[945]\ttraining's auc: 0.81985\tvalid_1's auc: 0.781427\n",
      "[946]\ttraining's auc: 0.819896\tvalid_1's auc: 0.781445\n",
      "[947]\ttraining's auc: 0.819931\tvalid_1's auc: 0.781458\n",
      "[948]\ttraining's auc: 0.819975\tvalid_1's auc: 0.781467\n",
      "[949]\ttraining's auc: 0.820013\tvalid_1's auc: 0.781471\n",
      "[950]\ttraining's auc: 0.82007\tvalid_1's auc: 0.781492\n",
      "[951]\ttraining's auc: 0.820106\tvalid_1's auc: 0.781499\n",
      "[952]\ttraining's auc: 0.820152\tvalid_1's auc: 0.781513\n",
      "[953]\ttraining's auc: 0.820191\tvalid_1's auc: 0.781519\n",
      "[954]\ttraining's auc: 0.82023\tvalid_1's auc: 0.781527\n",
      "[955]\ttraining's auc: 0.820265\tvalid_1's auc: 0.781541\n",
      "[956]\ttraining's auc: 0.820298\tvalid_1's auc: 0.781549\n",
      "[957]\ttraining's auc: 0.820341\tvalid_1's auc: 0.781561\n",
      "[958]\ttraining's auc: 0.82039\tvalid_1's auc: 0.781569\n",
      "[959]\ttraining's auc: 0.820434\tvalid_1's auc: 0.781581\n",
      "[960]\ttraining's auc: 0.820476\tvalid_1's auc: 0.781596\n",
      "[961]\ttraining's auc: 0.820514\tvalid_1's auc: 0.781605\n",
      "[962]\ttraining's auc: 0.820544\tvalid_1's auc: 0.781629\n",
      "[963]\ttraining's auc: 0.820585\tvalid_1's auc: 0.78164\n",
      "[964]\ttraining's auc: 0.82063\tvalid_1's auc: 0.781652\n",
      "[965]\ttraining's auc: 0.820671\tvalid_1's auc: 0.781666\n",
      "[966]\ttraining's auc: 0.820713\tvalid_1's auc: 0.781675\n",
      "[967]\ttraining's auc: 0.820761\tvalid_1's auc: 0.781694\n",
      "[968]\ttraining's auc: 0.820812\tvalid_1's auc: 0.781715\n",
      "[969]\ttraining's auc: 0.820855\tvalid_1's auc: 0.781723\n",
      "[970]\ttraining's auc: 0.820901\tvalid_1's auc: 0.78173\n",
      "[971]\ttraining's auc: 0.820946\tvalid_1's auc: 0.781743\n",
      "[972]\ttraining's auc: 0.820985\tvalid_1's auc: 0.781752\n",
      "[973]\ttraining's auc: 0.821034\tvalid_1's auc: 0.781771\n",
      "[974]\ttraining's auc: 0.821078\tvalid_1's auc: 0.781782\n",
      "[975]\ttraining's auc: 0.821129\tvalid_1's auc: 0.781789\n",
      "[976]\ttraining's auc: 0.821166\tvalid_1's auc: 0.781802\n",
      "[977]\ttraining's auc: 0.821217\tvalid_1's auc: 0.781842\n",
      "[978]\ttraining's auc: 0.821278\tvalid_1's auc: 0.781858\n",
      "[979]\ttraining's auc: 0.821323\tvalid_1's auc: 0.781864\n",
      "[980]\ttraining's auc: 0.821363\tvalid_1's auc: 0.781876\n",
      "[981]\ttraining's auc: 0.821409\tvalid_1's auc: 0.781881\n",
      "[982]\ttraining's auc: 0.821455\tvalid_1's auc: 0.781887\n",
      "[983]\ttraining's auc: 0.821504\tvalid_1's auc: 0.781895\n",
      "[984]\ttraining's auc: 0.821541\tvalid_1's auc: 0.781901\n",
      "[985]\ttraining's auc: 0.821585\tvalid_1's auc: 0.781906\n",
      "[986]\ttraining's auc: 0.821624\tvalid_1's auc: 0.781932\n",
      "[987]\ttraining's auc: 0.821667\tvalid_1's auc: 0.781938\n",
      "[988]\ttraining's auc: 0.821708\tvalid_1's auc: 0.781953\n",
      "[989]\ttraining's auc: 0.82175\tvalid_1's auc: 0.781966\n",
      "[990]\ttraining's auc: 0.821793\tvalid_1's auc: 0.781984\n",
      "[991]\ttraining's auc: 0.821841\tvalid_1's auc: 0.78201\n",
      "[992]\ttraining's auc: 0.821882\tvalid_1's auc: 0.782022\n",
      "[993]\ttraining's auc: 0.821936\tvalid_1's auc: 0.782039\n",
      "[994]\ttraining's auc: 0.821967\tvalid_1's auc: 0.782047\n",
      "[995]\ttraining's auc: 0.822003\tvalid_1's auc: 0.782059\n",
      "[996]\ttraining's auc: 0.82204\tvalid_1's auc: 0.782069\n",
      "[997]\ttraining's auc: 0.822071\tvalid_1's auc: 0.78207\n",
      "[998]\ttraining's auc: 0.822122\tvalid_1's auc: 0.782085\n",
      "[999]\ttraining's auc: 0.822168\tvalid_1's auc: 0.782094\n",
      "[1000]\ttraining's auc: 0.822217\tvalid_1's auc: 0.782106\n",
      "[1001]\ttraining's auc: 0.822257\tvalid_1's auc: 0.782111\n",
      "[1002]\ttraining's auc: 0.822303\tvalid_1's auc: 0.782127\n",
      "[1003]\ttraining's auc: 0.822347\tvalid_1's auc: 0.782142\n",
      "[1004]\ttraining's auc: 0.822392\tvalid_1's auc: 0.782167\n",
      "[1005]\ttraining's auc: 0.822439\tvalid_1's auc: 0.782176\n",
      "[1006]\ttraining's auc: 0.822485\tvalid_1's auc: 0.782181\n",
      "[1007]\ttraining's auc: 0.822517\tvalid_1's auc: 0.782196\n",
      "[1008]\ttraining's auc: 0.822562\tvalid_1's auc: 0.782213\n",
      "[1009]\ttraining's auc: 0.822609\tvalid_1's auc: 0.782234\n",
      "[1010]\ttraining's auc: 0.822652\tvalid_1's auc: 0.782244\n",
      "[1011]\ttraining's auc: 0.822705\tvalid_1's auc: 0.782248\n",
      "[1012]\ttraining's auc: 0.822747\tvalid_1's auc: 0.782258\n",
      "[1013]\ttraining's auc: 0.822797\tvalid_1's auc: 0.782265\n",
      "[1014]\ttraining's auc: 0.822846\tvalid_1's auc: 0.782274\n",
      "[1015]\ttraining's auc: 0.822886\tvalid_1's auc: 0.782286\n",
      "[1016]\ttraining's auc: 0.822924\tvalid_1's auc: 0.7823\n",
      "[1017]\ttraining's auc: 0.822966\tvalid_1's auc: 0.782322\n",
      "[1018]\ttraining's auc: 0.822995\tvalid_1's auc: 0.782321\n",
      "[1019]\ttraining's auc: 0.82303\tvalid_1's auc: 0.782342\n",
      "[1020]\ttraining's auc: 0.823075\tvalid_1's auc: 0.782354\n",
      "[1021]\ttraining's auc: 0.823112\tvalid_1's auc: 0.782375\n",
      "[1022]\ttraining's auc: 0.823154\tvalid_1's auc: 0.782379\n",
      "[1023]\ttraining's auc: 0.823198\tvalid_1's auc: 0.78239\n",
      "[1024]\ttraining's auc: 0.823239\tvalid_1's auc: 0.782397\n",
      "[1025]\ttraining's auc: 0.823285\tvalid_1's auc: 0.782399\n",
      "[1026]\ttraining's auc: 0.823324\tvalid_1's auc: 0.78242\n",
      "[1027]\ttraining's auc: 0.823371\tvalid_1's auc: 0.782432\n",
      "[1028]\ttraining's auc: 0.823406\tvalid_1's auc: 0.782439\n",
      "[1029]\ttraining's auc: 0.823446\tvalid_1's auc: 0.782451\n",
      "[1030]\ttraining's auc: 0.823491\tvalid_1's auc: 0.782462\n",
      "[1031]\ttraining's auc: 0.823536\tvalid_1's auc: 0.782465\n",
      "[1032]\ttraining's auc: 0.823572\tvalid_1's auc: 0.782477\n",
      "[1033]\ttraining's auc: 0.823599\tvalid_1's auc: 0.782491\n",
      "[1034]\ttraining's auc: 0.823643\tvalid_1's auc: 0.782502\n",
      "[1035]\ttraining's auc: 0.82368\tvalid_1's auc: 0.782529\n",
      "[1036]\ttraining's auc: 0.823716\tvalid_1's auc: 0.782536\n",
      "[1037]\ttraining's auc: 0.823745\tvalid_1's auc: 0.782541\n",
      "[1038]\ttraining's auc: 0.8238\tvalid_1's auc: 0.782561\n",
      "[1039]\ttraining's auc: 0.823855\tvalid_1's auc: 0.782576\n",
      "[1040]\ttraining's auc: 0.823893\tvalid_1's auc: 0.782574\n",
      "[1041]\ttraining's auc: 0.823933\tvalid_1's auc: 0.782595\n",
      "[1042]\ttraining's auc: 0.82398\tvalid_1's auc: 0.782602\n",
      "[1043]\ttraining's auc: 0.824015\tvalid_1's auc: 0.782617\n",
      "[1044]\ttraining's auc: 0.824051\tvalid_1's auc: 0.782623\n",
      "[1045]\ttraining's auc: 0.824092\tvalid_1's auc: 0.782625\n",
      "[1046]\ttraining's auc: 0.824125\tvalid_1's auc: 0.782654\n",
      "[1047]\ttraining's auc: 0.824161\tvalid_1's auc: 0.78267\n",
      "[1048]\ttraining's auc: 0.824201\tvalid_1's auc: 0.782678\n",
      "[1049]\ttraining's auc: 0.824236\tvalid_1's auc: 0.782691\n",
      "[1050]\ttraining's auc: 0.824274\tvalid_1's auc: 0.782702\n",
      "[1051]\ttraining's auc: 0.824312\tvalid_1's auc: 0.782703\n",
      "[1052]\ttraining's auc: 0.824353\tvalid_1's auc: 0.782707\n",
      "[1053]\ttraining's auc: 0.82439\tvalid_1's auc: 0.782721\n",
      "[1054]\ttraining's auc: 0.824433\tvalid_1's auc: 0.782747\n",
      "[1055]\ttraining's auc: 0.824473\tvalid_1's auc: 0.782754\n",
      "[1056]\ttraining's auc: 0.824509\tvalid_1's auc: 0.782767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1057]\ttraining's auc: 0.824545\tvalid_1's auc: 0.782771\n",
      "[1058]\ttraining's auc: 0.824585\tvalid_1's auc: 0.782792\n",
      "[1059]\ttraining's auc: 0.824631\tvalid_1's auc: 0.782802\n",
      "[1060]\ttraining's auc: 0.824671\tvalid_1's auc: 0.782823\n",
      "[1061]\ttraining's auc: 0.824719\tvalid_1's auc: 0.782835\n",
      "[1062]\ttraining's auc: 0.824758\tvalid_1's auc: 0.782842\n",
      "[1063]\ttraining's auc: 0.824801\tvalid_1's auc: 0.782859\n",
      "[1064]\ttraining's auc: 0.824843\tvalid_1's auc: 0.782874\n",
      "[1065]\ttraining's auc: 0.824887\tvalid_1's auc: 0.782887\n",
      "[1066]\ttraining's auc: 0.824926\tvalid_1's auc: 0.782906\n",
      "[1067]\ttraining's auc: 0.824966\tvalid_1's auc: 0.782917\n",
      "[1068]\ttraining's auc: 0.825003\tvalid_1's auc: 0.782926\n",
      "[1069]\ttraining's auc: 0.825045\tvalid_1's auc: 0.782939\n",
      "[1070]\ttraining's auc: 0.825089\tvalid_1's auc: 0.782956\n",
      "[1071]\ttraining's auc: 0.825131\tvalid_1's auc: 0.782958\n",
      "[1072]\ttraining's auc: 0.825169\tvalid_1's auc: 0.782965\n",
      "[1073]\ttraining's auc: 0.825211\tvalid_1's auc: 0.782979\n",
      "[1074]\ttraining's auc: 0.825243\tvalid_1's auc: 0.782988\n",
      "[1075]\ttraining's auc: 0.825281\tvalid_1's auc: 0.782999\n",
      "[1076]\ttraining's auc: 0.825325\tvalid_1's auc: 0.783012\n",
      "[1077]\ttraining's auc: 0.825363\tvalid_1's auc: 0.783024\n",
      "[1078]\ttraining's auc: 0.825403\tvalid_1's auc: 0.783033\n",
      "[1079]\ttraining's auc: 0.825444\tvalid_1's auc: 0.78304\n",
      "[1080]\ttraining's auc: 0.825476\tvalid_1's auc: 0.783051\n",
      "[1081]\ttraining's auc: 0.82551\tvalid_1's auc: 0.78306\n",
      "[1082]\ttraining's auc: 0.825556\tvalid_1's auc: 0.783067\n",
      "[1083]\ttraining's auc: 0.8256\tvalid_1's auc: 0.78308\n",
      "[1084]\ttraining's auc: 0.825647\tvalid_1's auc: 0.783084\n",
      "[1085]\ttraining's auc: 0.825679\tvalid_1's auc: 0.78309\n",
      "[1086]\ttraining's auc: 0.825721\tvalid_1's auc: 0.783106\n",
      "[1087]\ttraining's auc: 0.825767\tvalid_1's auc: 0.783118\n",
      "[1088]\ttraining's auc: 0.825807\tvalid_1's auc: 0.783126\n",
      "[1089]\ttraining's auc: 0.825847\tvalid_1's auc: 0.783133\n",
      "[1090]\ttraining's auc: 0.825885\tvalid_1's auc: 0.783139\n",
      "[1091]\ttraining's auc: 0.82593\tvalid_1's auc: 0.783155\n",
      "[1092]\ttraining's auc: 0.825959\tvalid_1's auc: 0.783166\n",
      "[1093]\ttraining's auc: 0.825997\tvalid_1's auc: 0.783173\n",
      "[1094]\ttraining's auc: 0.826027\tvalid_1's auc: 0.783179\n",
      "[1095]\ttraining's auc: 0.826058\tvalid_1's auc: 0.783185\n",
      "[1096]\ttraining's auc: 0.826089\tvalid_1's auc: 0.783192\n",
      "[1097]\ttraining's auc: 0.826132\tvalid_1's auc: 0.783202\n",
      "[1098]\ttraining's auc: 0.826166\tvalid_1's auc: 0.783209\n",
      "[1099]\ttraining's auc: 0.826194\tvalid_1's auc: 0.783219\n",
      "[1100]\ttraining's auc: 0.826227\tvalid_1's auc: 0.783241\n",
      "[1101]\ttraining's auc: 0.826263\tvalid_1's auc: 0.783257\n",
      "[1102]\ttraining's auc: 0.826307\tvalid_1's auc: 0.783273\n",
      "[1103]\ttraining's auc: 0.826362\tvalid_1's auc: 0.783289\n",
      "[1104]\ttraining's auc: 0.826411\tvalid_1's auc: 0.783294\n",
      "[1105]\ttraining's auc: 0.826456\tvalid_1's auc: 0.7833\n",
      "[1106]\ttraining's auc: 0.826481\tvalid_1's auc: 0.783316\n",
      "[1107]\ttraining's auc: 0.826532\tvalid_1's auc: 0.783325\n",
      "[1108]\ttraining's auc: 0.826568\tvalid_1's auc: 0.783339\n",
      "[1109]\ttraining's auc: 0.826613\tvalid_1's auc: 0.783352\n",
      "[1110]\ttraining's auc: 0.826659\tvalid_1's auc: 0.783366\n",
      "[1111]\ttraining's auc: 0.826698\tvalid_1's auc: 0.783367\n",
      "[1112]\ttraining's auc: 0.826745\tvalid_1's auc: 0.783379\n",
      "[1113]\ttraining's auc: 0.826794\tvalid_1's auc: 0.783394\n",
      "[1114]\ttraining's auc: 0.826829\tvalid_1's auc: 0.783404\n",
      "[1115]\ttraining's auc: 0.826875\tvalid_1's auc: 0.783413\n",
      "[1116]\ttraining's auc: 0.826911\tvalid_1's auc: 0.783426\n",
      "[1117]\ttraining's auc: 0.826956\tvalid_1's auc: 0.783432\n",
      "[1118]\ttraining's auc: 0.826997\tvalid_1's auc: 0.78344\n",
      "[1119]\ttraining's auc: 0.827035\tvalid_1's auc: 0.783451\n",
      "[1120]\ttraining's auc: 0.827073\tvalid_1's auc: 0.783447\n",
      "[1121]\ttraining's auc: 0.827106\tvalid_1's auc: 0.783462\n",
      "[1122]\ttraining's auc: 0.827148\tvalid_1's auc: 0.783465\n",
      "[1123]\ttraining's auc: 0.827187\tvalid_1's auc: 0.783474\n",
      "[1124]\ttraining's auc: 0.827233\tvalid_1's auc: 0.783474\n",
      "[1125]\ttraining's auc: 0.827262\tvalid_1's auc: 0.783488\n",
      "[1126]\ttraining's auc: 0.82729\tvalid_1's auc: 0.783489\n",
      "[1127]\ttraining's auc: 0.827333\tvalid_1's auc: 0.783503\n",
      "[1128]\ttraining's auc: 0.827374\tvalid_1's auc: 0.783515\n",
      "[1129]\ttraining's auc: 0.827413\tvalid_1's auc: 0.783527\n",
      "[1130]\ttraining's auc: 0.827453\tvalid_1's auc: 0.783545\n",
      "[1131]\ttraining's auc: 0.827494\tvalid_1's auc: 0.783561\n",
      "[1132]\ttraining's auc: 0.827541\tvalid_1's auc: 0.783576\n",
      "[1133]\ttraining's auc: 0.827569\tvalid_1's auc: 0.783585\n",
      "[1134]\ttraining's auc: 0.827618\tvalid_1's auc: 0.783603\n",
      "[1135]\ttraining's auc: 0.827661\tvalid_1's auc: 0.783614\n",
      "[1136]\ttraining's auc: 0.827708\tvalid_1's auc: 0.783638\n",
      "[1137]\ttraining's auc: 0.827742\tvalid_1's auc: 0.783659\n",
      "[1138]\ttraining's auc: 0.827781\tvalid_1's auc: 0.783656\n",
      "[1139]\ttraining's auc: 0.827815\tvalid_1's auc: 0.78366\n",
      "[1140]\ttraining's auc: 0.827859\tvalid_1's auc: 0.783675\n",
      "[1141]\ttraining's auc: 0.82791\tvalid_1's auc: 0.783696\n",
      "[1142]\ttraining's auc: 0.827951\tvalid_1's auc: 0.783701\n",
      "[1143]\ttraining's auc: 0.827971\tvalid_1's auc: 0.783703\n",
      "[1144]\ttraining's auc: 0.828017\tvalid_1's auc: 0.783712\n",
      "[1145]\ttraining's auc: 0.828062\tvalid_1's auc: 0.783709\n",
      "[1146]\ttraining's auc: 0.828102\tvalid_1's auc: 0.783723\n",
      "[1147]\ttraining's auc: 0.828139\tvalid_1's auc: 0.783728\n",
      "[1148]\ttraining's auc: 0.828177\tvalid_1's auc: 0.783727\n",
      "[1149]\ttraining's auc: 0.828216\tvalid_1's auc: 0.78373\n",
      "[1150]\ttraining's auc: 0.828258\tvalid_1's auc: 0.783738\n",
      "[1151]\ttraining's auc: 0.828296\tvalid_1's auc: 0.783749\n",
      "[1152]\ttraining's auc: 0.828346\tvalid_1's auc: 0.783769\n",
      "[1153]\ttraining's auc: 0.828382\tvalid_1's auc: 0.783777\n",
      "[1154]\ttraining's auc: 0.828409\tvalid_1's auc: 0.78379\n",
      "[1155]\ttraining's auc: 0.828455\tvalid_1's auc: 0.783801\n",
      "[1156]\ttraining's auc: 0.828496\tvalid_1's auc: 0.783814\n",
      "[1157]\ttraining's auc: 0.828542\tvalid_1's auc: 0.783827\n",
      "[1158]\ttraining's auc: 0.828587\tvalid_1's auc: 0.783828\n",
      "[1159]\ttraining's auc: 0.82862\tvalid_1's auc: 0.783833\n",
      "[1160]\ttraining's auc: 0.828663\tvalid_1's auc: 0.783839\n",
      "[1161]\ttraining's auc: 0.828695\tvalid_1's auc: 0.783841\n",
      "[1162]\ttraining's auc: 0.82873\tvalid_1's auc: 0.783865\n",
      "[1163]\ttraining's auc: 0.828764\tvalid_1's auc: 0.783876\n",
      "[1164]\ttraining's auc: 0.828797\tvalid_1's auc: 0.783869\n",
      "[1165]\ttraining's auc: 0.828841\tvalid_1's auc: 0.783878\n",
      "[1166]\ttraining's auc: 0.828882\tvalid_1's auc: 0.783899\n",
      "[1167]\ttraining's auc: 0.828927\tvalid_1's auc: 0.78391\n",
      "[1168]\ttraining's auc: 0.828961\tvalid_1's auc: 0.783929\n",
      "[1169]\ttraining's auc: 0.828999\tvalid_1's auc: 0.783939\n",
      "[1170]\ttraining's auc: 0.829039\tvalid_1's auc: 0.783938\n",
      "[1171]\ttraining's auc: 0.829063\tvalid_1's auc: 0.783946\n",
      "[1172]\ttraining's auc: 0.829108\tvalid_1's auc: 0.783962\n",
      "[1173]\ttraining's auc: 0.829146\tvalid_1's auc: 0.783969\n",
      "[1174]\ttraining's auc: 0.829179\tvalid_1's auc: 0.783971\n",
      "[1175]\ttraining's auc: 0.829221\tvalid_1's auc: 0.783976\n",
      "[1176]\ttraining's auc: 0.82926\tvalid_1's auc: 0.783981\n",
      "[1177]\ttraining's auc: 0.82931\tvalid_1's auc: 0.783981\n",
      "[1178]\ttraining's auc: 0.829353\tvalid_1's auc: 0.783991\n",
      "[1179]\ttraining's auc: 0.829398\tvalid_1's auc: 0.784001\n",
      "[1180]\ttraining's auc: 0.829444\tvalid_1's auc: 0.784017\n",
      "[1181]\ttraining's auc: 0.829487\tvalid_1's auc: 0.784044\n",
      "[1182]\ttraining's auc: 0.829525\tvalid_1's auc: 0.784041\n",
      "[1183]\ttraining's auc: 0.829553\tvalid_1's auc: 0.784051\n",
      "[1184]\ttraining's auc: 0.82959\tvalid_1's auc: 0.784057\n",
      "[1185]\ttraining's auc: 0.829627\tvalid_1's auc: 0.784068\n",
      "[1186]\ttraining's auc: 0.829671\tvalid_1's auc: 0.784075\n",
      "[1187]\ttraining's auc: 0.829704\tvalid_1's auc: 0.784088\n",
      "[1188]\ttraining's auc: 0.829741\tvalid_1's auc: 0.784092\n",
      "[1189]\ttraining's auc: 0.829784\tvalid_1's auc: 0.784099\n",
      "[1190]\ttraining's auc: 0.82982\tvalid_1's auc: 0.784103\n",
      "[1191]\ttraining's auc: 0.829865\tvalid_1's auc: 0.784107\n",
      "[1192]\ttraining's auc: 0.829903\tvalid_1's auc: 0.784132\n",
      "[1193]\ttraining's auc: 0.829932\tvalid_1's auc: 0.784142\n",
      "[1194]\ttraining's auc: 0.829972\tvalid_1's auc: 0.78416\n",
      "[1195]\ttraining's auc: 0.83001\tvalid_1's auc: 0.78417\n",
      "[1196]\ttraining's auc: 0.830052\tvalid_1's auc: 0.784176\n",
      "[1197]\ttraining's auc: 0.830085\tvalid_1's auc: 0.784183\n",
      "[1198]\ttraining's auc: 0.830123\tvalid_1's auc: 0.784204\n",
      "[1199]\ttraining's auc: 0.830157\tvalid_1's auc: 0.784217\n",
      "[1200]\ttraining's auc: 0.830192\tvalid_1's auc: 0.78423\n",
      "[1201]\ttraining's auc: 0.830229\tvalid_1's auc: 0.784235\n",
      "[1202]\ttraining's auc: 0.830259\tvalid_1's auc: 0.784235\n",
      "[1203]\ttraining's auc: 0.830296\tvalid_1's auc: 0.78424\n",
      "[1204]\ttraining's auc: 0.83033\tvalid_1's auc: 0.784246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1205]\ttraining's auc: 0.830364\tvalid_1's auc: 0.784251\n",
      "[1206]\ttraining's auc: 0.830408\tvalid_1's auc: 0.784257\n",
      "[1207]\ttraining's auc: 0.830436\tvalid_1's auc: 0.784256\n",
      "[1208]\ttraining's auc: 0.830466\tvalid_1's auc: 0.784261\n",
      "[1209]\ttraining's auc: 0.830494\tvalid_1's auc: 0.784264\n",
      "[1210]\ttraining's auc: 0.830527\tvalid_1's auc: 0.784279\n",
      "[1211]\ttraining's auc: 0.830567\tvalid_1's auc: 0.78429\n",
      "[1212]\ttraining's auc: 0.830601\tvalid_1's auc: 0.784297\n",
      "[1213]\ttraining's auc: 0.830644\tvalid_1's auc: 0.784302\n",
      "[1214]\ttraining's auc: 0.830686\tvalid_1's auc: 0.784308\n",
      "[1215]\ttraining's auc: 0.830722\tvalid_1's auc: 0.784325\n",
      "[1216]\ttraining's auc: 0.830754\tvalid_1's auc: 0.784329\n",
      "[1217]\ttraining's auc: 0.830789\tvalid_1's auc: 0.784335\n",
      "[1218]\ttraining's auc: 0.83084\tvalid_1's auc: 0.78435\n",
      "[1219]\ttraining's auc: 0.830884\tvalid_1's auc: 0.784358\n",
      "[1220]\ttraining's auc: 0.830914\tvalid_1's auc: 0.784358\n",
      "[1221]\ttraining's auc: 0.830956\tvalid_1's auc: 0.784371\n",
      "[1222]\ttraining's auc: 0.830995\tvalid_1's auc: 0.784379\n",
      "[1223]\ttraining's auc: 0.831038\tvalid_1's auc: 0.78439\n",
      "[1224]\ttraining's auc: 0.831066\tvalid_1's auc: 0.7844\n",
      "[1225]\ttraining's auc: 0.831102\tvalid_1's auc: 0.784407\n",
      "[1226]\ttraining's auc: 0.831137\tvalid_1's auc: 0.784418\n",
      "[1227]\ttraining's auc: 0.831167\tvalid_1's auc: 0.784422\n",
      "[1228]\ttraining's auc: 0.831215\tvalid_1's auc: 0.784429\n",
      "[1229]\ttraining's auc: 0.831243\tvalid_1's auc: 0.784437\n",
      "[1230]\ttraining's auc: 0.831288\tvalid_1's auc: 0.78444\n",
      "[1231]\ttraining's auc: 0.83132\tvalid_1's auc: 0.78445\n",
      "[1232]\ttraining's auc: 0.831351\tvalid_1's auc: 0.784453\n",
      "[1233]\ttraining's auc: 0.831386\tvalid_1's auc: 0.784457\n",
      "[1234]\ttraining's auc: 0.83144\tvalid_1's auc: 0.784483\n",
      "[1235]\ttraining's auc: 0.831477\tvalid_1's auc: 0.784492\n",
      "[1236]\ttraining's auc: 0.83151\tvalid_1's auc: 0.784498\n",
      "[1237]\ttraining's auc: 0.831556\tvalid_1's auc: 0.784516\n",
      "[1238]\ttraining's auc: 0.831601\tvalid_1's auc: 0.784521\n",
      "[1239]\ttraining's auc: 0.831636\tvalid_1's auc: 0.784521\n",
      "[1240]\ttraining's auc: 0.83166\tvalid_1's auc: 0.784527\n",
      "[1241]\ttraining's auc: 0.831698\tvalid_1's auc: 0.784552\n",
      "[1242]\ttraining's auc: 0.831731\tvalid_1's auc: 0.784553\n",
      "[1243]\ttraining's auc: 0.831776\tvalid_1's auc: 0.784561\n",
      "[1244]\ttraining's auc: 0.831809\tvalid_1's auc: 0.784561\n",
      "[1245]\ttraining's auc: 0.831837\tvalid_1's auc: 0.784571\n",
      "[1246]\ttraining's auc: 0.831873\tvalid_1's auc: 0.784578\n",
      "[1247]\ttraining's auc: 0.831907\tvalid_1's auc: 0.784582\n",
      "[1248]\ttraining's auc: 0.831936\tvalid_1's auc: 0.784588\n",
      "[1249]\ttraining's auc: 0.831972\tvalid_1's auc: 0.784588\n",
      "[1250]\ttraining's auc: 0.832013\tvalid_1's auc: 0.78459\n",
      "[1251]\ttraining's auc: 0.832052\tvalid_1's auc: 0.784598\n",
      "[1252]\ttraining's auc: 0.832094\tvalid_1's auc: 0.784616\n",
      "[1253]\ttraining's auc: 0.832121\tvalid_1's auc: 0.784632\n",
      "[1254]\ttraining's auc: 0.832152\tvalid_1's auc: 0.784636\n",
      "[1255]\ttraining's auc: 0.83219\tvalid_1's auc: 0.78464\n",
      "[1256]\ttraining's auc: 0.832222\tvalid_1's auc: 0.784642\n",
      "[1257]\ttraining's auc: 0.832255\tvalid_1's auc: 0.784647\n",
      "[1258]\ttraining's auc: 0.832301\tvalid_1's auc: 0.784651\n",
      "[1259]\ttraining's auc: 0.832331\tvalid_1's auc: 0.784648\n",
      "[1260]\ttraining's auc: 0.832366\tvalid_1's auc: 0.784655\n",
      "[1261]\ttraining's auc: 0.832402\tvalid_1's auc: 0.784668\n",
      "[1262]\ttraining's auc: 0.832437\tvalid_1's auc: 0.784668\n",
      "[1263]\ttraining's auc: 0.83247\tvalid_1's auc: 0.784664\n",
      "[1264]\ttraining's auc: 0.832502\tvalid_1's auc: 0.784671\n",
      "[1265]\ttraining's auc: 0.832539\tvalid_1's auc: 0.78468\n",
      "[1266]\ttraining's auc: 0.832581\tvalid_1's auc: 0.784694\n",
      "[1267]\ttraining's auc: 0.832626\tvalid_1's auc: 0.7847\n",
      "[1268]\ttraining's auc: 0.832669\tvalid_1's auc: 0.784703\n",
      "[1269]\ttraining's auc: 0.832701\tvalid_1's auc: 0.784714\n",
      "[1270]\ttraining's auc: 0.832743\tvalid_1's auc: 0.78472\n",
      "[1271]\ttraining's auc: 0.832786\tvalid_1's auc: 0.784732\n",
      "[1272]\ttraining's auc: 0.832838\tvalid_1's auc: 0.784737\n",
      "[1273]\ttraining's auc: 0.832887\tvalid_1's auc: 0.784735\n",
      "[1274]\ttraining's auc: 0.832917\tvalid_1's auc: 0.784749\n",
      "[1275]\ttraining's auc: 0.832955\tvalid_1's auc: 0.784755\n",
      "[1276]\ttraining's auc: 0.832997\tvalid_1's auc: 0.784764\n",
      "[1277]\ttraining's auc: 0.83302\tvalid_1's auc: 0.784772\n",
      "[1278]\ttraining's auc: 0.833053\tvalid_1's auc: 0.784781\n",
      "[1279]\ttraining's auc: 0.833089\tvalid_1's auc: 0.784787\n",
      "[1280]\ttraining's auc: 0.833125\tvalid_1's auc: 0.784796\n",
      "[1281]\ttraining's auc: 0.833157\tvalid_1's auc: 0.784794\n",
      "[1282]\ttraining's auc: 0.833192\tvalid_1's auc: 0.784799\n",
      "[1283]\ttraining's auc: 0.833222\tvalid_1's auc: 0.784799\n",
      "[1284]\ttraining's auc: 0.833248\tvalid_1's auc: 0.784801\n",
      "[1285]\ttraining's auc: 0.83329\tvalid_1's auc: 0.784804\n",
      "[1286]\ttraining's auc: 0.833326\tvalid_1's auc: 0.784804\n",
      "[1287]\ttraining's auc: 0.833363\tvalid_1's auc: 0.784818\n",
      "[1288]\ttraining's auc: 0.8334\tvalid_1's auc: 0.784829\n",
      "[1289]\ttraining's auc: 0.833441\tvalid_1's auc: 0.784831\n",
      "[1290]\ttraining's auc: 0.833476\tvalid_1's auc: 0.784834\n",
      "[1291]\ttraining's auc: 0.833507\tvalid_1's auc: 0.784843\n",
      "[1292]\ttraining's auc: 0.833518\tvalid_1's auc: 0.784848\n",
      "[1293]\ttraining's auc: 0.833552\tvalid_1's auc: 0.784857\n",
      "[1294]\ttraining's auc: 0.833582\tvalid_1's auc: 0.784861\n",
      "[1295]\ttraining's auc: 0.83362\tvalid_1's auc: 0.784872\n",
      "[1296]\ttraining's auc: 0.833652\tvalid_1's auc: 0.784882\n",
      "[1297]\ttraining's auc: 0.833696\tvalid_1's auc: 0.784891\n",
      "[1298]\ttraining's auc: 0.833729\tvalid_1's auc: 0.784902\n",
      "[1299]\ttraining's auc: 0.833771\tvalid_1's auc: 0.784905\n",
      "[1300]\ttraining's auc: 0.833806\tvalid_1's auc: 0.784919\n",
      "[1301]\ttraining's auc: 0.833839\tvalid_1's auc: 0.784926\n",
      "[1302]\ttraining's auc: 0.833876\tvalid_1's auc: 0.784933\n",
      "[1303]\ttraining's auc: 0.833913\tvalid_1's auc: 0.784936\n",
      "[1304]\ttraining's auc: 0.833945\tvalid_1's auc: 0.784945\n",
      "[1305]\ttraining's auc: 0.833984\tvalid_1's auc: 0.784957\n",
      "[1306]\ttraining's auc: 0.834016\tvalid_1's auc: 0.784965\n",
      "[1307]\ttraining's auc: 0.834043\tvalid_1's auc: 0.784964\n",
      "[1308]\ttraining's auc: 0.834079\tvalid_1's auc: 0.784977\n",
      "[1309]\ttraining's auc: 0.834101\tvalid_1's auc: 0.78497\n",
      "[1310]\ttraining's auc: 0.834122\tvalid_1's auc: 0.784972\n",
      "[1311]\ttraining's auc: 0.834155\tvalid_1's auc: 0.784974\n",
      "[1312]\ttraining's auc: 0.834189\tvalid_1's auc: 0.784979\n",
      "[1313]\ttraining's auc: 0.834214\tvalid_1's auc: 0.784978\n",
      "[1314]\ttraining's auc: 0.834257\tvalid_1's auc: 0.784984\n",
      "[1315]\ttraining's auc: 0.834294\tvalid_1's auc: 0.784979\n",
      "[1316]\ttraining's auc: 0.834336\tvalid_1's auc: 0.784982\n",
      "[1317]\ttraining's auc: 0.834363\tvalid_1's auc: 0.784984\n",
      "[1318]\ttraining's auc: 0.83439\tvalid_1's auc: 0.784997\n",
      "[1319]\ttraining's auc: 0.834428\tvalid_1's auc: 0.785008\n",
      "[1320]\ttraining's auc: 0.834456\tvalid_1's auc: 0.785015\n",
      "[1321]\ttraining's auc: 0.834487\tvalid_1's auc: 0.785028\n",
      "[1322]\ttraining's auc: 0.834527\tvalid_1's auc: 0.785039\n",
      "[1323]\ttraining's auc: 0.83457\tvalid_1's auc: 0.785043\n",
      "[1324]\ttraining's auc: 0.834606\tvalid_1's auc: 0.785046\n",
      "[1325]\ttraining's auc: 0.834634\tvalid_1's auc: 0.785057\n",
      "[1326]\ttraining's auc: 0.834678\tvalid_1's auc: 0.785077\n",
      "[1327]\ttraining's auc: 0.834706\tvalid_1's auc: 0.785083\n",
      "[1328]\ttraining's auc: 0.834741\tvalid_1's auc: 0.785092\n",
      "[1329]\ttraining's auc: 0.83478\tvalid_1's auc: 0.78509\n",
      "[1330]\ttraining's auc: 0.834823\tvalid_1's auc: 0.785091\n",
      "[1331]\ttraining's auc: 0.834859\tvalid_1's auc: 0.785098\n",
      "[1332]\ttraining's auc: 0.8349\tvalid_1's auc: 0.785106\n",
      "[1333]\ttraining's auc: 0.834939\tvalid_1's auc: 0.78512\n",
      "[1334]\ttraining's auc: 0.83497\tvalid_1's auc: 0.785123\n",
      "[1335]\ttraining's auc: 0.835009\tvalid_1's auc: 0.78514\n",
      "[1336]\ttraining's auc: 0.835045\tvalid_1's auc: 0.785138\n",
      "[1337]\ttraining's auc: 0.835081\tvalid_1's auc: 0.785149\n",
      "[1338]\ttraining's auc: 0.835102\tvalid_1's auc: 0.78515\n",
      "[1339]\ttraining's auc: 0.835138\tvalid_1's auc: 0.785161\n",
      "[1340]\ttraining's auc: 0.835165\tvalid_1's auc: 0.785164\n",
      "[1341]\ttraining's auc: 0.835191\tvalid_1's auc: 0.785173\n",
      "[1342]\ttraining's auc: 0.835228\tvalid_1's auc: 0.785175\n",
      "[1343]\ttraining's auc: 0.835261\tvalid_1's auc: 0.785173\n",
      "[1344]\ttraining's auc: 0.835296\tvalid_1's auc: 0.785188\n",
      "[1345]\ttraining's auc: 0.835337\tvalid_1's auc: 0.785196\n",
      "[1346]\ttraining's auc: 0.835372\tvalid_1's auc: 0.7852\n",
      "[1347]\ttraining's auc: 0.835397\tvalid_1's auc: 0.785199\n",
      "[1348]\ttraining's auc: 0.83543\tvalid_1's auc: 0.785201\n",
      "[1349]\ttraining's auc: 0.835472\tvalid_1's auc: 0.785212\n",
      "[1350]\ttraining's auc: 0.835503\tvalid_1's auc: 0.785226\n",
      "[1351]\ttraining's auc: 0.835542\tvalid_1's auc: 0.785225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1352]\ttraining's auc: 0.83558\tvalid_1's auc: 0.78523\n",
      "[1353]\ttraining's auc: 0.835614\tvalid_1's auc: 0.785241\n",
      "[1354]\ttraining's auc: 0.835641\tvalid_1's auc: 0.785246\n",
      "[1355]\ttraining's auc: 0.835665\tvalid_1's auc: 0.78525\n",
      "[1356]\ttraining's auc: 0.8357\tvalid_1's auc: 0.785255\n",
      "[1357]\ttraining's auc: 0.835748\tvalid_1's auc: 0.785262\n",
      "[1358]\ttraining's auc: 0.835777\tvalid_1's auc: 0.78526\n",
      "[1359]\ttraining's auc: 0.835809\tvalid_1's auc: 0.785267\n",
      "[1360]\ttraining's auc: 0.835843\tvalid_1's auc: 0.785268\n",
      "[1361]\ttraining's auc: 0.835879\tvalid_1's auc: 0.785271\n",
      "[1362]\ttraining's auc: 0.835906\tvalid_1's auc: 0.785273\n",
      "[1363]\ttraining's auc: 0.835945\tvalid_1's auc: 0.785271\n",
      "[1364]\ttraining's auc: 0.835983\tvalid_1's auc: 0.785282\n",
      "[1365]\ttraining's auc: 0.836023\tvalid_1's auc: 0.785285\n",
      "[1366]\ttraining's auc: 0.836067\tvalid_1's auc: 0.785295\n",
      "[1367]\ttraining's auc: 0.836106\tvalid_1's auc: 0.7853\n",
      "[1368]\ttraining's auc: 0.836144\tvalid_1's auc: 0.785307\n",
      "[1369]\ttraining's auc: 0.836174\tvalid_1's auc: 0.78531\n",
      "[1370]\ttraining's auc: 0.836203\tvalid_1's auc: 0.785329\n",
      "[1371]\ttraining's auc: 0.836237\tvalid_1's auc: 0.785339\n",
      "[1372]\ttraining's auc: 0.836268\tvalid_1's auc: 0.785348\n",
      "[1373]\ttraining's auc: 0.836305\tvalid_1's auc: 0.78535\n",
      "[1374]\ttraining's auc: 0.836332\tvalid_1's auc: 0.785364\n",
      "[1375]\ttraining's auc: 0.83637\tvalid_1's auc: 0.785376\n",
      "[1376]\ttraining's auc: 0.836403\tvalid_1's auc: 0.785379\n",
      "[1377]\ttraining's auc: 0.836438\tvalid_1's auc: 0.785381\n",
      "[1378]\ttraining's auc: 0.836477\tvalid_1's auc: 0.785382\n",
      "[1379]\ttraining's auc: 0.836511\tvalid_1's auc: 0.785385\n",
      "[1380]\ttraining's auc: 0.836547\tvalid_1's auc: 0.785395\n",
      "[1381]\ttraining's auc: 0.83658\tvalid_1's auc: 0.785401\n",
      "[1382]\ttraining's auc: 0.836613\tvalid_1's auc: 0.785406\n",
      "[1383]\ttraining's auc: 0.836659\tvalid_1's auc: 0.785443\n",
      "[1384]\ttraining's auc: 0.836682\tvalid_1's auc: 0.785437\n",
      "[1385]\ttraining's auc: 0.836715\tvalid_1's auc: 0.785443\n",
      "[1386]\ttraining's auc: 0.836747\tvalid_1's auc: 0.785448\n",
      "[1387]\ttraining's auc: 0.836787\tvalid_1's auc: 0.785448\n",
      "[1388]\ttraining's auc: 0.836822\tvalid_1's auc: 0.785453\n",
      "[1389]\ttraining's auc: 0.83686\tvalid_1's auc: 0.785461\n",
      "[1390]\ttraining's auc: 0.836887\tvalid_1's auc: 0.785467\n",
      "[1391]\ttraining's auc: 0.83692\tvalid_1's auc: 0.785456\n",
      "[1392]\ttraining's auc: 0.836946\tvalid_1's auc: 0.785457\n",
      "[1393]\ttraining's auc: 0.836989\tvalid_1's auc: 0.785459\n",
      "[1394]\ttraining's auc: 0.837013\tvalid_1's auc: 0.785466\n",
      "[1395]\ttraining's auc: 0.837042\tvalid_1's auc: 0.785469\n",
      "[1396]\ttraining's auc: 0.837067\tvalid_1's auc: 0.78548\n",
      "[1397]\ttraining's auc: 0.837104\tvalid_1's auc: 0.785482\n",
      "[1398]\ttraining's auc: 0.837146\tvalid_1's auc: 0.785491\n",
      "[1399]\ttraining's auc: 0.837189\tvalid_1's auc: 0.785493\n",
      "[1400]\ttraining's auc: 0.83722\tvalid_1's auc: 0.785495\n",
      "[1401]\ttraining's auc: 0.837254\tvalid_1's auc: 0.785494\n",
      "[1402]\ttraining's auc: 0.837286\tvalid_1's auc: 0.785496\n",
      "[1403]\ttraining's auc: 0.837325\tvalid_1's auc: 0.785513\n",
      "[1404]\ttraining's auc: 0.837357\tvalid_1's auc: 0.785515\n",
      "[1405]\ttraining's auc: 0.837403\tvalid_1's auc: 0.785522\n",
      "[1406]\ttraining's auc: 0.837436\tvalid_1's auc: 0.785528\n",
      "[1407]\ttraining's auc: 0.837474\tvalid_1's auc: 0.785526\n",
      "[1408]\ttraining's auc: 0.837515\tvalid_1's auc: 0.785525\n",
      "[1409]\ttraining's auc: 0.837543\tvalid_1's auc: 0.785534\n",
      "[1410]\ttraining's auc: 0.837577\tvalid_1's auc: 0.785539\n",
      "[1411]\ttraining's auc: 0.837611\tvalid_1's auc: 0.78555\n",
      "[1412]\ttraining's auc: 0.837639\tvalid_1's auc: 0.785542\n",
      "[1413]\ttraining's auc: 0.837677\tvalid_1's auc: 0.785555\n",
      "[1414]\ttraining's auc: 0.837713\tvalid_1's auc: 0.785555\n",
      "[1415]\ttraining's auc: 0.83774\tvalid_1's auc: 0.785566\n",
      "[1416]\ttraining's auc: 0.837781\tvalid_1's auc: 0.785575\n",
      "[1417]\ttraining's auc: 0.837808\tvalid_1's auc: 0.785585\n",
      "[1418]\ttraining's auc: 0.837839\tvalid_1's auc: 0.785591\n",
      "[1419]\ttraining's auc: 0.837877\tvalid_1's auc: 0.785595\n",
      "[1420]\ttraining's auc: 0.837921\tvalid_1's auc: 0.785604\n",
      "[1421]\ttraining's auc: 0.83795\tvalid_1's auc: 0.785604\n",
      "[1422]\ttraining's auc: 0.837978\tvalid_1's auc: 0.785612\n",
      "[1423]\ttraining's auc: 0.838008\tvalid_1's auc: 0.785623\n",
      "[1424]\ttraining's auc: 0.838043\tvalid_1's auc: 0.785631\n",
      "[1425]\ttraining's auc: 0.83807\tvalid_1's auc: 0.785629\n",
      "[1426]\ttraining's auc: 0.838103\tvalid_1's auc: 0.785634\n",
      "[1427]\ttraining's auc: 0.838143\tvalid_1's auc: 0.785645\n",
      "[1428]\ttraining's auc: 0.838185\tvalid_1's auc: 0.785654\n",
      "[1429]\ttraining's auc: 0.838216\tvalid_1's auc: 0.785661\n",
      "[1430]\ttraining's auc: 0.83824\tvalid_1's auc: 0.785669\n",
      "[1431]\ttraining's auc: 0.838268\tvalid_1's auc: 0.78569\n",
      "[1432]\ttraining's auc: 0.83829\tvalid_1's auc: 0.785696\n",
      "[1433]\ttraining's auc: 0.838329\tvalid_1's auc: 0.785704\n",
      "[1434]\ttraining's auc: 0.838354\tvalid_1's auc: 0.785709\n",
      "[1435]\ttraining's auc: 0.838391\tvalid_1's auc: 0.785706\n",
      "[1436]\ttraining's auc: 0.83842\tvalid_1's auc: 0.785718\n",
      "[1437]\ttraining's auc: 0.83845\tvalid_1's auc: 0.785713\n",
      "[1438]\ttraining's auc: 0.838481\tvalid_1's auc: 0.785719\n",
      "[1439]\ttraining's auc: 0.838515\tvalid_1's auc: 0.785723\n",
      "[1440]\ttraining's auc: 0.838552\tvalid_1's auc: 0.785721\n",
      "[1441]\ttraining's auc: 0.838585\tvalid_1's auc: 0.785718\n",
      "[1442]\ttraining's auc: 0.83862\tvalid_1's auc: 0.785728\n",
      "[1443]\ttraining's auc: 0.83866\tvalid_1's auc: 0.78573\n",
      "[1444]\ttraining's auc: 0.838693\tvalid_1's auc: 0.78574\n",
      "[1445]\ttraining's auc: 0.838723\tvalid_1's auc: 0.785746\n",
      "[1446]\ttraining's auc: 0.838755\tvalid_1's auc: 0.78575\n",
      "[1447]\ttraining's auc: 0.838777\tvalid_1's auc: 0.785749\n",
      "[1448]\ttraining's auc: 0.838804\tvalid_1's auc: 0.785755\n",
      "[1449]\ttraining's auc: 0.838843\tvalid_1's auc: 0.785765\n",
      "[1450]\ttraining's auc: 0.838872\tvalid_1's auc: 0.785769\n",
      "[1451]\ttraining's auc: 0.838908\tvalid_1's auc: 0.785773\n",
      "[1452]\ttraining's auc: 0.838938\tvalid_1's auc: 0.78578\n",
      "[1453]\ttraining's auc: 0.838971\tvalid_1's auc: 0.785791\n",
      "[1454]\ttraining's auc: 0.839005\tvalid_1's auc: 0.785794\n",
      "[1455]\ttraining's auc: 0.839039\tvalid_1's auc: 0.785796\n",
      "[1456]\ttraining's auc: 0.839074\tvalid_1's auc: 0.785799\n",
      "[1457]\ttraining's auc: 0.839107\tvalid_1's auc: 0.785802\n",
      "[1458]\ttraining's auc: 0.839142\tvalid_1's auc: 0.785806\n",
      "[1459]\ttraining's auc: 0.839174\tvalid_1's auc: 0.785811\n",
      "[1460]\ttraining's auc: 0.839207\tvalid_1's auc: 0.785801\n",
      "[1461]\ttraining's auc: 0.839236\tvalid_1's auc: 0.785809\n",
      "[1462]\ttraining's auc: 0.839261\tvalid_1's auc: 0.78581\n",
      "[1463]\ttraining's auc: 0.839292\tvalid_1's auc: 0.78581\n",
      "[1464]\ttraining's auc: 0.839325\tvalid_1's auc: 0.785817\n",
      "[1465]\ttraining's auc: 0.839354\tvalid_1's auc: 0.785818\n",
      "[1466]\ttraining's auc: 0.839391\tvalid_1's auc: 0.785817\n",
      "[1467]\ttraining's auc: 0.839429\tvalid_1's auc: 0.78582\n",
      "[1468]\ttraining's auc: 0.839465\tvalid_1's auc: 0.785824\n",
      "[1469]\ttraining's auc: 0.83949\tvalid_1's auc: 0.785825\n",
      "[1470]\ttraining's auc: 0.839522\tvalid_1's auc: 0.785829\n",
      "[1471]\ttraining's auc: 0.839551\tvalid_1's auc: 0.785836\n",
      "[1472]\ttraining's auc: 0.839578\tvalid_1's auc: 0.785844\n",
      "[1473]\ttraining's auc: 0.839607\tvalid_1's auc: 0.785859\n",
      "[1474]\ttraining's auc: 0.839636\tvalid_1's auc: 0.785861\n",
      "[1475]\ttraining's auc: 0.839665\tvalid_1's auc: 0.785871\n",
      "[1476]\ttraining's auc: 0.839697\tvalid_1's auc: 0.785888\n",
      "[1477]\ttraining's auc: 0.839728\tvalid_1's auc: 0.785887\n",
      "[1478]\ttraining's auc: 0.839756\tvalid_1's auc: 0.785883\n",
      "[1479]\ttraining's auc: 0.839787\tvalid_1's auc: 0.785886\n",
      "[1480]\ttraining's auc: 0.839812\tvalid_1's auc: 0.785892\n",
      "[1481]\ttraining's auc: 0.839853\tvalid_1's auc: 0.785903\n",
      "[1482]\ttraining's auc: 0.839886\tvalid_1's auc: 0.785906\n",
      "[1483]\ttraining's auc: 0.839923\tvalid_1's auc: 0.785914\n",
      "[1484]\ttraining's auc: 0.839956\tvalid_1's auc: 0.78592\n",
      "[1485]\ttraining's auc: 0.839981\tvalid_1's auc: 0.785924\n",
      "[1486]\ttraining's auc: 0.840019\tvalid_1's auc: 0.785932\n",
      "[1487]\ttraining's auc: 0.840048\tvalid_1's auc: 0.785928\n",
      "[1488]\ttraining's auc: 0.840089\tvalid_1's auc: 0.785938\n",
      "[1489]\ttraining's auc: 0.840118\tvalid_1's auc: 0.785942\n",
      "[1490]\ttraining's auc: 0.84015\tvalid_1's auc: 0.785945\n",
      "[1491]\ttraining's auc: 0.840186\tvalid_1's auc: 0.785954\n",
      "[1492]\ttraining's auc: 0.840222\tvalid_1's auc: 0.785973\n",
      "[1493]\ttraining's auc: 0.840251\tvalid_1's auc: 0.785981\n",
      "[1494]\ttraining's auc: 0.840284\tvalid_1's auc: 0.785986\n",
      "[1495]\ttraining's auc: 0.840323\tvalid_1's auc: 0.785989\n",
      "[1496]\ttraining's auc: 0.840365\tvalid_1's auc: 0.785986\n",
      "[1497]\ttraining's auc: 0.840397\tvalid_1's auc: 0.78599\n",
      "[1498]\ttraining's auc: 0.840421\tvalid_1's auc: 0.785992\n",
      "[1499]\ttraining's auc: 0.84046\tvalid_1's auc: 0.78601\n",
      "[1500]\ttraining's auc: 0.840495\tvalid_1's auc: 0.786013\n",
      "[1501]\ttraining's auc: 0.840524\tvalid_1's auc: 0.786013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1502]\ttraining's auc: 0.840565\tvalid_1's auc: 0.786022\n",
      "[1503]\ttraining's auc: 0.840599\tvalid_1's auc: 0.786032\n",
      "[1504]\ttraining's auc: 0.840621\tvalid_1's auc: 0.786033\n",
      "[1505]\ttraining's auc: 0.840655\tvalid_1's auc: 0.78605\n",
      "[1506]\ttraining's auc: 0.840684\tvalid_1's auc: 0.786064\n",
      "[1507]\ttraining's auc: 0.840712\tvalid_1's auc: 0.786066\n",
      "[1508]\ttraining's auc: 0.840747\tvalid_1's auc: 0.786071\n",
      "[1509]\ttraining's auc: 0.840778\tvalid_1's auc: 0.786076\n",
      "[1510]\ttraining's auc: 0.840819\tvalid_1's auc: 0.786074\n",
      "[1511]\ttraining's auc: 0.840854\tvalid_1's auc: 0.786077\n",
      "[1512]\ttraining's auc: 0.840881\tvalid_1's auc: 0.786082\n",
      "[1513]\ttraining's auc: 0.84092\tvalid_1's auc: 0.786086\n",
      "[1514]\ttraining's auc: 0.840955\tvalid_1's auc: 0.78609\n",
      "[1515]\ttraining's auc: 0.840986\tvalid_1's auc: 0.786091\n",
      "[1516]\ttraining's auc: 0.841019\tvalid_1's auc: 0.786096\n",
      "[1517]\ttraining's auc: 0.841051\tvalid_1's auc: 0.786098\n",
      "[1518]\ttraining's auc: 0.841076\tvalid_1's auc: 0.786095\n",
      "[1519]\ttraining's auc: 0.841101\tvalid_1's auc: 0.786098\n",
      "[1520]\ttraining's auc: 0.841132\tvalid_1's auc: 0.786099\n",
      "[1521]\ttraining's auc: 0.841161\tvalid_1's auc: 0.786103\n",
      "[1522]\ttraining's auc: 0.841195\tvalid_1's auc: 0.786113\n",
      "[1523]\ttraining's auc: 0.841228\tvalid_1's auc: 0.786115\n",
      "[1524]\ttraining's auc: 0.841255\tvalid_1's auc: 0.786122\n",
      "[1525]\ttraining's auc: 0.841292\tvalid_1's auc: 0.78613\n",
      "[1526]\ttraining's auc: 0.841322\tvalid_1's auc: 0.786144\n",
      "[1527]\ttraining's auc: 0.841361\tvalid_1's auc: 0.786151\n",
      "[1528]\ttraining's auc: 0.841396\tvalid_1's auc: 0.786159\n",
      "[1529]\ttraining's auc: 0.841426\tvalid_1's auc: 0.786167\n",
      "[1530]\ttraining's auc: 0.841454\tvalid_1's auc: 0.786159\n",
      "[1531]\ttraining's auc: 0.841483\tvalid_1's auc: 0.786164\n",
      "[1532]\ttraining's auc: 0.841508\tvalid_1's auc: 0.78618\n",
      "[1533]\ttraining's auc: 0.84154\tvalid_1's auc: 0.786187\n",
      "[1534]\ttraining's auc: 0.841565\tvalid_1's auc: 0.786191\n",
      "[1535]\ttraining's auc: 0.841598\tvalid_1's auc: 0.786191\n",
      "[1536]\ttraining's auc: 0.841636\tvalid_1's auc: 0.786203\n",
      "[1537]\ttraining's auc: 0.841668\tvalid_1's auc: 0.786216\n",
      "[1538]\ttraining's auc: 0.841702\tvalid_1's auc: 0.786224\n",
      "[1539]\ttraining's auc: 0.84174\tvalid_1's auc: 0.786223\n",
      "[1540]\ttraining's auc: 0.841772\tvalid_1's auc: 0.78622\n",
      "[1541]\ttraining's auc: 0.841801\tvalid_1's auc: 0.786223\n",
      "[1542]\ttraining's auc: 0.841829\tvalid_1's auc: 0.786226\n",
      "[1543]\ttraining's auc: 0.84185\tvalid_1's auc: 0.78624\n",
      "[1544]\ttraining's auc: 0.84189\tvalid_1's auc: 0.786241\n",
      "[1545]\ttraining's auc: 0.841916\tvalid_1's auc: 0.786248\n",
      "[1546]\ttraining's auc: 0.841944\tvalid_1's auc: 0.786256\n",
      "[1547]\ttraining's auc: 0.841971\tvalid_1's auc: 0.786254\n",
      "[1548]\ttraining's auc: 0.842008\tvalid_1's auc: 0.786252\n",
      "[1549]\ttraining's auc: 0.842049\tvalid_1's auc: 0.786254\n",
      "[1550]\ttraining's auc: 0.842082\tvalid_1's auc: 0.786263\n",
      "[1551]\ttraining's auc: 0.842123\tvalid_1's auc: 0.786271\n",
      "[1552]\ttraining's auc: 0.84215\tvalid_1's auc: 0.786276\n",
      "[1553]\ttraining's auc: 0.842181\tvalid_1's auc: 0.786283\n",
      "[1554]\ttraining's auc: 0.84221\tvalid_1's auc: 0.786284\n",
      "[1555]\ttraining's auc: 0.842243\tvalid_1's auc: 0.78629\n",
      "[1556]\ttraining's auc: 0.842268\tvalid_1's auc: 0.786287\n",
      "[1557]\ttraining's auc: 0.842301\tvalid_1's auc: 0.786293\n",
      "[1558]\ttraining's auc: 0.842329\tvalid_1's auc: 0.786299\n",
      "[1559]\ttraining's auc: 0.842367\tvalid_1's auc: 0.786316\n",
      "[1560]\ttraining's auc: 0.8424\tvalid_1's auc: 0.786324\n",
      "[1561]\ttraining's auc: 0.842433\tvalid_1's auc: 0.786336\n",
      "[1562]\ttraining's auc: 0.842472\tvalid_1's auc: 0.786337\n",
      "[1563]\ttraining's auc: 0.842505\tvalid_1's auc: 0.786332\n",
      "[1564]\ttraining's auc: 0.842537\tvalid_1's auc: 0.786345\n",
      "[1565]\ttraining's auc: 0.842569\tvalid_1's auc: 0.786346\n",
      "[1566]\ttraining's auc: 0.842607\tvalid_1's auc: 0.786348\n",
      "[1567]\ttraining's auc: 0.842641\tvalid_1's auc: 0.78636\n",
      "[1568]\ttraining's auc: 0.842672\tvalid_1's auc: 0.78637\n",
      "[1569]\ttraining's auc: 0.842701\tvalid_1's auc: 0.786373\n",
      "[1570]\ttraining's auc: 0.842727\tvalid_1's auc: 0.786394\n",
      "[1571]\ttraining's auc: 0.842762\tvalid_1's auc: 0.786398\n",
      "[1572]\ttraining's auc: 0.842793\tvalid_1's auc: 0.786399\n",
      "[1573]\ttraining's auc: 0.842818\tvalid_1's auc: 0.786405\n",
      "[1574]\ttraining's auc: 0.842847\tvalid_1's auc: 0.786407\n",
      "[1575]\ttraining's auc: 0.842886\tvalid_1's auc: 0.786422\n",
      "[1576]\ttraining's auc: 0.842917\tvalid_1's auc: 0.78642\n",
      "[1577]\ttraining's auc: 0.842943\tvalid_1's auc: 0.786423\n",
      "[1578]\ttraining's auc: 0.84297\tvalid_1's auc: 0.786431\n",
      "[1579]\ttraining's auc: 0.843002\tvalid_1's auc: 0.786432\n",
      "[1580]\ttraining's auc: 0.843037\tvalid_1's auc: 0.786433\n",
      "[1581]\ttraining's auc: 0.843067\tvalid_1's auc: 0.786446\n",
      "[1582]\ttraining's auc: 0.843097\tvalid_1's auc: 0.78646\n",
      "[1583]\ttraining's auc: 0.843131\tvalid_1's auc: 0.786464\n",
      "[1584]\ttraining's auc: 0.843161\tvalid_1's auc: 0.786462\n",
      "[1585]\ttraining's auc: 0.843196\tvalid_1's auc: 0.786466\n",
      "[1586]\ttraining's auc: 0.843237\tvalid_1's auc: 0.786468\n",
      "[1587]\ttraining's auc: 0.843273\tvalid_1's auc: 0.786482\n",
      "[1588]\ttraining's auc: 0.843306\tvalid_1's auc: 0.786483\n",
      "[1589]\ttraining's auc: 0.843339\tvalid_1's auc: 0.786498\n",
      "[1590]\ttraining's auc: 0.843367\tvalid_1's auc: 0.786498\n",
      "[1591]\ttraining's auc: 0.843394\tvalid_1's auc: 0.786503\n",
      "[1592]\ttraining's auc: 0.843427\tvalid_1's auc: 0.786504\n",
      "[1593]\ttraining's auc: 0.843448\tvalid_1's auc: 0.786508\n",
      "[1594]\ttraining's auc: 0.843484\tvalid_1's auc: 0.78651\n",
      "[1595]\ttraining's auc: 0.843523\tvalid_1's auc: 0.786516\n",
      "[1596]\ttraining's auc: 0.843545\tvalid_1's auc: 0.786514\n",
      "[1597]\ttraining's auc: 0.843579\tvalid_1's auc: 0.786524\n",
      "[1598]\ttraining's auc: 0.843605\tvalid_1's auc: 0.78653\n",
      "[1599]\ttraining's auc: 0.843641\tvalid_1's auc: 0.786536\n",
      "[1600]\ttraining's auc: 0.843675\tvalid_1's auc: 0.786541\n",
      "[1601]\ttraining's auc: 0.843705\tvalid_1's auc: 0.786544\n",
      "[1602]\ttraining's auc: 0.843726\tvalid_1's auc: 0.786548\n",
      "[1603]\ttraining's auc: 0.843758\tvalid_1's auc: 0.786561\n",
      "[1604]\ttraining's auc: 0.843789\tvalid_1's auc: 0.786568\n",
      "[1605]\ttraining's auc: 0.843824\tvalid_1's auc: 0.786567\n",
      "[1606]\ttraining's auc: 0.843859\tvalid_1's auc: 0.786558\n",
      "[1607]\ttraining's auc: 0.843888\tvalid_1's auc: 0.786558\n",
      "[1608]\ttraining's auc: 0.843922\tvalid_1's auc: 0.786563\n",
      "[1609]\ttraining's auc: 0.843949\tvalid_1's auc: 0.786568\n",
      "[1610]\ttraining's auc: 0.843983\tvalid_1's auc: 0.786572\n",
      "[1611]\ttraining's auc: 0.844005\tvalid_1's auc: 0.786581\n",
      "[1612]\ttraining's auc: 0.844035\tvalid_1's auc: 0.786586\n",
      "[1613]\ttraining's auc: 0.844064\tvalid_1's auc: 0.78659\n",
      "[1614]\ttraining's auc: 0.844103\tvalid_1's auc: 0.7866\n",
      "[1615]\ttraining's auc: 0.844135\tvalid_1's auc: 0.786607\n",
      "[1616]\ttraining's auc: 0.844168\tvalid_1's auc: 0.786606\n",
      "[1617]\ttraining's auc: 0.844189\tvalid_1's auc: 0.786613\n",
      "[1618]\ttraining's auc: 0.844213\tvalid_1's auc: 0.786622\n",
      "[1619]\ttraining's auc: 0.84425\tvalid_1's auc: 0.786638\n",
      "[1620]\ttraining's auc: 0.844281\tvalid_1's auc: 0.786637\n",
      "[1621]\ttraining's auc: 0.844319\tvalid_1's auc: 0.786638\n",
      "[1622]\ttraining's auc: 0.844351\tvalid_1's auc: 0.786635\n",
      "[1623]\ttraining's auc: 0.844388\tvalid_1's auc: 0.786633\n",
      "[1624]\ttraining's auc: 0.844421\tvalid_1's auc: 0.78663\n",
      "[1625]\ttraining's auc: 0.844449\tvalid_1's auc: 0.786638\n",
      "[1626]\ttraining's auc: 0.84447\tvalid_1's auc: 0.786646\n",
      "[1627]\ttraining's auc: 0.844504\tvalid_1's auc: 0.786649\n",
      "[1628]\ttraining's auc: 0.844536\tvalid_1's auc: 0.786656\n",
      "[1629]\ttraining's auc: 0.844563\tvalid_1's auc: 0.786655\n",
      "[1630]\ttraining's auc: 0.844596\tvalid_1's auc: 0.786661\n",
      "[1631]\ttraining's auc: 0.844624\tvalid_1's auc: 0.786662\n",
      "[1632]\ttraining's auc: 0.844654\tvalid_1's auc: 0.786666\n",
      "[1633]\ttraining's auc: 0.844684\tvalid_1's auc: 0.786677\n",
      "[1634]\ttraining's auc: 0.844716\tvalid_1's auc: 0.78668\n",
      "[1635]\ttraining's auc: 0.844756\tvalid_1's auc: 0.78668\n",
      "[1636]\ttraining's auc: 0.844782\tvalid_1's auc: 0.786686\n",
      "[1637]\ttraining's auc: 0.844812\tvalid_1's auc: 0.78669\n",
      "[1638]\ttraining's auc: 0.844849\tvalid_1's auc: 0.786695\n",
      "[1639]\ttraining's auc: 0.844873\tvalid_1's auc: 0.786695\n",
      "[1640]\ttraining's auc: 0.844901\tvalid_1's auc: 0.786699\n",
      "[1641]\ttraining's auc: 0.844926\tvalid_1's auc: 0.786708\n",
      "[1642]\ttraining's auc: 0.844964\tvalid_1's auc: 0.786713\n",
      "[1643]\ttraining's auc: 0.844995\tvalid_1's auc: 0.786714\n",
      "[1644]\ttraining's auc: 0.845036\tvalid_1's auc: 0.786719\n",
      "[1645]\ttraining's auc: 0.845074\tvalid_1's auc: 0.786723\n",
      "[1646]\ttraining's auc: 0.845106\tvalid_1's auc: 0.786722\n",
      "[1647]\ttraining's auc: 0.845138\tvalid_1's auc: 0.78673\n",
      "[1648]\ttraining's auc: 0.845177\tvalid_1's auc: 0.786732\n",
      "[1649]\ttraining's auc: 0.84521\tvalid_1's auc: 0.78673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1650]\ttraining's auc: 0.845236\tvalid_1's auc: 0.78674\n",
      "[1651]\ttraining's auc: 0.845271\tvalid_1's auc: 0.786742\n",
      "[1652]\ttraining's auc: 0.845299\tvalid_1's auc: 0.786741\n",
      "[1653]\ttraining's auc: 0.845325\tvalid_1's auc: 0.786746\n",
      "[1654]\ttraining's auc: 0.845357\tvalid_1's auc: 0.786742\n",
      "[1655]\ttraining's auc: 0.845394\tvalid_1's auc: 0.786749\n",
      "[1656]\ttraining's auc: 0.845426\tvalid_1's auc: 0.786754\n",
      "[1657]\ttraining's auc: 0.845463\tvalid_1's auc: 0.786766\n",
      "[1658]\ttraining's auc: 0.845509\tvalid_1's auc: 0.786766\n",
      "[1659]\ttraining's auc: 0.845545\tvalid_1's auc: 0.786788\n",
      "[1660]\ttraining's auc: 0.845581\tvalid_1's auc: 0.786791\n",
      "[1661]\ttraining's auc: 0.845612\tvalid_1's auc: 0.786794\n",
      "[1662]\ttraining's auc: 0.845642\tvalid_1's auc: 0.786791\n",
      "[1663]\ttraining's auc: 0.84567\tvalid_1's auc: 0.786791\n",
      "[1664]\ttraining's auc: 0.845707\tvalid_1's auc: 0.786795\n",
      "[1665]\ttraining's auc: 0.845726\tvalid_1's auc: 0.786799\n",
      "[1666]\ttraining's auc: 0.84576\tvalid_1's auc: 0.786796\n",
      "[1667]\ttraining's auc: 0.845797\tvalid_1's auc: 0.786808\n",
      "[1668]\ttraining's auc: 0.845823\tvalid_1's auc: 0.786808\n",
      "[1669]\ttraining's auc: 0.845851\tvalid_1's auc: 0.786808\n",
      "[1670]\ttraining's auc: 0.845873\tvalid_1's auc: 0.786811\n",
      "[1671]\ttraining's auc: 0.845893\tvalid_1's auc: 0.786813\n",
      "[1672]\ttraining's auc: 0.845922\tvalid_1's auc: 0.786822\n",
      "[1673]\ttraining's auc: 0.84595\tvalid_1's auc: 0.786827\n",
      "[1674]\ttraining's auc: 0.845982\tvalid_1's auc: 0.786824\n",
      "[1675]\ttraining's auc: 0.846018\tvalid_1's auc: 0.78683\n",
      "[1676]\ttraining's auc: 0.846048\tvalid_1's auc: 0.78683\n",
      "[1677]\ttraining's auc: 0.846073\tvalid_1's auc: 0.786839\n",
      "[1678]\ttraining's auc: 0.846104\tvalid_1's auc: 0.786855\n",
      "[1679]\ttraining's auc: 0.84613\tvalid_1's auc: 0.786866\n",
      "[1680]\ttraining's auc: 0.846152\tvalid_1's auc: 0.786872\n",
      "[1681]\ttraining's auc: 0.846186\tvalid_1's auc: 0.786879\n",
      "[1682]\ttraining's auc: 0.846225\tvalid_1's auc: 0.786888\n",
      "[1683]\ttraining's auc: 0.846249\tvalid_1's auc: 0.78689\n",
      "[1684]\ttraining's auc: 0.846273\tvalid_1's auc: 0.786893\n",
      "[1685]\ttraining's auc: 0.846302\tvalid_1's auc: 0.786895\n",
      "[1686]\ttraining's auc: 0.846336\tvalid_1's auc: 0.786895\n",
      "[1687]\ttraining's auc: 0.846368\tvalid_1's auc: 0.786897\n",
      "[1688]\ttraining's auc: 0.846397\tvalid_1's auc: 0.7869\n",
      "[1689]\ttraining's auc: 0.846435\tvalid_1's auc: 0.786908\n",
      "[1690]\ttraining's auc: 0.846462\tvalid_1's auc: 0.786909\n",
      "[1691]\ttraining's auc: 0.8465\tvalid_1's auc: 0.786917\n",
      "[1692]\ttraining's auc: 0.846528\tvalid_1's auc: 0.786923\n",
      "[1693]\ttraining's auc: 0.846556\tvalid_1's auc: 0.786932\n",
      "[1694]\ttraining's auc: 0.846582\tvalid_1's auc: 0.786928\n",
      "[1695]\ttraining's auc: 0.846621\tvalid_1's auc: 0.786948\n",
      "[1696]\ttraining's auc: 0.846653\tvalid_1's auc: 0.786941\n",
      "[1697]\ttraining's auc: 0.84669\tvalid_1's auc: 0.786938\n",
      "[1698]\ttraining's auc: 0.846715\tvalid_1's auc: 0.786934\n",
      "[1699]\ttraining's auc: 0.846745\tvalid_1's auc: 0.786945\n",
      "[1700]\ttraining's auc: 0.846766\tvalid_1's auc: 0.786942\n",
      "[1701]\ttraining's auc: 0.846792\tvalid_1's auc: 0.786942\n",
      "[1702]\ttraining's auc: 0.846807\tvalid_1's auc: 0.786946\n",
      "[1703]\ttraining's auc: 0.846843\tvalid_1's auc: 0.786955\n",
      "[1704]\ttraining's auc: 0.84687\tvalid_1's auc: 0.786959\n",
      "[1705]\ttraining's auc: 0.846911\tvalid_1's auc: 0.786969\n",
      "[1706]\ttraining's auc: 0.846945\tvalid_1's auc: 0.786966\n",
      "[1707]\ttraining's auc: 0.846972\tvalid_1's auc: 0.786963\n",
      "[1708]\ttraining's auc: 0.847\tvalid_1's auc: 0.786961\n",
      "[1709]\ttraining's auc: 0.847036\tvalid_1's auc: 0.786967\n",
      "[1710]\ttraining's auc: 0.847063\tvalid_1's auc: 0.786973\n",
      "[1711]\ttraining's auc: 0.847093\tvalid_1's auc: 0.786971\n",
      "[1712]\ttraining's auc: 0.847122\tvalid_1's auc: 0.786971\n",
      "[1713]\ttraining's auc: 0.847153\tvalid_1's auc: 0.786978\n",
      "[1714]\ttraining's auc: 0.847179\tvalid_1's auc: 0.786976\n",
      "[1715]\ttraining's auc: 0.847219\tvalid_1's auc: 0.786987\n",
      "[1716]\ttraining's auc: 0.847249\tvalid_1's auc: 0.78699\n",
      "[1717]\ttraining's auc: 0.847272\tvalid_1's auc: 0.786991\n",
      "[1718]\ttraining's auc: 0.847303\tvalid_1's auc: 0.786986\n",
      "[1719]\ttraining's auc: 0.847318\tvalid_1's auc: 0.786989\n",
      "[1720]\ttraining's auc: 0.847356\tvalid_1's auc: 0.786997\n",
      "[1721]\ttraining's auc: 0.847375\tvalid_1's auc: 0.786998\n",
      "[1722]\ttraining's auc: 0.847406\tvalid_1's auc: 0.786999\n",
      "[1723]\ttraining's auc: 0.847445\tvalid_1's auc: 0.787006\n",
      "[1724]\ttraining's auc: 0.84748\tvalid_1's auc: 0.787011\n",
      "[1725]\ttraining's auc: 0.847511\tvalid_1's auc: 0.787008\n",
      "[1726]\ttraining's auc: 0.847539\tvalid_1's auc: 0.787012\n",
      "[1727]\ttraining's auc: 0.847569\tvalid_1's auc: 0.787\n",
      "[1728]\ttraining's auc: 0.847596\tvalid_1's auc: 0.787012\n",
      "[1729]\ttraining's auc: 0.847617\tvalid_1's auc: 0.787007\n",
      "[1730]\ttraining's auc: 0.847646\tvalid_1's auc: 0.787013\n",
      "[1731]\ttraining's auc: 0.847678\tvalid_1's auc: 0.787017\n",
      "[1732]\ttraining's auc: 0.847709\tvalid_1's auc: 0.787017\n",
      "[1733]\ttraining's auc: 0.847735\tvalid_1's auc: 0.787027\n",
      "[1734]\ttraining's auc: 0.847766\tvalid_1's auc: 0.787021\n",
      "[1735]\ttraining's auc: 0.847797\tvalid_1's auc: 0.787024\n",
      "[1736]\ttraining's auc: 0.847827\tvalid_1's auc: 0.787031\n",
      "[1737]\ttraining's auc: 0.847857\tvalid_1's auc: 0.787033\n",
      "[1738]\ttraining's auc: 0.847889\tvalid_1's auc: 0.787038\n",
      "[1739]\ttraining's auc: 0.847917\tvalid_1's auc: 0.787038\n",
      "[1740]\ttraining's auc: 0.84795\tvalid_1's auc: 0.787036\n",
      "[1741]\ttraining's auc: 0.847964\tvalid_1's auc: 0.78704\n",
      "[1742]\ttraining's auc: 0.847998\tvalid_1's auc: 0.787041\n",
      "[1743]\ttraining's auc: 0.848028\tvalid_1's auc: 0.787042\n",
      "[1744]\ttraining's auc: 0.848051\tvalid_1's auc: 0.787047\n",
      "[1745]\ttraining's auc: 0.848072\tvalid_1's auc: 0.787051\n",
      "[1746]\ttraining's auc: 0.848109\tvalid_1's auc: 0.787058\n",
      "[1747]\ttraining's auc: 0.848146\tvalid_1's auc: 0.78706\n",
      "[1748]\ttraining's auc: 0.848173\tvalid_1's auc: 0.787068\n",
      "[1749]\ttraining's auc: 0.848206\tvalid_1's auc: 0.787074\n",
      "[1750]\ttraining's auc: 0.848244\tvalid_1's auc: 0.78707\n",
      "[1751]\ttraining's auc: 0.848278\tvalid_1's auc: 0.787073\n",
      "[1752]\ttraining's auc: 0.848301\tvalid_1's auc: 0.78707\n",
      "[1753]\ttraining's auc: 0.848334\tvalid_1's auc: 0.787071\n",
      "[1754]\ttraining's auc: 0.848349\tvalid_1's auc: 0.787074\n",
      "[1755]\ttraining's auc: 0.848369\tvalid_1's auc: 0.78707\n",
      "[1756]\ttraining's auc: 0.848395\tvalid_1's auc: 0.78707\n",
      "[1757]\ttraining's auc: 0.848422\tvalid_1's auc: 0.787074\n",
      "[1758]\ttraining's auc: 0.848446\tvalid_1's auc: 0.787082\n",
      "[1759]\ttraining's auc: 0.84847\tvalid_1's auc: 0.787083\n",
      "[1760]\ttraining's auc: 0.848497\tvalid_1's auc: 0.787084\n",
      "[1761]\ttraining's auc: 0.848532\tvalid_1's auc: 0.787082\n",
      "[1762]\ttraining's auc: 0.848562\tvalid_1's auc: 0.787085\n",
      "[1763]\ttraining's auc: 0.848591\tvalid_1's auc: 0.787094\n",
      "[1764]\ttraining's auc: 0.84862\tvalid_1's auc: 0.787091\n",
      "[1765]\ttraining's auc: 0.848651\tvalid_1's auc: 0.787091\n",
      "[1766]\ttraining's auc: 0.848674\tvalid_1's auc: 0.787093\n",
      "[1767]\ttraining's auc: 0.848705\tvalid_1's auc: 0.787095\n",
      "[1768]\ttraining's auc: 0.848737\tvalid_1's auc: 0.787095\n",
      "[1769]\ttraining's auc: 0.848762\tvalid_1's auc: 0.787099\n",
      "[1770]\ttraining's auc: 0.848784\tvalid_1's auc: 0.787101\n",
      "[1771]\ttraining's auc: 0.848821\tvalid_1's auc: 0.787102\n",
      "[1772]\ttraining's auc: 0.848856\tvalid_1's auc: 0.787099\n",
      "[1773]\ttraining's auc: 0.848884\tvalid_1's auc: 0.787104\n",
      "[1774]\ttraining's auc: 0.848906\tvalid_1's auc: 0.787108\n",
      "[1775]\ttraining's auc: 0.848933\tvalid_1's auc: 0.787108\n",
      "[1776]\ttraining's auc: 0.848966\tvalid_1's auc: 0.787113\n",
      "[1777]\ttraining's auc: 0.848995\tvalid_1's auc: 0.787121\n",
      "[1778]\ttraining's auc: 0.849026\tvalid_1's auc: 0.78712\n",
      "[1779]\ttraining's auc: 0.849065\tvalid_1's auc: 0.787118\n",
      "[1780]\ttraining's auc: 0.849095\tvalid_1's auc: 0.787127\n",
      "[1781]\ttraining's auc: 0.849132\tvalid_1's auc: 0.787136\n",
      "[1782]\ttraining's auc: 0.849148\tvalid_1's auc: 0.787137\n",
      "[1783]\ttraining's auc: 0.849179\tvalid_1's auc: 0.787134\n",
      "[1784]\ttraining's auc: 0.8492\tvalid_1's auc: 0.787141\n",
      "[1785]\ttraining's auc: 0.849214\tvalid_1's auc: 0.787153\n",
      "[1786]\ttraining's auc: 0.84925\tvalid_1's auc: 0.787156\n",
      "[1787]\ttraining's auc: 0.849289\tvalid_1's auc: 0.787161\n",
      "[1788]\ttraining's auc: 0.849313\tvalid_1's auc: 0.787158\n",
      "[1789]\ttraining's auc: 0.849335\tvalid_1's auc: 0.787159\n",
      "[1790]\ttraining's auc: 0.849359\tvalid_1's auc: 0.787163\n",
      "[1791]\ttraining's auc: 0.84939\tvalid_1's auc: 0.787166\n",
      "[1792]\ttraining's auc: 0.849416\tvalid_1's auc: 0.787166\n",
      "[1793]\ttraining's auc: 0.849461\tvalid_1's auc: 0.787176\n",
      "[1794]\ttraining's auc: 0.849489\tvalid_1's auc: 0.78718\n",
      "[1795]\ttraining's auc: 0.849515\tvalid_1's auc: 0.787185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1796]\ttraining's auc: 0.849552\tvalid_1's auc: 0.787184\n",
      "[1797]\ttraining's auc: 0.849582\tvalid_1's auc: 0.787188\n",
      "[1798]\ttraining's auc: 0.849603\tvalid_1's auc: 0.787192\n",
      "[1799]\ttraining's auc: 0.849638\tvalid_1's auc: 0.787199\n",
      "[1800]\ttraining's auc: 0.849666\tvalid_1's auc: 0.787202\n",
      "[1801]\ttraining's auc: 0.849686\tvalid_1's auc: 0.787214\n",
      "[1802]\ttraining's auc: 0.849704\tvalid_1's auc: 0.787211\n",
      "[1803]\ttraining's auc: 0.849733\tvalid_1's auc: 0.787213\n",
      "[1804]\ttraining's auc: 0.849763\tvalid_1's auc: 0.787223\n",
      "[1805]\ttraining's auc: 0.849788\tvalid_1's auc: 0.78722\n",
      "[1806]\ttraining's auc: 0.849814\tvalid_1's auc: 0.787231\n",
      "[1807]\ttraining's auc: 0.849831\tvalid_1's auc: 0.78723\n",
      "[1808]\ttraining's auc: 0.849861\tvalid_1's auc: 0.787232\n",
      "[1809]\ttraining's auc: 0.849892\tvalid_1's auc: 0.787234\n",
      "[1810]\ttraining's auc: 0.849913\tvalid_1's auc: 0.787236\n",
      "[1811]\ttraining's auc: 0.849939\tvalid_1's auc: 0.787241\n",
      "[1812]\ttraining's auc: 0.849964\tvalid_1's auc: 0.787241\n",
      "[1813]\ttraining's auc: 0.849999\tvalid_1's auc: 0.787245\n",
      "[1814]\ttraining's auc: 0.850031\tvalid_1's auc: 0.787248\n",
      "[1815]\ttraining's auc: 0.85006\tvalid_1's auc: 0.787261\n",
      "[1816]\ttraining's auc: 0.850081\tvalid_1's auc: 0.787263\n",
      "[1817]\ttraining's auc: 0.850102\tvalid_1's auc: 0.787268\n",
      "[1818]\ttraining's auc: 0.850138\tvalid_1's auc: 0.787275\n",
      "[1819]\ttraining's auc: 0.850169\tvalid_1's auc: 0.787287\n",
      "[1820]\ttraining's auc: 0.850193\tvalid_1's auc: 0.787291\n",
      "[1821]\ttraining's auc: 0.850226\tvalid_1's auc: 0.787298\n",
      "[1822]\ttraining's auc: 0.850255\tvalid_1's auc: 0.787299\n",
      "[1823]\ttraining's auc: 0.850285\tvalid_1's auc: 0.787298\n",
      "[1824]\ttraining's auc: 0.850318\tvalid_1's auc: 0.787303\n",
      "[1825]\ttraining's auc: 0.850346\tvalid_1's auc: 0.787299\n",
      "[1826]\ttraining's auc: 0.850379\tvalid_1's auc: 0.787305\n",
      "[1827]\ttraining's auc: 0.850409\tvalid_1's auc: 0.787303\n",
      "[1828]\ttraining's auc: 0.850445\tvalid_1's auc: 0.787312\n",
      "[1829]\ttraining's auc: 0.850477\tvalid_1's auc: 0.787311\n",
      "[1830]\ttraining's auc: 0.85051\tvalid_1's auc: 0.787308\n",
      "[1831]\ttraining's auc: 0.850533\tvalid_1's auc: 0.787309\n",
      "[1832]\ttraining's auc: 0.850562\tvalid_1's auc: 0.787314\n",
      "[1833]\ttraining's auc: 0.85059\tvalid_1's auc: 0.787318\n",
      "[1834]\ttraining's auc: 0.850624\tvalid_1's auc: 0.787317\n",
      "[1835]\ttraining's auc: 0.850655\tvalid_1's auc: 0.787319\n",
      "[1836]\ttraining's auc: 0.850683\tvalid_1's auc: 0.787321\n",
      "[1837]\ttraining's auc: 0.850717\tvalid_1's auc: 0.787326\n",
      "[1838]\ttraining's auc: 0.850747\tvalid_1's auc: 0.787326\n",
      "[1839]\ttraining's auc: 0.850784\tvalid_1's auc: 0.787329\n",
      "[1840]\ttraining's auc: 0.850802\tvalid_1's auc: 0.787328\n",
      "[1841]\ttraining's auc: 0.850824\tvalid_1's auc: 0.787334\n",
      "[1842]\ttraining's auc: 0.850841\tvalid_1's auc: 0.787336\n",
      "[1843]\ttraining's auc: 0.850869\tvalid_1's auc: 0.787339\n",
      "[1844]\ttraining's auc: 0.850901\tvalid_1's auc: 0.787341\n",
      "[1845]\ttraining's auc: 0.850925\tvalid_1's auc: 0.787342\n",
      "[1846]\ttraining's auc: 0.850958\tvalid_1's auc: 0.78734\n",
      "[1847]\ttraining's auc: 0.85098\tvalid_1's auc: 0.787346\n",
      "[1848]\ttraining's auc: 0.851004\tvalid_1's auc: 0.78734\n",
      "[1849]\ttraining's auc: 0.851019\tvalid_1's auc: 0.787344\n",
      "[1850]\ttraining's auc: 0.851046\tvalid_1's auc: 0.787349\n",
      "[1851]\ttraining's auc: 0.85108\tvalid_1's auc: 0.787353\n",
      "[1852]\ttraining's auc: 0.851108\tvalid_1's auc: 0.787357\n",
      "[1853]\ttraining's auc: 0.851147\tvalid_1's auc: 0.787359\n",
      "[1854]\ttraining's auc: 0.851181\tvalid_1's auc: 0.787359\n",
      "[1855]\ttraining's auc: 0.851206\tvalid_1's auc: 0.787368\n",
      "[1856]\ttraining's auc: 0.851232\tvalid_1's auc: 0.787363\n",
      "[1857]\ttraining's auc: 0.851255\tvalid_1's auc: 0.787365\n",
      "[1858]\ttraining's auc: 0.851278\tvalid_1's auc: 0.787366\n",
      "[1859]\ttraining's auc: 0.851309\tvalid_1's auc: 0.787364\n",
      "[1860]\ttraining's auc: 0.851333\tvalid_1's auc: 0.787367\n",
      "[1861]\ttraining's auc: 0.851354\tvalid_1's auc: 0.787368\n",
      "[1862]\ttraining's auc: 0.851383\tvalid_1's auc: 0.787363\n",
      "[1863]\ttraining's auc: 0.85142\tvalid_1's auc: 0.787368\n",
      "[1864]\ttraining's auc: 0.851432\tvalid_1's auc: 0.787374\n",
      "[1865]\ttraining's auc: 0.851465\tvalid_1's auc: 0.787379\n",
      "[1866]\ttraining's auc: 0.851499\tvalid_1's auc: 0.787389\n",
      "[1867]\ttraining's auc: 0.851524\tvalid_1's auc: 0.787385\n",
      "[1868]\ttraining's auc: 0.851551\tvalid_1's auc: 0.787389\n",
      "[1869]\ttraining's auc: 0.85158\tvalid_1's auc: 0.787398\n",
      "[1870]\ttraining's auc: 0.851603\tvalid_1's auc: 0.787403\n",
      "[1871]\ttraining's auc: 0.851628\tvalid_1's auc: 0.787406\n",
      "[1872]\ttraining's auc: 0.851653\tvalid_1's auc: 0.78741\n",
      "[1873]\ttraining's auc: 0.851679\tvalid_1's auc: 0.787403\n",
      "[1874]\ttraining's auc: 0.851699\tvalid_1's auc: 0.787404\n",
      "[1875]\ttraining's auc: 0.851731\tvalid_1's auc: 0.787415\n",
      "[1876]\ttraining's auc: 0.851761\tvalid_1's auc: 0.787415\n",
      "[1877]\ttraining's auc: 0.851788\tvalid_1's auc: 0.787421\n",
      "[1878]\ttraining's auc: 0.851827\tvalid_1's auc: 0.787425\n",
      "[1879]\ttraining's auc: 0.851854\tvalid_1's auc: 0.787438\n",
      "[1880]\ttraining's auc: 0.851888\tvalid_1's auc: 0.787445\n",
      "[1881]\ttraining's auc: 0.851918\tvalid_1's auc: 0.787452\n",
      "[1882]\ttraining's auc: 0.851953\tvalid_1's auc: 0.787458\n",
      "[1883]\ttraining's auc: 0.851985\tvalid_1's auc: 0.787457\n",
      "[1884]\ttraining's auc: 0.852016\tvalid_1's auc: 0.78746\n",
      "[1885]\ttraining's auc: 0.852046\tvalid_1's auc: 0.787468\n",
      "[1886]\ttraining's auc: 0.852063\tvalid_1's auc: 0.787474\n",
      "[1887]\ttraining's auc: 0.852082\tvalid_1's auc: 0.787482\n",
      "[1888]\ttraining's auc: 0.852116\tvalid_1's auc: 0.787486\n",
      "[1889]\ttraining's auc: 0.852143\tvalid_1's auc: 0.787485\n",
      "[1890]\ttraining's auc: 0.852171\tvalid_1's auc: 0.787489\n",
      "[1891]\ttraining's auc: 0.852202\tvalid_1's auc: 0.787494\n",
      "[1892]\ttraining's auc: 0.85224\tvalid_1's auc: 0.787492\n",
      "[1893]\ttraining's auc: 0.852274\tvalid_1's auc: 0.7875\n",
      "[1894]\ttraining's auc: 0.852301\tvalid_1's auc: 0.787502\n",
      "[1895]\ttraining's auc: 0.852324\tvalid_1's auc: 0.787503\n",
      "[1896]\ttraining's auc: 0.852356\tvalid_1's auc: 0.787508\n",
      "[1897]\ttraining's auc: 0.852385\tvalid_1's auc: 0.787506\n",
      "[1898]\ttraining's auc: 0.852404\tvalid_1's auc: 0.787509\n",
      "[1899]\ttraining's auc: 0.852437\tvalid_1's auc: 0.787503\n",
      "[1900]\ttraining's auc: 0.852473\tvalid_1's auc: 0.787509\n",
      "[1901]\ttraining's auc: 0.852497\tvalid_1's auc: 0.787504\n",
      "[1902]\ttraining's auc: 0.852526\tvalid_1's auc: 0.787505\n",
      "[1903]\ttraining's auc: 0.852551\tvalid_1's auc: 0.787508\n",
      "[1904]\ttraining's auc: 0.852582\tvalid_1's auc: 0.78751\n",
      "[1905]\ttraining's auc: 0.852596\tvalid_1's auc: 0.787509\n",
      "[1906]\ttraining's auc: 0.852617\tvalid_1's auc: 0.787508\n",
      "[1907]\ttraining's auc: 0.852648\tvalid_1's auc: 0.787515\n",
      "[1908]\ttraining's auc: 0.852683\tvalid_1's auc: 0.787511\n",
      "[1909]\ttraining's auc: 0.852725\tvalid_1's auc: 0.78753\n",
      "[1910]\ttraining's auc: 0.852748\tvalid_1's auc: 0.787534\n",
      "[1911]\ttraining's auc: 0.852773\tvalid_1's auc: 0.787541\n",
      "[1912]\ttraining's auc: 0.852791\tvalid_1's auc: 0.787547\n",
      "[1913]\ttraining's auc: 0.852817\tvalid_1's auc: 0.787546\n",
      "[1914]\ttraining's auc: 0.852842\tvalid_1's auc: 0.787556\n",
      "[1915]\ttraining's auc: 0.852874\tvalid_1's auc: 0.787561\n",
      "[1916]\ttraining's auc: 0.852897\tvalid_1's auc: 0.787567\n",
      "[1917]\ttraining's auc: 0.852921\tvalid_1's auc: 0.787572\n",
      "[1918]\ttraining's auc: 0.852951\tvalid_1's auc: 0.78758\n",
      "[1919]\ttraining's auc: 0.85298\tvalid_1's auc: 0.787579\n",
      "[1920]\ttraining's auc: 0.853011\tvalid_1's auc: 0.787581\n",
      "[1921]\ttraining's auc: 0.853042\tvalid_1's auc: 0.78759\n",
      "[1922]\ttraining's auc: 0.853075\tvalid_1's auc: 0.787592\n",
      "[1923]\ttraining's auc: 0.853099\tvalid_1's auc: 0.787594\n",
      "[1924]\ttraining's auc: 0.853122\tvalid_1's auc: 0.787591\n",
      "[1925]\ttraining's auc: 0.853148\tvalid_1's auc: 0.787596\n",
      "[1926]\ttraining's auc: 0.853176\tvalid_1's auc: 0.787598\n",
      "[1927]\ttraining's auc: 0.85321\tvalid_1's auc: 0.787595\n",
      "[1928]\ttraining's auc: 0.853244\tvalid_1's auc: 0.787597\n",
      "[1929]\ttraining's auc: 0.853276\tvalid_1's auc: 0.78761\n",
      "[1930]\ttraining's auc: 0.853301\tvalid_1's auc: 0.787619\n",
      "[1931]\ttraining's auc: 0.853323\tvalid_1's auc: 0.787615\n",
      "[1932]\ttraining's auc: 0.853347\tvalid_1's auc: 0.787611\n",
      "[1933]\ttraining's auc: 0.853367\tvalid_1's auc: 0.787613\n",
      "[1934]\ttraining's auc: 0.853384\tvalid_1's auc: 0.78762\n",
      "[1935]\ttraining's auc: 0.853419\tvalid_1's auc: 0.787619\n",
      "[1936]\ttraining's auc: 0.853447\tvalid_1's auc: 0.787626\n",
      "[1937]\ttraining's auc: 0.853475\tvalid_1's auc: 0.787639\n",
      "[1938]\ttraining's auc: 0.8535\tvalid_1's auc: 0.787642\n",
      "[1939]\ttraining's auc: 0.853524\tvalid_1's auc: 0.787648\n",
      "[1940]\ttraining's auc: 0.853561\tvalid_1's auc: 0.787652\n",
      "[1941]\ttraining's auc: 0.853584\tvalid_1's auc: 0.787658\n",
      "[1942]\ttraining's auc: 0.853614\tvalid_1's auc: 0.787664\n",
      "[1943]\ttraining's auc: 0.853643\tvalid_1's auc: 0.787668\n",
      "[1944]\ttraining's auc: 0.853673\tvalid_1's auc: 0.787683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1945]\ttraining's auc: 0.853697\tvalid_1's auc: 0.787681\n",
      "[1946]\ttraining's auc: 0.853713\tvalid_1's auc: 0.787683\n",
      "[1947]\ttraining's auc: 0.853736\tvalid_1's auc: 0.787681\n",
      "[1948]\ttraining's auc: 0.853771\tvalid_1's auc: 0.787679\n",
      "[1949]\ttraining's auc: 0.853803\tvalid_1's auc: 0.787677\n",
      "[1950]\ttraining's auc: 0.853825\tvalid_1's auc: 0.787672\n",
      "[1951]\ttraining's auc: 0.853857\tvalid_1's auc: 0.787671\n",
      "[1952]\ttraining's auc: 0.853885\tvalid_1's auc: 0.787675\n",
      "[1953]\ttraining's auc: 0.853912\tvalid_1's auc: 0.787674\n",
      "[1954]\ttraining's auc: 0.853934\tvalid_1's auc: 0.787675\n",
      "[1955]\ttraining's auc: 0.853964\tvalid_1's auc: 0.787678\n",
      "[1956]\ttraining's auc: 0.853993\tvalid_1's auc: 0.787677\n",
      "[1957]\ttraining's auc: 0.854025\tvalid_1's auc: 0.787669\n",
      "[1958]\ttraining's auc: 0.854058\tvalid_1's auc: 0.787676\n",
      "[1959]\ttraining's auc: 0.854081\tvalid_1's auc: 0.787674\n",
      "[1960]\ttraining's auc: 0.854112\tvalid_1's auc: 0.787679\n",
      "[1961]\ttraining's auc: 0.854127\tvalid_1's auc: 0.787679\n",
      "[1962]\ttraining's auc: 0.854159\tvalid_1's auc: 0.78768\n",
      "[1963]\ttraining's auc: 0.854175\tvalid_1's auc: 0.78768\n",
      "[1964]\ttraining's auc: 0.854209\tvalid_1's auc: 0.78768\n",
      "[1965]\ttraining's auc: 0.854239\tvalid_1's auc: 0.787686\n",
      "[1966]\ttraining's auc: 0.854266\tvalid_1's auc: 0.787684\n",
      "[1967]\ttraining's auc: 0.854301\tvalid_1's auc: 0.787685\n",
      "[1968]\ttraining's auc: 0.854329\tvalid_1's auc: 0.787689\n",
      "[1969]\ttraining's auc: 0.854354\tvalid_1's auc: 0.787702\n",
      "[1970]\ttraining's auc: 0.854388\tvalid_1's auc: 0.78771\n",
      "[1971]\ttraining's auc: 0.854416\tvalid_1's auc: 0.787709\n",
      "[1972]\ttraining's auc: 0.854448\tvalid_1's auc: 0.787716\n",
      "[1973]\ttraining's auc: 0.854476\tvalid_1's auc: 0.78772\n",
      "[1974]\ttraining's auc: 0.854503\tvalid_1's auc: 0.787718\n",
      "[1975]\ttraining's auc: 0.854528\tvalid_1's auc: 0.787723\n",
      "[1976]\ttraining's auc: 0.854553\tvalid_1's auc: 0.787718\n",
      "[1977]\ttraining's auc: 0.854586\tvalid_1's auc: 0.787718\n",
      "[1978]\ttraining's auc: 0.854617\tvalid_1's auc: 0.787719\n",
      "[1979]\ttraining's auc: 0.854646\tvalid_1's auc: 0.787715\n",
      "[1980]\ttraining's auc: 0.85467\tvalid_1's auc: 0.787724\n",
      "[1981]\ttraining's auc: 0.854701\tvalid_1's auc: 0.787722\n",
      "[1982]\ttraining's auc: 0.854728\tvalid_1's auc: 0.787722\n",
      "[1983]\ttraining's auc: 0.854765\tvalid_1's auc: 0.787727\n",
      "[1984]\ttraining's auc: 0.854789\tvalid_1's auc: 0.787731\n",
      "[1985]\ttraining's auc: 0.854807\tvalid_1's auc: 0.787733\n",
      "[1986]\ttraining's auc: 0.854827\tvalid_1's auc: 0.787735\n",
      "[1987]\ttraining's auc: 0.854857\tvalid_1's auc: 0.787732\n",
      "[1988]\ttraining's auc: 0.854884\tvalid_1's auc: 0.787733\n",
      "[1989]\ttraining's auc: 0.854912\tvalid_1's auc: 0.787732\n",
      "[1990]\ttraining's auc: 0.854937\tvalid_1's auc: 0.787734\n",
      "[1991]\ttraining's auc: 0.854959\tvalid_1's auc: 0.787733\n",
      "[1992]\ttraining's auc: 0.854976\tvalid_1's auc: 0.787731\n",
      "[1993]\ttraining's auc: 0.854986\tvalid_1's auc: 0.78773\n",
      "[1994]\ttraining's auc: 0.855016\tvalid_1's auc: 0.78773\n",
      "[1995]\ttraining's auc: 0.855042\tvalid_1's auc: 0.78773\n",
      "[1996]\ttraining's auc: 0.855066\tvalid_1's auc: 0.787735\n",
      "[1997]\ttraining's auc: 0.855087\tvalid_1's auc: 0.787744\n",
      "[1998]\ttraining's auc: 0.855115\tvalid_1's auc: 0.787754\n",
      "[1999]\ttraining's auc: 0.85514\tvalid_1's auc: 0.787761\n",
      "[2000]\ttraining's auc: 0.855151\tvalid_1's auc: 0.787763\n",
      "[2001]\ttraining's auc: 0.855166\tvalid_1's auc: 0.787761\n",
      "[2002]\ttraining's auc: 0.855199\tvalid_1's auc: 0.787753\n",
      "[2003]\ttraining's auc: 0.855227\tvalid_1's auc: 0.787757\n",
      "[2004]\ttraining's auc: 0.855259\tvalid_1's auc: 0.787768\n",
      "[2005]\ttraining's auc: 0.855292\tvalid_1's auc: 0.787772\n",
      "[2006]\ttraining's auc: 0.855319\tvalid_1's auc: 0.787769\n",
      "[2007]\ttraining's auc: 0.855345\tvalid_1's auc: 0.787767\n",
      "[2008]\ttraining's auc: 0.855368\tvalid_1's auc: 0.787768\n",
      "[2009]\ttraining's auc: 0.8554\tvalid_1's auc: 0.787784\n",
      "[2010]\ttraining's auc: 0.855425\tvalid_1's auc: 0.787784\n",
      "[2011]\ttraining's auc: 0.855456\tvalid_1's auc: 0.787786\n",
      "[2012]\ttraining's auc: 0.855475\tvalid_1's auc: 0.78779\n",
      "[2013]\ttraining's auc: 0.855496\tvalid_1's auc: 0.787798\n",
      "[2014]\ttraining's auc: 0.855528\tvalid_1's auc: 0.787795\n",
      "[2015]\ttraining's auc: 0.855558\tvalid_1's auc: 0.787798\n",
      "[2016]\ttraining's auc: 0.855588\tvalid_1's auc: 0.787801\n",
      "[2017]\ttraining's auc: 0.85561\tvalid_1's auc: 0.787805\n",
      "[2018]\ttraining's auc: 0.855635\tvalid_1's auc: 0.787813\n",
      "[2019]\ttraining's auc: 0.855659\tvalid_1's auc: 0.787819\n",
      "[2020]\ttraining's auc: 0.855687\tvalid_1's auc: 0.787821\n",
      "[2021]\ttraining's auc: 0.855705\tvalid_1's auc: 0.787824\n",
      "[2022]\ttraining's auc: 0.855731\tvalid_1's auc: 0.787824\n",
      "[2023]\ttraining's auc: 0.855763\tvalid_1's auc: 0.787829\n",
      "[2024]\ttraining's auc: 0.855782\tvalid_1's auc: 0.787833\n",
      "[2025]\ttraining's auc: 0.855809\tvalid_1's auc: 0.787837\n",
      "[2026]\ttraining's auc: 0.855839\tvalid_1's auc: 0.787839\n",
      "[2027]\ttraining's auc: 0.855873\tvalid_1's auc: 0.787835\n",
      "[2028]\ttraining's auc: 0.855897\tvalid_1's auc: 0.787831\n",
      "[2029]\ttraining's auc: 0.855916\tvalid_1's auc: 0.787835\n",
      "[2030]\ttraining's auc: 0.855939\tvalid_1's auc: 0.787835\n",
      "[2031]\ttraining's auc: 0.855959\tvalid_1's auc: 0.787834\n",
      "[2032]\ttraining's auc: 0.855982\tvalid_1's auc: 0.787845\n",
      "[2033]\ttraining's auc: 0.85601\tvalid_1's auc: 0.787843\n",
      "[2034]\ttraining's auc: 0.856035\tvalid_1's auc: 0.787847\n",
      "[2035]\ttraining's auc: 0.856059\tvalid_1's auc: 0.787853\n",
      "[2036]\ttraining's auc: 0.85608\tvalid_1's auc: 0.787852\n",
      "[2037]\ttraining's auc: 0.856111\tvalid_1's auc: 0.787861\n",
      "[2038]\ttraining's auc: 0.856134\tvalid_1's auc: 0.787859\n",
      "[2039]\ttraining's auc: 0.856157\tvalid_1's auc: 0.787861\n",
      "[2040]\ttraining's auc: 0.856184\tvalid_1's auc: 0.787857\n",
      "[2041]\ttraining's auc: 0.856214\tvalid_1's auc: 0.787859\n",
      "[2042]\ttraining's auc: 0.856247\tvalid_1's auc: 0.787863\n",
      "[2043]\ttraining's auc: 0.856278\tvalid_1's auc: 0.787862\n",
      "[2044]\ttraining's auc: 0.856306\tvalid_1's auc: 0.787864\n",
      "[2045]\ttraining's auc: 0.856338\tvalid_1's auc: 0.787866\n",
      "[2046]\ttraining's auc: 0.856367\tvalid_1's auc: 0.787865\n",
      "[2047]\ttraining's auc: 0.856397\tvalid_1's auc: 0.787867\n",
      "[2048]\ttraining's auc: 0.856427\tvalid_1's auc: 0.787868\n",
      "[2049]\ttraining's auc: 0.856447\tvalid_1's auc: 0.787867\n",
      "[2050]\ttraining's auc: 0.856468\tvalid_1's auc: 0.787867\n",
      "[2051]\ttraining's auc: 0.856492\tvalid_1's auc: 0.78787\n",
      "[2052]\ttraining's auc: 0.85652\tvalid_1's auc: 0.787873\n",
      "[2053]\ttraining's auc: 0.856565\tvalid_1's auc: 0.787884\n",
      "[2054]\ttraining's auc: 0.856598\tvalid_1's auc: 0.787887\n",
      "[2055]\ttraining's auc: 0.856626\tvalid_1's auc: 0.787892\n",
      "[2056]\ttraining's auc: 0.856643\tvalid_1's auc: 0.787889\n",
      "[2057]\ttraining's auc: 0.856672\tvalid_1's auc: 0.787907\n",
      "[2058]\ttraining's auc: 0.856704\tvalid_1's auc: 0.787913\n",
      "[2059]\ttraining's auc: 0.85673\tvalid_1's auc: 0.787915\n",
      "[2060]\ttraining's auc: 0.856758\tvalid_1's auc: 0.787919\n",
      "[2061]\ttraining's auc: 0.856786\tvalid_1's auc: 0.78792\n",
      "[2062]\ttraining's auc: 0.85682\tvalid_1's auc: 0.787917\n",
      "[2063]\ttraining's auc: 0.856847\tvalid_1's auc: 0.78792\n",
      "[2064]\ttraining's auc: 0.856872\tvalid_1's auc: 0.787922\n",
      "[2065]\ttraining's auc: 0.856897\tvalid_1's auc: 0.787915\n",
      "[2066]\ttraining's auc: 0.856925\tvalid_1's auc: 0.787911\n",
      "[2067]\ttraining's auc: 0.856944\tvalid_1's auc: 0.787911\n",
      "[2068]\ttraining's auc: 0.856966\tvalid_1's auc: 0.787916\n",
      "[2069]\ttraining's auc: 0.856991\tvalid_1's auc: 0.787918\n",
      "[2070]\ttraining's auc: 0.857018\tvalid_1's auc: 0.787933\n",
      "[2071]\ttraining's auc: 0.857042\tvalid_1's auc: 0.787928\n",
      "[2072]\ttraining's auc: 0.857064\tvalid_1's auc: 0.787925\n",
      "[2073]\ttraining's auc: 0.857093\tvalid_1's auc: 0.787928\n",
      "[2074]\ttraining's auc: 0.857123\tvalid_1's auc: 0.787934\n",
      "[2075]\ttraining's auc: 0.857148\tvalid_1's auc: 0.787939\n",
      "[2076]\ttraining's auc: 0.857174\tvalid_1's auc: 0.78794\n",
      "[2077]\ttraining's auc: 0.8572\tvalid_1's auc: 0.787947\n",
      "[2078]\ttraining's auc: 0.857224\tvalid_1's auc: 0.787948\n",
      "[2079]\ttraining's auc: 0.857253\tvalid_1's auc: 0.787953\n",
      "[2080]\ttraining's auc: 0.857284\tvalid_1's auc: 0.787956\n",
      "[2081]\ttraining's auc: 0.857309\tvalid_1's auc: 0.787956\n",
      "[2082]\ttraining's auc: 0.857337\tvalid_1's auc: 0.787957\n",
      "[2083]\ttraining's auc: 0.857363\tvalid_1's auc: 0.787961\n",
      "[2084]\ttraining's auc: 0.857394\tvalid_1's auc: 0.787954\n",
      "[2085]\ttraining's auc: 0.857418\tvalid_1's auc: 0.787952\n",
      "[2086]\ttraining's auc: 0.857449\tvalid_1's auc: 0.787956\n",
      "[2087]\ttraining's auc: 0.857476\tvalid_1's auc: 0.787957\n",
      "[2088]\ttraining's auc: 0.857498\tvalid_1's auc: 0.787951\n",
      "[2089]\ttraining's auc: 0.857519\tvalid_1's auc: 0.787967\n",
      "[2090]\ttraining's auc: 0.857544\tvalid_1's auc: 0.787969\n",
      "[2091]\ttraining's auc: 0.857579\tvalid_1's auc: 0.787974\n",
      "[2092]\ttraining's auc: 0.857607\tvalid_1's auc: 0.787974\n",
      "[2093]\ttraining's auc: 0.857633\tvalid_1's auc: 0.787974\n",
      "[2094]\ttraining's auc: 0.857665\tvalid_1's auc: 0.787973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2095]\ttraining's auc: 0.857683\tvalid_1's auc: 0.787973\n",
      "[2096]\ttraining's auc: 0.857711\tvalid_1's auc: 0.787986\n",
      "[2097]\ttraining's auc: 0.857734\tvalid_1's auc: 0.787988\n",
      "[2098]\ttraining's auc: 0.857759\tvalid_1's auc: 0.787992\n",
      "[2099]\ttraining's auc: 0.857788\tvalid_1's auc: 0.787993\n",
      "[2100]\ttraining's auc: 0.857809\tvalid_1's auc: 0.787995\n",
      "[2101]\ttraining's auc: 0.857832\tvalid_1's auc: 0.787996\n",
      "[2102]\ttraining's auc: 0.857856\tvalid_1's auc: 0.787994\n",
      "[2103]\ttraining's auc: 0.857873\tvalid_1's auc: 0.787995\n",
      "[2104]\ttraining's auc: 0.857893\tvalid_1's auc: 0.787998\n",
      "[2105]\ttraining's auc: 0.857919\tvalid_1's auc: 0.788003\n",
      "[2106]\ttraining's auc: 0.857943\tvalid_1's auc: 0.788007\n",
      "[2107]\ttraining's auc: 0.85797\tvalid_1's auc: 0.788008\n",
      "[2108]\ttraining's auc: 0.857999\tvalid_1's auc: 0.788008\n",
      "[2109]\ttraining's auc: 0.858026\tvalid_1's auc: 0.78801\n",
      "[2110]\ttraining's auc: 0.858046\tvalid_1's auc: 0.788014\n",
      "[2111]\ttraining's auc: 0.858069\tvalid_1's auc: 0.788026\n",
      "[2112]\ttraining's auc: 0.858097\tvalid_1's auc: 0.788028\n",
      "[2113]\ttraining's auc: 0.858125\tvalid_1's auc: 0.788032\n",
      "[2114]\ttraining's auc: 0.858153\tvalid_1's auc: 0.788032\n",
      "[2115]\ttraining's auc: 0.858188\tvalid_1's auc: 0.788032\n",
      "[2116]\ttraining's auc: 0.858213\tvalid_1's auc: 0.788033\n",
      "[2117]\ttraining's auc: 0.858234\tvalid_1's auc: 0.788032\n",
      "[2118]\ttraining's auc: 0.858266\tvalid_1's auc: 0.78804\n",
      "[2119]\ttraining's auc: 0.858298\tvalid_1's auc: 0.788049\n",
      "[2120]\ttraining's auc: 0.858327\tvalid_1's auc: 0.78805\n",
      "[2121]\ttraining's auc: 0.858349\tvalid_1's auc: 0.788056\n",
      "[2122]\ttraining's auc: 0.858371\tvalid_1's auc: 0.788058\n",
      "[2123]\ttraining's auc: 0.858401\tvalid_1's auc: 0.788067\n",
      "[2124]\ttraining's auc: 0.85843\tvalid_1's auc: 0.788072\n",
      "[2125]\ttraining's auc: 0.858458\tvalid_1's auc: 0.788069\n",
      "[2126]\ttraining's auc: 0.858487\tvalid_1's auc: 0.788075\n",
      "[2127]\ttraining's auc: 0.858513\tvalid_1's auc: 0.788077\n",
      "[2128]\ttraining's auc: 0.858533\tvalid_1's auc: 0.788072\n",
      "[2129]\ttraining's auc: 0.85856\tvalid_1's auc: 0.788077\n",
      "[2130]\ttraining's auc: 0.858586\tvalid_1's auc: 0.788079\n",
      "[2131]\ttraining's auc: 0.858615\tvalid_1's auc: 0.788088\n",
      "[2132]\ttraining's auc: 0.858642\tvalid_1's auc: 0.788088\n",
      "[2133]\ttraining's auc: 0.858665\tvalid_1's auc: 0.788089\n",
      "[2134]\ttraining's auc: 0.8587\tvalid_1's auc: 0.788103\n",
      "[2135]\ttraining's auc: 0.858726\tvalid_1's auc: 0.788105\n",
      "[2136]\ttraining's auc: 0.85874\tvalid_1's auc: 0.78811\n",
      "[2137]\ttraining's auc: 0.858764\tvalid_1's auc: 0.788113\n",
      "[2138]\ttraining's auc: 0.858791\tvalid_1's auc: 0.788115\n",
      "[2139]\ttraining's auc: 0.858827\tvalid_1's auc: 0.788109\n",
      "[2140]\ttraining's auc: 0.858851\tvalid_1's auc: 0.788112\n",
      "[2141]\ttraining's auc: 0.858888\tvalid_1's auc: 0.788115\n",
      "[2142]\ttraining's auc: 0.85891\tvalid_1's auc: 0.78812\n",
      "[2143]\ttraining's auc: 0.858947\tvalid_1's auc: 0.788126\n",
      "[2144]\ttraining's auc: 0.858967\tvalid_1's auc: 0.788127\n",
      "[2145]\ttraining's auc: 0.859002\tvalid_1's auc: 0.788123\n",
      "[2146]\ttraining's auc: 0.859031\tvalid_1's auc: 0.788121\n",
      "[2147]\ttraining's auc: 0.859057\tvalid_1's auc: 0.788124\n",
      "[2148]\ttraining's auc: 0.859081\tvalid_1's auc: 0.788129\n",
      "[2149]\ttraining's auc: 0.8591\tvalid_1's auc: 0.788123\n",
      "[2150]\ttraining's auc: 0.859131\tvalid_1's auc: 0.788128\n",
      "[2151]\ttraining's auc: 0.859166\tvalid_1's auc: 0.788125\n",
      "[2152]\ttraining's auc: 0.859191\tvalid_1's auc: 0.788123\n",
      "[2153]\ttraining's auc: 0.859214\tvalid_1's auc: 0.788121\n",
      "[2154]\ttraining's auc: 0.859244\tvalid_1's auc: 0.788121\n",
      "[2155]\ttraining's auc: 0.859275\tvalid_1's auc: 0.788129\n",
      "[2156]\ttraining's auc: 0.859289\tvalid_1's auc: 0.788126\n",
      "[2157]\ttraining's auc: 0.859311\tvalid_1's auc: 0.788126\n",
      "[2158]\ttraining's auc: 0.859337\tvalid_1's auc: 0.788127\n",
      "[2159]\ttraining's auc: 0.859355\tvalid_1's auc: 0.788131\n",
      "[2160]\ttraining's auc: 0.859389\tvalid_1's auc: 0.788136\n",
      "[2161]\ttraining's auc: 0.859413\tvalid_1's auc: 0.788137\n",
      "[2162]\ttraining's auc: 0.859428\tvalid_1's auc: 0.788139\n",
      "[2163]\ttraining's auc: 0.85946\tvalid_1's auc: 0.788143\n",
      "[2164]\ttraining's auc: 0.859501\tvalid_1's auc: 0.78815\n",
      "[2165]\ttraining's auc: 0.859527\tvalid_1's auc: 0.788159\n",
      "[2166]\ttraining's auc: 0.859539\tvalid_1's auc: 0.78816\n",
      "[2167]\ttraining's auc: 0.859566\tvalid_1's auc: 0.78816\n",
      "[2168]\ttraining's auc: 0.859593\tvalid_1's auc: 0.788163\n",
      "[2169]\ttraining's auc: 0.859625\tvalid_1's auc: 0.78816\n",
      "[2170]\ttraining's auc: 0.859641\tvalid_1's auc: 0.788163\n",
      "[2171]\ttraining's auc: 0.859664\tvalid_1's auc: 0.788164\n",
      "[2172]\ttraining's auc: 0.859686\tvalid_1's auc: 0.788165\n",
      "[2173]\ttraining's auc: 0.859715\tvalid_1's auc: 0.788166\n",
      "[2174]\ttraining's auc: 0.859744\tvalid_1's auc: 0.788171\n",
      "[2175]\ttraining's auc: 0.85977\tvalid_1's auc: 0.78817\n",
      "[2176]\ttraining's auc: 0.859799\tvalid_1's auc: 0.788171\n",
      "[2177]\ttraining's auc: 0.859831\tvalid_1's auc: 0.788164\n",
      "[2178]\ttraining's auc: 0.859846\tvalid_1's auc: 0.788166\n",
      "[2179]\ttraining's auc: 0.859868\tvalid_1's auc: 0.788169\n",
      "[2180]\ttraining's auc: 0.859894\tvalid_1's auc: 0.788171\n",
      "[2181]\ttraining's auc: 0.859911\tvalid_1's auc: 0.788171\n",
      "[2182]\ttraining's auc: 0.859935\tvalid_1's auc: 0.788178\n",
      "[2183]\ttraining's auc: 0.859963\tvalid_1's auc: 0.788185\n",
      "[2184]\ttraining's auc: 0.859992\tvalid_1's auc: 0.788188\n",
      "[2185]\ttraining's auc: 0.860029\tvalid_1's auc: 0.788189\n",
      "[2186]\ttraining's auc: 0.860056\tvalid_1's auc: 0.788196\n",
      "[2187]\ttraining's auc: 0.860088\tvalid_1's auc: 0.788201\n",
      "[2188]\ttraining's auc: 0.860114\tvalid_1's auc: 0.788204\n",
      "[2189]\ttraining's auc: 0.860142\tvalid_1's auc: 0.788209\n",
      "[2190]\ttraining's auc: 0.860177\tvalid_1's auc: 0.788212\n",
      "[2191]\ttraining's auc: 0.860201\tvalid_1's auc: 0.788212\n",
      "[2192]\ttraining's auc: 0.860234\tvalid_1's auc: 0.788222\n",
      "[2193]\ttraining's auc: 0.860251\tvalid_1's auc: 0.788225\n",
      "[2194]\ttraining's auc: 0.860275\tvalid_1's auc: 0.788228\n",
      "[2195]\ttraining's auc: 0.860292\tvalid_1's auc: 0.788225\n",
      "[2196]\ttraining's auc: 0.860322\tvalid_1's auc: 0.788228\n",
      "[2197]\ttraining's auc: 0.860343\tvalid_1's auc: 0.788236\n",
      "[2198]\ttraining's auc: 0.860373\tvalid_1's auc: 0.788237\n",
      "[2199]\ttraining's auc: 0.860398\tvalid_1's auc: 0.788236\n",
      "[2200]\ttraining's auc: 0.860422\tvalid_1's auc: 0.788234\n",
      "[2201]\ttraining's auc: 0.860445\tvalid_1's auc: 0.788234\n",
      "[2202]\ttraining's auc: 0.860466\tvalid_1's auc: 0.788233\n",
      "[2203]\ttraining's auc: 0.860504\tvalid_1's auc: 0.788238\n",
      "[2204]\ttraining's auc: 0.86052\tvalid_1's auc: 0.788245\n",
      "[2205]\ttraining's auc: 0.860556\tvalid_1's auc: 0.788243\n",
      "[2206]\ttraining's auc: 0.860586\tvalid_1's auc: 0.788251\n",
      "[2207]\ttraining's auc: 0.860614\tvalid_1's auc: 0.788255\n",
      "[2208]\ttraining's auc: 0.860641\tvalid_1's auc: 0.78826\n",
      "[2209]\ttraining's auc: 0.860672\tvalid_1's auc: 0.788264\n",
      "[2210]\ttraining's auc: 0.860687\tvalid_1's auc: 0.788266\n",
      "[2211]\ttraining's auc: 0.860712\tvalid_1's auc: 0.788268\n",
      "[2212]\ttraining's auc: 0.860741\tvalid_1's auc: 0.788265\n",
      "[2213]\ttraining's auc: 0.860767\tvalid_1's auc: 0.788269\n",
      "[2214]\ttraining's auc: 0.86079\tvalid_1's auc: 0.788269\n",
      "[2215]\ttraining's auc: 0.860809\tvalid_1's auc: 0.788276\n",
      "[2216]\ttraining's auc: 0.860835\tvalid_1's auc: 0.788285\n",
      "[2217]\ttraining's auc: 0.860862\tvalid_1's auc: 0.788285\n",
      "[2218]\ttraining's auc: 0.860884\tvalid_1's auc: 0.788285\n",
      "[2219]\ttraining's auc: 0.860909\tvalid_1's auc: 0.78829\n",
      "[2220]\ttraining's auc: 0.860937\tvalid_1's auc: 0.788289\n",
      "[2221]\ttraining's auc: 0.860956\tvalid_1's auc: 0.788289\n",
      "[2222]\ttraining's auc: 0.860981\tvalid_1's auc: 0.788287\n",
      "[2223]\ttraining's auc: 0.861003\tvalid_1's auc: 0.788286\n",
      "[2224]\ttraining's auc: 0.861022\tvalid_1's auc: 0.788292\n",
      "[2225]\ttraining's auc: 0.861042\tvalid_1's auc: 0.788298\n",
      "[2226]\ttraining's auc: 0.861071\tvalid_1's auc: 0.788299\n",
      "[2227]\ttraining's auc: 0.861087\tvalid_1's auc: 0.788299\n",
      "[2228]\ttraining's auc: 0.861119\tvalid_1's auc: 0.788304\n",
      "[2229]\ttraining's auc: 0.861147\tvalid_1's auc: 0.788307\n",
      "[2230]\ttraining's auc: 0.861169\tvalid_1's auc: 0.788309\n",
      "[2231]\ttraining's auc: 0.861191\tvalid_1's auc: 0.788312\n",
      "[2232]\ttraining's auc: 0.861219\tvalid_1's auc: 0.788309\n",
      "[2233]\ttraining's auc: 0.861246\tvalid_1's auc: 0.788311\n",
      "[2234]\ttraining's auc: 0.861268\tvalid_1's auc: 0.788309\n",
      "[2235]\ttraining's auc: 0.861301\tvalid_1's auc: 0.788322\n",
      "[2236]\ttraining's auc: 0.861325\tvalid_1's auc: 0.788321\n",
      "[2237]\ttraining's auc: 0.861346\tvalid_1's auc: 0.788322\n",
      "[2238]\ttraining's auc: 0.86137\tvalid_1's auc: 0.788317\n",
      "[2239]\ttraining's auc: 0.861382\tvalid_1's auc: 0.788316\n",
      "[2240]\ttraining's auc: 0.86141\tvalid_1's auc: 0.788324\n",
      "[2241]\ttraining's auc: 0.861435\tvalid_1's auc: 0.788329\n",
      "[2242]\ttraining's auc: 0.861466\tvalid_1's auc: 0.78833\n",
      "[2243]\ttraining's auc: 0.861492\tvalid_1's auc: 0.788336\n",
      "[2244]\ttraining's auc: 0.861516\tvalid_1's auc: 0.788339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2245]\ttraining's auc: 0.861541\tvalid_1's auc: 0.788332\n",
      "[2246]\ttraining's auc: 0.86156\tvalid_1's auc: 0.788332\n",
      "[2247]\ttraining's auc: 0.861585\tvalid_1's auc: 0.788326\n",
      "[2248]\ttraining's auc: 0.861604\tvalid_1's auc: 0.788336\n",
      "[2249]\ttraining's auc: 0.861637\tvalid_1's auc: 0.788338\n",
      "[2250]\ttraining's auc: 0.86166\tvalid_1's auc: 0.788342\n",
      "[2251]\ttraining's auc: 0.861688\tvalid_1's auc: 0.788348\n",
      "[2252]\ttraining's auc: 0.861711\tvalid_1's auc: 0.78835\n",
      "[2253]\ttraining's auc: 0.861735\tvalid_1's auc: 0.788352\n",
      "[2254]\ttraining's auc: 0.861757\tvalid_1's auc: 0.788351\n",
      "[2255]\ttraining's auc: 0.861787\tvalid_1's auc: 0.78835\n",
      "[2256]\ttraining's auc: 0.86182\tvalid_1's auc: 0.788352\n",
      "[2257]\ttraining's auc: 0.861835\tvalid_1's auc: 0.788357\n",
      "[2258]\ttraining's auc: 0.861859\tvalid_1's auc: 0.78836\n",
      "[2259]\ttraining's auc: 0.861902\tvalid_1's auc: 0.788368\n",
      "[2260]\ttraining's auc: 0.861926\tvalid_1's auc: 0.78837\n",
      "[2261]\ttraining's auc: 0.861947\tvalid_1's auc: 0.788366\n",
      "[2262]\ttraining's auc: 0.861974\tvalid_1's auc: 0.788362\n",
      "[2263]\ttraining's auc: 0.861999\tvalid_1's auc: 0.788363\n",
      "[2264]\ttraining's auc: 0.862021\tvalid_1's auc: 0.788363\n",
      "[2265]\ttraining's auc: 0.86206\tvalid_1's auc: 0.788367\n",
      "[2266]\ttraining's auc: 0.862085\tvalid_1's auc: 0.78837\n",
      "[2267]\ttraining's auc: 0.862106\tvalid_1's auc: 0.788366\n",
      "[2268]\ttraining's auc: 0.862129\tvalid_1's auc: 0.788367\n",
      "[2269]\ttraining's auc: 0.862158\tvalid_1's auc: 0.788363\n",
      "[2270]\ttraining's auc: 0.862181\tvalid_1's auc: 0.788363\n",
      "[2271]\ttraining's auc: 0.862207\tvalid_1's auc: 0.788357\n",
      "[2272]\ttraining's auc: 0.862216\tvalid_1's auc: 0.788359\n",
      "[2273]\ttraining's auc: 0.86224\tvalid_1's auc: 0.78836\n",
      "[2274]\ttraining's auc: 0.862262\tvalid_1's auc: 0.788363\n",
      "[2275]\ttraining's auc: 0.862284\tvalid_1's auc: 0.788366\n",
      "[2276]\ttraining's auc: 0.862306\tvalid_1's auc: 0.788371\n",
      "[2277]\ttraining's auc: 0.862326\tvalid_1's auc: 0.788371\n",
      "[2278]\ttraining's auc: 0.862354\tvalid_1's auc: 0.788371\n",
      "[2279]\ttraining's auc: 0.862374\tvalid_1's auc: 0.788371\n",
      "[2280]\ttraining's auc: 0.862396\tvalid_1's auc: 0.78837\n",
      "[2281]\ttraining's auc: 0.862432\tvalid_1's auc: 0.788365\n",
      "[2282]\ttraining's auc: 0.862462\tvalid_1's auc: 0.788364\n",
      "[2283]\ttraining's auc: 0.862486\tvalid_1's auc: 0.788366\n",
      "[2284]\ttraining's auc: 0.862519\tvalid_1's auc: 0.788366\n",
      "[2285]\ttraining's auc: 0.862523\tvalid_1's auc: 0.788366\n",
      "[2286]\ttraining's auc: 0.862555\tvalid_1's auc: 0.788368\n",
      "[2287]\ttraining's auc: 0.862558\tvalid_1's auc: 0.78837\n",
      "[2288]\ttraining's auc: 0.862579\tvalid_1's auc: 0.788373\n",
      "[2289]\ttraining's auc: 0.862599\tvalid_1's auc: 0.788373\n",
      "[2290]\ttraining's auc: 0.862625\tvalid_1's auc: 0.788372\n",
      "[2291]\ttraining's auc: 0.862651\tvalid_1's auc: 0.788376\n",
      "[2292]\ttraining's auc: 0.862672\tvalid_1's auc: 0.788378\n",
      "[2293]\ttraining's auc: 0.862695\tvalid_1's auc: 0.788381\n",
      "[2294]\ttraining's auc: 0.862702\tvalid_1's auc: 0.788383\n",
      "[2295]\ttraining's auc: 0.862723\tvalid_1's auc: 0.78838\n",
      "[2296]\ttraining's auc: 0.86275\tvalid_1's auc: 0.78837\n",
      "[2297]\ttraining's auc: 0.86277\tvalid_1's auc: 0.788374\n",
      "[2298]\ttraining's auc: 0.862788\tvalid_1's auc: 0.788378\n",
      "[2299]\ttraining's auc: 0.862809\tvalid_1's auc: 0.788385\n",
      "[2300]\ttraining's auc: 0.862831\tvalid_1's auc: 0.78839\n",
      "[2301]\ttraining's auc: 0.86286\tvalid_1's auc: 0.788391\n",
      "[2302]\ttraining's auc: 0.862888\tvalid_1's auc: 0.788389\n",
      "[2303]\ttraining's auc: 0.862911\tvalid_1's auc: 0.788393\n",
      "[2304]\ttraining's auc: 0.862945\tvalid_1's auc: 0.788388\n",
      "[2305]\ttraining's auc: 0.862964\tvalid_1's auc: 0.788389\n",
      "[2306]\ttraining's auc: 0.862985\tvalid_1's auc: 0.788391\n",
      "[2307]\ttraining's auc: 0.863003\tvalid_1's auc: 0.788396\n",
      "[2308]\ttraining's auc: 0.86303\tvalid_1's auc: 0.788396\n",
      "[2309]\ttraining's auc: 0.863053\tvalid_1's auc: 0.78839\n",
      "[2310]\ttraining's auc: 0.863077\tvalid_1's auc: 0.788392\n",
      "[2311]\ttraining's auc: 0.86311\tvalid_1's auc: 0.788391\n",
      "[2312]\ttraining's auc: 0.863138\tvalid_1's auc: 0.788391\n",
      "[2313]\ttraining's auc: 0.863166\tvalid_1's auc: 0.788384\n",
      "[2314]\ttraining's auc: 0.863193\tvalid_1's auc: 0.788384\n",
      "[2315]\ttraining's auc: 0.863223\tvalid_1's auc: 0.788387\n",
      "[2316]\ttraining's auc: 0.863252\tvalid_1's auc: 0.788387\n",
      "[2317]\ttraining's auc: 0.863275\tvalid_1's auc: 0.788394\n",
      "[2318]\ttraining's auc: 0.863299\tvalid_1's auc: 0.788392\n",
      "[2319]\ttraining's auc: 0.863321\tvalid_1's auc: 0.788394\n",
      "[2320]\ttraining's auc: 0.863344\tvalid_1's auc: 0.788395\n",
      "[2321]\ttraining's auc: 0.86337\tvalid_1's auc: 0.788395\n",
      "[2322]\ttraining's auc: 0.863393\tvalid_1's auc: 0.788397\n",
      "[2323]\ttraining's auc: 0.86342\tvalid_1's auc: 0.788409\n",
      "[2324]\ttraining's auc: 0.863445\tvalid_1's auc: 0.788408\n",
      "[2325]\ttraining's auc: 0.863472\tvalid_1's auc: 0.788411\n",
      "[2326]\ttraining's auc: 0.863503\tvalid_1's auc: 0.788408\n",
      "[2327]\ttraining's auc: 0.863535\tvalid_1's auc: 0.788413\n",
      "[2328]\ttraining's auc: 0.863562\tvalid_1's auc: 0.78841\n",
      "[2329]\ttraining's auc: 0.863596\tvalid_1's auc: 0.788423\n",
      "[2330]\ttraining's auc: 0.863625\tvalid_1's auc: 0.788421\n",
      "[2331]\ttraining's auc: 0.86365\tvalid_1's auc: 0.788421\n",
      "[2332]\ttraining's auc: 0.863672\tvalid_1's auc: 0.788421\n",
      "[2333]\ttraining's auc: 0.863698\tvalid_1's auc: 0.788422\n",
      "[2334]\ttraining's auc: 0.863729\tvalid_1's auc: 0.788428\n",
      "[2335]\ttraining's auc: 0.863753\tvalid_1's auc: 0.788426\n",
      "[2336]\ttraining's auc: 0.863779\tvalid_1's auc: 0.788431\n",
      "[2337]\ttraining's auc: 0.86381\tvalid_1's auc: 0.788431\n",
      "[2338]\ttraining's auc: 0.863834\tvalid_1's auc: 0.788428\n",
      "[2339]\ttraining's auc: 0.863864\tvalid_1's auc: 0.78843\n",
      "[2340]\ttraining's auc: 0.863886\tvalid_1's auc: 0.788431\n",
      "[2341]\ttraining's auc: 0.86391\tvalid_1's auc: 0.788436\n",
      "[2342]\ttraining's auc: 0.863937\tvalid_1's auc: 0.788436\n",
      "[2343]\ttraining's auc: 0.863957\tvalid_1's auc: 0.788443\n",
      "[2344]\ttraining's auc: 0.863983\tvalid_1's auc: 0.788448\n",
      "[2345]\ttraining's auc: 0.864012\tvalid_1's auc: 0.788449\n",
      "[2346]\ttraining's auc: 0.864036\tvalid_1's auc: 0.788448\n",
      "[2347]\ttraining's auc: 0.864058\tvalid_1's auc: 0.788452\n",
      "[2348]\ttraining's auc: 0.864088\tvalid_1's auc: 0.788459\n",
      "[2349]\ttraining's auc: 0.864119\tvalid_1's auc: 0.78846\n",
      "[2350]\ttraining's auc: 0.864144\tvalid_1's auc: 0.788466\n",
      "[2351]\ttraining's auc: 0.864167\tvalid_1's auc: 0.788468\n",
      "[2352]\ttraining's auc: 0.864189\tvalid_1's auc: 0.788472\n",
      "[2353]\ttraining's auc: 0.864217\tvalid_1's auc: 0.788474\n",
      "[2354]\ttraining's auc: 0.864241\tvalid_1's auc: 0.788475\n",
      "[2355]\ttraining's auc: 0.864272\tvalid_1's auc: 0.788478\n",
      "[2356]\ttraining's auc: 0.864291\tvalid_1's auc: 0.788481\n",
      "[2357]\ttraining's auc: 0.864315\tvalid_1's auc: 0.788481\n",
      "[2358]\ttraining's auc: 0.864341\tvalid_1's auc: 0.788486\n",
      "[2359]\ttraining's auc: 0.864367\tvalid_1's auc: 0.788479\n",
      "[2360]\ttraining's auc: 0.864393\tvalid_1's auc: 0.788486\n",
      "[2361]\ttraining's auc: 0.864417\tvalid_1's auc: 0.788479\n",
      "[2362]\ttraining's auc: 0.864444\tvalid_1's auc: 0.788478\n",
      "[2363]\ttraining's auc: 0.864472\tvalid_1's auc: 0.788484\n",
      "[2364]\ttraining's auc: 0.864489\tvalid_1's auc: 0.78848\n",
      "[2365]\ttraining's auc: 0.864512\tvalid_1's auc: 0.788483\n",
      "[2366]\ttraining's auc: 0.864537\tvalid_1's auc: 0.788479\n",
      "[2367]\ttraining's auc: 0.864561\tvalid_1's auc: 0.788477\n",
      "[2368]\ttraining's auc: 0.864588\tvalid_1's auc: 0.78848\n",
      "[2369]\ttraining's auc: 0.864606\tvalid_1's auc: 0.788482\n",
      "[2370]\ttraining's auc: 0.864628\tvalid_1's auc: 0.788485\n",
      "[2371]\ttraining's auc: 0.864652\tvalid_1's auc: 0.788484\n",
      "[2372]\ttraining's auc: 0.864685\tvalid_1's auc: 0.788491\n",
      "[2373]\ttraining's auc: 0.864706\tvalid_1's auc: 0.788491\n",
      "[2374]\ttraining's auc: 0.864732\tvalid_1's auc: 0.788502\n",
      "[2375]\ttraining's auc: 0.86475\tvalid_1's auc: 0.78851\n",
      "[2376]\ttraining's auc: 0.864762\tvalid_1's auc: 0.788511\n",
      "[2377]\ttraining's auc: 0.864783\tvalid_1's auc: 0.788514\n",
      "[2378]\ttraining's auc: 0.864809\tvalid_1's auc: 0.788521\n",
      "[2379]\ttraining's auc: 0.86484\tvalid_1's auc: 0.788516\n",
      "[2380]\ttraining's auc: 0.864868\tvalid_1's auc: 0.788513\n",
      "[2381]\ttraining's auc: 0.864904\tvalid_1's auc: 0.788515\n",
      "[2382]\ttraining's auc: 0.864933\tvalid_1's auc: 0.788514\n",
      "[2383]\ttraining's auc: 0.864958\tvalid_1's auc: 0.788516\n",
      "[2384]\ttraining's auc: 0.864979\tvalid_1's auc: 0.788518\n",
      "[2385]\ttraining's auc: 0.865001\tvalid_1's auc: 0.788513\n",
      "[2386]\ttraining's auc: 0.865026\tvalid_1's auc: 0.788519\n",
      "[2387]\ttraining's auc: 0.86505\tvalid_1's auc: 0.788527\n",
      "[2388]\ttraining's auc: 0.865077\tvalid_1's auc: 0.788528\n",
      "[2389]\ttraining's auc: 0.865097\tvalid_1's auc: 0.788527\n",
      "[2390]\ttraining's auc: 0.86512\tvalid_1's auc: 0.788526\n",
      "[2391]\ttraining's auc: 0.865143\tvalid_1's auc: 0.788528\n",
      "[2392]\ttraining's auc: 0.865157\tvalid_1's auc: 0.788527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2393]\ttraining's auc: 0.865176\tvalid_1's auc: 0.788532\n",
      "[2394]\ttraining's auc: 0.865206\tvalid_1's auc: 0.788534\n",
      "[2395]\ttraining's auc: 0.865241\tvalid_1's auc: 0.788529\n",
      "[2396]\ttraining's auc: 0.865268\tvalid_1's auc: 0.788533\n",
      "[2397]\ttraining's auc: 0.86529\tvalid_1's auc: 0.788538\n",
      "[2398]\ttraining's auc: 0.865321\tvalid_1's auc: 0.788543\n",
      "[2399]\ttraining's auc: 0.865333\tvalid_1's auc: 0.788542\n",
      "[2400]\ttraining's auc: 0.865357\tvalid_1's auc: 0.788534\n",
      "[2401]\ttraining's auc: 0.865388\tvalid_1's auc: 0.788539\n",
      "[2402]\ttraining's auc: 0.865415\tvalid_1's auc: 0.788538\n",
      "[2403]\ttraining's auc: 0.865441\tvalid_1's auc: 0.788543\n",
      "[2404]\ttraining's auc: 0.865461\tvalid_1's auc: 0.788541\n",
      "[2405]\ttraining's auc: 0.865478\tvalid_1's auc: 0.788548\n",
      "[2406]\ttraining's auc: 0.865501\tvalid_1's auc: 0.78855\n",
      "[2407]\ttraining's auc: 0.865519\tvalid_1's auc: 0.788553\n",
      "[2408]\ttraining's auc: 0.865541\tvalid_1's auc: 0.788554\n",
      "[2409]\ttraining's auc: 0.865558\tvalid_1's auc: 0.78855\n",
      "[2410]\ttraining's auc: 0.86558\tvalid_1's auc: 0.788557\n",
      "[2411]\ttraining's auc: 0.865612\tvalid_1's auc: 0.788564\n",
      "[2412]\ttraining's auc: 0.865634\tvalid_1's auc: 0.788566\n",
      "[2413]\ttraining's auc: 0.865656\tvalid_1's auc: 0.788556\n",
      "[2414]\ttraining's auc: 0.865682\tvalid_1's auc: 0.788565\n",
      "[2415]\ttraining's auc: 0.865699\tvalid_1's auc: 0.788565\n",
      "[2416]\ttraining's auc: 0.865716\tvalid_1's auc: 0.788574\n",
      "[2417]\ttraining's auc: 0.86574\tvalid_1's auc: 0.78857\n",
      "[2418]\ttraining's auc: 0.865764\tvalid_1's auc: 0.788572\n",
      "[2419]\ttraining's auc: 0.865791\tvalid_1's auc: 0.788576\n",
      "[2420]\ttraining's auc: 0.865804\tvalid_1's auc: 0.78858\n",
      "[2421]\ttraining's auc: 0.865825\tvalid_1's auc: 0.788585\n",
      "[2422]\ttraining's auc: 0.865851\tvalid_1's auc: 0.788588\n",
      "[2423]\ttraining's auc: 0.865875\tvalid_1's auc: 0.788588\n",
      "[2424]\ttraining's auc: 0.865909\tvalid_1's auc: 0.788596\n",
      "[2425]\ttraining's auc: 0.865937\tvalid_1's auc: 0.788601\n",
      "[2426]\ttraining's auc: 0.865954\tvalid_1's auc: 0.788601\n",
      "[2427]\ttraining's auc: 0.86598\tvalid_1's auc: 0.788601\n",
      "[2428]\ttraining's auc: 0.866006\tvalid_1's auc: 0.788602\n",
      "[2429]\ttraining's auc: 0.866037\tvalid_1's auc: 0.788609\n",
      "[2430]\ttraining's auc: 0.866061\tvalid_1's auc: 0.788604\n",
      "[2431]\ttraining's auc: 0.866086\tvalid_1's auc: 0.788602\n",
      "[2432]\ttraining's auc: 0.866116\tvalid_1's auc: 0.788609\n",
      "[2433]\ttraining's auc: 0.86614\tvalid_1's auc: 0.788608\n",
      "[2434]\ttraining's auc: 0.866162\tvalid_1's auc: 0.788609\n",
      "[2435]\ttraining's auc: 0.866184\tvalid_1's auc: 0.788616\n",
      "[2436]\ttraining's auc: 0.866206\tvalid_1's auc: 0.788611\n",
      "[2437]\ttraining's auc: 0.866233\tvalid_1's auc: 0.788611\n",
      "[2438]\ttraining's auc: 0.866255\tvalid_1's auc: 0.788611\n",
      "[2439]\ttraining's auc: 0.866283\tvalid_1's auc: 0.788612\n",
      "[2440]\ttraining's auc: 0.866306\tvalid_1's auc: 0.788611\n",
      "[2441]\ttraining's auc: 0.866329\tvalid_1's auc: 0.788624\n",
      "[2442]\ttraining's auc: 0.866349\tvalid_1's auc: 0.788625\n",
      "[2443]\ttraining's auc: 0.866377\tvalid_1's auc: 0.788619\n",
      "[2444]\ttraining's auc: 0.866403\tvalid_1's auc: 0.788624\n",
      "[2445]\ttraining's auc: 0.86643\tvalid_1's auc: 0.788627\n",
      "[2446]\ttraining's auc: 0.866458\tvalid_1's auc: 0.788628\n",
      "[2447]\ttraining's auc: 0.866478\tvalid_1's auc: 0.788633\n",
      "[2448]\ttraining's auc: 0.866505\tvalid_1's auc: 0.788635\n",
      "[2449]\ttraining's auc: 0.866515\tvalid_1's auc: 0.788637\n",
      "[2450]\ttraining's auc: 0.866542\tvalid_1's auc: 0.788625\n",
      "[2451]\ttraining's auc: 0.866562\tvalid_1's auc: 0.788626\n",
      "[2452]\ttraining's auc: 0.866585\tvalid_1's auc: 0.788624\n",
      "[2453]\ttraining's auc: 0.866611\tvalid_1's auc: 0.788624\n",
      "[2454]\ttraining's auc: 0.866632\tvalid_1's auc: 0.788625\n",
      "[2455]\ttraining's auc: 0.866655\tvalid_1's auc: 0.788623\n",
      "[2456]\ttraining's auc: 0.866683\tvalid_1's auc: 0.788634\n",
      "[2457]\ttraining's auc: 0.866708\tvalid_1's auc: 0.788635\n",
      "[2458]\ttraining's auc: 0.866735\tvalid_1's auc: 0.788636\n",
      "[2459]\ttraining's auc: 0.866758\tvalid_1's auc: 0.788631\n",
      "[2460]\ttraining's auc: 0.866786\tvalid_1's auc: 0.788633\n",
      "[2461]\ttraining's auc: 0.866814\tvalid_1's auc: 0.788636\n",
      "[2462]\ttraining's auc: 0.866832\tvalid_1's auc: 0.788635\n",
      "[2463]\ttraining's auc: 0.866851\tvalid_1's auc: 0.788635\n",
      "[2464]\ttraining's auc: 0.866874\tvalid_1's auc: 0.788642\n",
      "[2465]\ttraining's auc: 0.866904\tvalid_1's auc: 0.788647\n",
      "[2466]\ttraining's auc: 0.866928\tvalid_1's auc: 0.788645\n",
      "[2467]\ttraining's auc: 0.866961\tvalid_1's auc: 0.788646\n",
      "[2468]\ttraining's auc: 0.866982\tvalid_1's auc: 0.788647\n",
      "[2469]\ttraining's auc: 0.867014\tvalid_1's auc: 0.788645\n",
      "[2470]\ttraining's auc: 0.867039\tvalid_1's auc: 0.78865\n",
      "[2471]\ttraining's auc: 0.867058\tvalid_1's auc: 0.788648\n",
      "[2472]\ttraining's auc: 0.867077\tvalid_1's auc: 0.788647\n",
      "[2473]\ttraining's auc: 0.867111\tvalid_1's auc: 0.788651\n",
      "[2474]\ttraining's auc: 0.867135\tvalid_1's auc: 0.788651\n",
      "[2475]\ttraining's auc: 0.867158\tvalid_1's auc: 0.78865\n",
      "[2476]\ttraining's auc: 0.867185\tvalid_1's auc: 0.788658\n",
      "[2477]\ttraining's auc: 0.867206\tvalid_1's auc: 0.788657\n",
      "[2478]\ttraining's auc: 0.867233\tvalid_1's auc: 0.788657\n",
      "[2479]\ttraining's auc: 0.86726\tvalid_1's auc: 0.78866\n",
      "[2480]\ttraining's auc: 0.867281\tvalid_1's auc: 0.78866\n",
      "[2481]\ttraining's auc: 0.867292\tvalid_1's auc: 0.788663\n",
      "[2482]\ttraining's auc: 0.867321\tvalid_1's auc: 0.788663\n",
      "[2483]\ttraining's auc: 0.867344\tvalid_1's auc: 0.788661\n",
      "[2484]\ttraining's auc: 0.867361\tvalid_1's auc: 0.788663\n",
      "[2485]\ttraining's auc: 0.867387\tvalid_1's auc: 0.788664\n",
      "[2486]\ttraining's auc: 0.86741\tvalid_1's auc: 0.788667\n",
      "[2487]\ttraining's auc: 0.867435\tvalid_1's auc: 0.78867\n",
      "[2488]\ttraining's auc: 0.867453\tvalid_1's auc: 0.788667\n",
      "[2489]\ttraining's auc: 0.867475\tvalid_1's auc: 0.788674\n",
      "[2490]\ttraining's auc: 0.867507\tvalid_1's auc: 0.788671\n",
      "[2491]\ttraining's auc: 0.86753\tvalid_1's auc: 0.788676\n",
      "[2492]\ttraining's auc: 0.867542\tvalid_1's auc: 0.788683\n",
      "[2493]\ttraining's auc: 0.867564\tvalid_1's auc: 0.788685\n",
      "[2494]\ttraining's auc: 0.867594\tvalid_1's auc: 0.788681\n",
      "[2495]\ttraining's auc: 0.867617\tvalid_1's auc: 0.788675\n",
      "[2496]\ttraining's auc: 0.867636\tvalid_1's auc: 0.788673\n",
      "[2497]\ttraining's auc: 0.867661\tvalid_1's auc: 0.788674\n",
      "[2498]\ttraining's auc: 0.867693\tvalid_1's auc: 0.788673\n",
      "[2499]\ttraining's auc: 0.867726\tvalid_1's auc: 0.788676\n",
      "[2500]\ttraining's auc: 0.867748\tvalid_1's auc: 0.788677\n",
      "[2501]\ttraining's auc: 0.867766\tvalid_1's auc: 0.788679\n",
      "[2502]\ttraining's auc: 0.867784\tvalid_1's auc: 0.788677\n",
      "[2503]\ttraining's auc: 0.867804\tvalid_1's auc: 0.788678\n",
      "[2504]\ttraining's auc: 0.867815\tvalid_1's auc: 0.78868\n",
      "[2505]\ttraining's auc: 0.867834\tvalid_1's auc: 0.788688\n",
      "[2506]\ttraining's auc: 0.867865\tvalid_1's auc: 0.788684\n",
      "[2507]\ttraining's auc: 0.867884\tvalid_1's auc: 0.788683\n",
      "[2508]\ttraining's auc: 0.867907\tvalid_1's auc: 0.788683\n",
      "[2509]\ttraining's auc: 0.867938\tvalid_1's auc: 0.78869\n",
      "[2510]\ttraining's auc: 0.867957\tvalid_1's auc: 0.788696\n",
      "[2511]\ttraining's auc: 0.867986\tvalid_1's auc: 0.788695\n",
      "[2512]\ttraining's auc: 0.868011\tvalid_1's auc: 0.788701\n",
      "[2513]\ttraining's auc: 0.868025\tvalid_1's auc: 0.788695\n",
      "[2514]\ttraining's auc: 0.868044\tvalid_1's auc: 0.788701\n",
      "[2515]\ttraining's auc: 0.86806\tvalid_1's auc: 0.788699\n",
      "[2516]\ttraining's auc: 0.868078\tvalid_1's auc: 0.7887\n",
      "[2517]\ttraining's auc: 0.868097\tvalid_1's auc: 0.788703\n",
      "[2518]\ttraining's auc: 0.868129\tvalid_1's auc: 0.788696\n",
      "[2519]\ttraining's auc: 0.868157\tvalid_1's auc: 0.788699\n",
      "[2520]\ttraining's auc: 0.868184\tvalid_1's auc: 0.788691\n",
      "[2521]\ttraining's auc: 0.868203\tvalid_1's auc: 0.788685\n",
      "[2522]\ttraining's auc: 0.868229\tvalid_1's auc: 0.788683\n",
      "[2523]\ttraining's auc: 0.868254\tvalid_1's auc: 0.78868\n",
      "[2524]\ttraining's auc: 0.868272\tvalid_1's auc: 0.78868\n",
      "[2525]\ttraining's auc: 0.8683\tvalid_1's auc: 0.788688\n",
      "[2526]\ttraining's auc: 0.86832\tvalid_1's auc: 0.788685\n",
      "[2527]\ttraining's auc: 0.868342\tvalid_1's auc: 0.788684\n",
      "[2528]\ttraining's auc: 0.86837\tvalid_1's auc: 0.788683\n",
      "[2529]\ttraining's auc: 0.8684\tvalid_1's auc: 0.788684\n",
      "[2530]\ttraining's auc: 0.868424\tvalid_1's auc: 0.788686\n",
      "[2531]\ttraining's auc: 0.86845\tvalid_1's auc: 0.788683\n",
      "[2532]\ttraining's auc: 0.86847\tvalid_1's auc: 0.788687\n",
      "[2533]\ttraining's auc: 0.868495\tvalid_1's auc: 0.788688\n",
      "[2534]\ttraining's auc: 0.868526\tvalid_1's auc: 0.788687\n",
      "[2535]\ttraining's auc: 0.868563\tvalid_1's auc: 0.788684\n",
      "[2536]\ttraining's auc: 0.868592\tvalid_1's auc: 0.78869\n",
      "[2537]\ttraining's auc: 0.868614\tvalid_1's auc: 0.788691\n",
      "[2538]\ttraining's auc: 0.868627\tvalid_1's auc: 0.788695\n",
      "[2539]\ttraining's auc: 0.868653\tvalid_1's auc: 0.788699\n",
      "[2540]\ttraining's auc: 0.868668\tvalid_1's auc: 0.788702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2541]\ttraining's auc: 0.86869\tvalid_1's auc: 0.788706\n",
      "[2542]\ttraining's auc: 0.86871\tvalid_1's auc: 0.788715\n",
      "[2543]\ttraining's auc: 0.868737\tvalid_1's auc: 0.788713\n",
      "[2544]\ttraining's auc: 0.86876\tvalid_1's auc: 0.788716\n",
      "[2545]\ttraining's auc: 0.868778\tvalid_1's auc: 0.788716\n",
      "[2546]\ttraining's auc: 0.8688\tvalid_1's auc: 0.788716\n",
      "[2547]\ttraining's auc: 0.868827\tvalid_1's auc: 0.788715\n",
      "[2548]\ttraining's auc: 0.868855\tvalid_1's auc: 0.788715\n",
      "[2549]\ttraining's auc: 0.868879\tvalid_1's auc: 0.788714\n",
      "[2550]\ttraining's auc: 0.868904\tvalid_1's auc: 0.788722\n",
      "[2551]\ttraining's auc: 0.868918\tvalid_1's auc: 0.788723\n",
      "[2552]\ttraining's auc: 0.868938\tvalid_1's auc: 0.788728\n",
      "[2553]\ttraining's auc: 0.868962\tvalid_1's auc: 0.788735\n",
      "[2554]\ttraining's auc: 0.868991\tvalid_1's auc: 0.788736\n",
      "[2555]\ttraining's auc: 0.869017\tvalid_1's auc: 0.788741\n",
      "[2556]\ttraining's auc: 0.869038\tvalid_1's auc: 0.788739\n",
      "[2557]\ttraining's auc: 0.869062\tvalid_1's auc: 0.788744\n",
      "[2558]\ttraining's auc: 0.869104\tvalid_1's auc: 0.788746\n",
      "[2559]\ttraining's auc: 0.869122\tvalid_1's auc: 0.788748\n",
      "[2560]\ttraining's auc: 0.869146\tvalid_1's auc: 0.788746\n",
      "[2561]\ttraining's auc: 0.869165\tvalid_1's auc: 0.78875\n",
      "[2562]\ttraining's auc: 0.869187\tvalid_1's auc: 0.788749\n",
      "[2563]\ttraining's auc: 0.869214\tvalid_1's auc: 0.788752\n",
      "[2564]\ttraining's auc: 0.869237\tvalid_1's auc: 0.788751\n",
      "[2565]\ttraining's auc: 0.869258\tvalid_1's auc: 0.788744\n",
      "[2566]\ttraining's auc: 0.869266\tvalid_1's auc: 0.788745\n",
      "[2567]\ttraining's auc: 0.869291\tvalid_1's auc: 0.788747\n",
      "[2568]\ttraining's auc: 0.869319\tvalid_1's auc: 0.78875\n",
      "[2569]\ttraining's auc: 0.869347\tvalid_1's auc: 0.788759\n",
      "[2570]\ttraining's auc: 0.869375\tvalid_1's auc: 0.788764\n",
      "[2571]\ttraining's auc: 0.869404\tvalid_1's auc: 0.78877\n",
      "[2572]\ttraining's auc: 0.869429\tvalid_1's auc: 0.788775\n",
      "[2573]\ttraining's auc: 0.869447\tvalid_1's auc: 0.788779\n",
      "[2574]\ttraining's auc: 0.869458\tvalid_1's auc: 0.78878\n",
      "[2575]\ttraining's auc: 0.869483\tvalid_1's auc: 0.788787\n",
      "[2576]\ttraining's auc: 0.869502\tvalid_1's auc: 0.788788\n",
      "[2577]\ttraining's auc: 0.869524\tvalid_1's auc: 0.788789\n",
      "[2578]\ttraining's auc: 0.869548\tvalid_1's auc: 0.788811\n",
      "[2579]\ttraining's auc: 0.869578\tvalid_1's auc: 0.788814\n",
      "[2580]\ttraining's auc: 0.869608\tvalid_1's auc: 0.788814\n",
      "[2581]\ttraining's auc: 0.869637\tvalid_1's auc: 0.788815\n",
      "[2582]\ttraining's auc: 0.869677\tvalid_1's auc: 0.788824\n",
      "[2583]\ttraining's auc: 0.869697\tvalid_1's auc: 0.788823\n",
      "[2584]\ttraining's auc: 0.869726\tvalid_1's auc: 0.788824\n",
      "[2585]\ttraining's auc: 0.869749\tvalid_1's auc: 0.788824\n",
      "[2586]\ttraining's auc: 0.869769\tvalid_1's auc: 0.788827\n",
      "[2587]\ttraining's auc: 0.869793\tvalid_1's auc: 0.788826\n",
      "[2588]\ttraining's auc: 0.869815\tvalid_1's auc: 0.788827\n",
      "[2589]\ttraining's auc: 0.869841\tvalid_1's auc: 0.788832\n",
      "[2590]\ttraining's auc: 0.869871\tvalid_1's auc: 0.788825\n",
      "[2591]\ttraining's auc: 0.869894\tvalid_1's auc: 0.788826\n",
      "[2592]\ttraining's auc: 0.869915\tvalid_1's auc: 0.788827\n",
      "[2593]\ttraining's auc: 0.869931\tvalid_1's auc: 0.788831\n",
      "[2594]\ttraining's auc: 0.869957\tvalid_1's auc: 0.788835\n",
      "[2595]\ttraining's auc: 0.869979\tvalid_1's auc: 0.788837\n",
      "[2596]\ttraining's auc: 0.870009\tvalid_1's auc: 0.788843\n",
      "[2597]\ttraining's auc: 0.870029\tvalid_1's auc: 0.788842\n",
      "[2598]\ttraining's auc: 0.87005\tvalid_1's auc: 0.788846\n",
      "[2599]\ttraining's auc: 0.870074\tvalid_1's auc: 0.788841\n",
      "[2600]\ttraining's auc: 0.870093\tvalid_1's auc: 0.788843\n",
      "[2601]\ttraining's auc: 0.870121\tvalid_1's auc: 0.788843\n",
      "[2602]\ttraining's auc: 0.870142\tvalid_1's auc: 0.788845\n",
      "[2603]\ttraining's auc: 0.870168\tvalid_1's auc: 0.788852\n",
      "[2604]\ttraining's auc: 0.870196\tvalid_1's auc: 0.788852\n",
      "[2605]\ttraining's auc: 0.870207\tvalid_1's auc: 0.788857\n",
      "[2606]\ttraining's auc: 0.870228\tvalid_1's auc: 0.788861\n",
      "[2607]\ttraining's auc: 0.870251\tvalid_1's auc: 0.788858\n",
      "[2608]\ttraining's auc: 0.870284\tvalid_1's auc: 0.788858\n",
      "[2609]\ttraining's auc: 0.870305\tvalid_1's auc: 0.788857\n",
      "[2610]\ttraining's auc: 0.870329\tvalid_1's auc: 0.788854\n",
      "[2611]\ttraining's auc: 0.87036\tvalid_1's auc: 0.788858\n",
      "[2612]\ttraining's auc: 0.870388\tvalid_1's auc: 0.788856\n",
      "[2613]\ttraining's auc: 0.870416\tvalid_1's auc: 0.78885\n",
      "[2614]\ttraining's auc: 0.870435\tvalid_1's auc: 0.788852\n",
      "[2615]\ttraining's auc: 0.870464\tvalid_1's auc: 0.78885\n",
      "[2616]\ttraining's auc: 0.870497\tvalid_1's auc: 0.78886\n",
      "[2617]\ttraining's auc: 0.870522\tvalid_1's auc: 0.788862\n",
      "[2618]\ttraining's auc: 0.87054\tvalid_1's auc: 0.788865\n",
      "[2619]\ttraining's auc: 0.87056\tvalid_1's auc: 0.788859\n",
      "[2620]\ttraining's auc: 0.870586\tvalid_1's auc: 0.788862\n",
      "[2621]\ttraining's auc: 0.870623\tvalid_1's auc: 0.788864\n",
      "[2622]\ttraining's auc: 0.87064\tvalid_1's auc: 0.788868\n",
      "[2623]\ttraining's auc: 0.870662\tvalid_1's auc: 0.788874\n",
      "[2624]\ttraining's auc: 0.870677\tvalid_1's auc: 0.78888\n",
      "[2625]\ttraining's auc: 0.870692\tvalid_1's auc: 0.788878\n",
      "[2626]\ttraining's auc: 0.870712\tvalid_1's auc: 0.788883\n",
      "[2627]\ttraining's auc: 0.87074\tvalid_1's auc: 0.788886\n",
      "[2628]\ttraining's auc: 0.87076\tvalid_1's auc: 0.788885\n",
      "[2629]\ttraining's auc: 0.870785\tvalid_1's auc: 0.788885\n",
      "[2630]\ttraining's auc: 0.87081\tvalid_1's auc: 0.788887\n",
      "[2631]\ttraining's auc: 0.870837\tvalid_1's auc: 0.788893\n",
      "[2632]\ttraining's auc: 0.870857\tvalid_1's auc: 0.788895\n",
      "[2633]\ttraining's auc: 0.870884\tvalid_1's auc: 0.788897\n",
      "[2634]\ttraining's auc: 0.870909\tvalid_1's auc: 0.788895\n",
      "[2635]\ttraining's auc: 0.870934\tvalid_1's auc: 0.788899\n",
      "[2636]\ttraining's auc: 0.870962\tvalid_1's auc: 0.788901\n",
      "[2637]\ttraining's auc: 0.870985\tvalid_1's auc: 0.788905\n",
      "[2638]\ttraining's auc: 0.871007\tvalid_1's auc: 0.788914\n",
      "[2639]\ttraining's auc: 0.871026\tvalid_1's auc: 0.788913\n",
      "[2640]\ttraining's auc: 0.871043\tvalid_1's auc: 0.788909\n",
      "[2641]\ttraining's auc: 0.871062\tvalid_1's auc: 0.788907\n",
      "[2642]\ttraining's auc: 0.871085\tvalid_1's auc: 0.788911\n",
      "[2643]\ttraining's auc: 0.871103\tvalid_1's auc: 0.788906\n",
      "[2644]\ttraining's auc: 0.871121\tvalid_1's auc: 0.788909\n",
      "[2645]\ttraining's auc: 0.871132\tvalid_1's auc: 0.788906\n",
      "[2646]\ttraining's auc: 0.871156\tvalid_1's auc: 0.788908\n",
      "[2647]\ttraining's auc: 0.871173\tvalid_1's auc: 0.788903\n",
      "[2648]\ttraining's auc: 0.871201\tvalid_1's auc: 0.788901\n",
      "[2649]\ttraining's auc: 0.871223\tvalid_1's auc: 0.788901\n",
      "[2650]\ttraining's auc: 0.871243\tvalid_1's auc: 0.788898\n",
      "[2651]\ttraining's auc: 0.871266\tvalid_1's auc: 0.788901\n",
      "[2652]\ttraining's auc: 0.871289\tvalid_1's auc: 0.788897\n",
      "[2653]\ttraining's auc: 0.871312\tvalid_1's auc: 0.788893\n",
      "[2654]\ttraining's auc: 0.871335\tvalid_1's auc: 0.788896\n",
      "[2655]\ttraining's auc: 0.871356\tvalid_1's auc: 0.788893\n",
      "[2656]\ttraining's auc: 0.871377\tvalid_1's auc: 0.78889\n",
      "[2657]\ttraining's auc: 0.871397\tvalid_1's auc: 0.78889\n",
      "[2658]\ttraining's auc: 0.871412\tvalid_1's auc: 0.788896\n",
      "[2659]\ttraining's auc: 0.871436\tvalid_1's auc: 0.788896\n",
      "[2660]\ttraining's auc: 0.871466\tvalid_1's auc: 0.788895\n",
      "[2661]\ttraining's auc: 0.871489\tvalid_1's auc: 0.788885\n",
      "[2662]\ttraining's auc: 0.871521\tvalid_1's auc: 0.788882\n",
      "[2663]\ttraining's auc: 0.871552\tvalid_1's auc: 0.788885\n",
      "[2664]\ttraining's auc: 0.871588\tvalid_1's auc: 0.788893\n",
      "[2665]\ttraining's auc: 0.871615\tvalid_1's auc: 0.788893\n",
      "[2666]\ttraining's auc: 0.871637\tvalid_1's auc: 0.788888\n",
      "[2667]\ttraining's auc: 0.871659\tvalid_1's auc: 0.788889\n",
      "[2668]\ttraining's auc: 0.871675\tvalid_1's auc: 0.788888\n",
      "[2669]\ttraining's auc: 0.871706\tvalid_1's auc: 0.788892\n",
      "[2670]\ttraining's auc: 0.871735\tvalid_1's auc: 0.788893\n",
      "[2671]\ttraining's auc: 0.871757\tvalid_1's auc: 0.788894\n",
      "[2672]\ttraining's auc: 0.87179\tvalid_1's auc: 0.788891\n",
      "[2673]\ttraining's auc: 0.871814\tvalid_1's auc: 0.788901\n",
      "[2674]\ttraining's auc: 0.871822\tvalid_1's auc: 0.788898\n",
      "[2675]\ttraining's auc: 0.871856\tvalid_1's auc: 0.78889\n",
      "[2676]\ttraining's auc: 0.871879\tvalid_1's auc: 0.788898\n",
      "[2677]\ttraining's auc: 0.871896\tvalid_1's auc: 0.788903\n",
      "[2678]\ttraining's auc: 0.871929\tvalid_1's auc: 0.788898\n",
      "[2679]\ttraining's auc: 0.871958\tvalid_1's auc: 0.788901\n",
      "[2680]\ttraining's auc: 0.871971\tvalid_1's auc: 0.788903\n",
      "[2681]\ttraining's auc: 0.871994\tvalid_1's auc: 0.788906\n",
      "[2682]\ttraining's auc: 0.872016\tvalid_1's auc: 0.788907\n",
      "[2683]\ttraining's auc: 0.872046\tvalid_1's auc: 0.788912\n",
      "[2684]\ttraining's auc: 0.872072\tvalid_1's auc: 0.788916\n",
      "[2685]\ttraining's auc: 0.872091\tvalid_1's auc: 0.788918\n",
      "[2686]\ttraining's auc: 0.872114\tvalid_1's auc: 0.788917\n",
      "[2687]\ttraining's auc: 0.872128\tvalid_1's auc: 0.788917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2688]\ttraining's auc: 0.872156\tvalid_1's auc: 0.788918\n",
      "[2689]\ttraining's auc: 0.872185\tvalid_1's auc: 0.788923\n",
      "[2690]\ttraining's auc: 0.87221\tvalid_1's auc: 0.788918\n",
      "[2691]\ttraining's auc: 0.872238\tvalid_1's auc: 0.788917\n",
      "[2692]\ttraining's auc: 0.872249\tvalid_1's auc: 0.788917\n",
      "[2693]\ttraining's auc: 0.872264\tvalid_1's auc: 0.78892\n",
      "[2694]\ttraining's auc: 0.872287\tvalid_1's auc: 0.788916\n",
      "[2695]\ttraining's auc: 0.872318\tvalid_1's auc: 0.788921\n",
      "[2696]\ttraining's auc: 0.872338\tvalid_1's auc: 0.788921\n",
      "[2697]\ttraining's auc: 0.872359\tvalid_1's auc: 0.788916\n",
      "[2698]\ttraining's auc: 0.872378\tvalid_1's auc: 0.78892\n",
      "[2699]\ttraining's auc: 0.872401\tvalid_1's auc: 0.788927\n",
      "[2700]\ttraining's auc: 0.87242\tvalid_1's auc: 0.788923\n",
      "[2701]\ttraining's auc: 0.872443\tvalid_1's auc: 0.788928\n",
      "[2702]\ttraining's auc: 0.872472\tvalid_1's auc: 0.788933\n",
      "[2703]\ttraining's auc: 0.872496\tvalid_1's auc: 0.788929\n",
      "[2704]\ttraining's auc: 0.87252\tvalid_1's auc: 0.788928\n",
      "[2705]\ttraining's auc: 0.872549\tvalid_1's auc: 0.788936\n",
      "[2706]\ttraining's auc: 0.872581\tvalid_1's auc: 0.788935\n",
      "[2707]\ttraining's auc: 0.872602\tvalid_1's auc: 0.788934\n",
      "[2708]\ttraining's auc: 0.872633\tvalid_1's auc: 0.788938\n",
      "[2709]\ttraining's auc: 0.872657\tvalid_1's auc: 0.788945\n",
      "[2710]\ttraining's auc: 0.872683\tvalid_1's auc: 0.788939\n",
      "[2711]\ttraining's auc: 0.87271\tvalid_1's auc: 0.788942\n",
      "[2712]\ttraining's auc: 0.872739\tvalid_1's auc: 0.788947\n",
      "[2713]\ttraining's auc: 0.872768\tvalid_1's auc: 0.788946\n",
      "[2714]\ttraining's auc: 0.872791\tvalid_1's auc: 0.788947\n",
      "[2715]\ttraining's auc: 0.872812\tvalid_1's auc: 0.78895\n",
      "[2716]\ttraining's auc: 0.872835\tvalid_1's auc: 0.788948\n",
      "[2717]\ttraining's auc: 0.872862\tvalid_1's auc: 0.788952\n",
      "[2718]\ttraining's auc: 0.872885\tvalid_1's auc: 0.788952\n",
      "[2719]\ttraining's auc: 0.872913\tvalid_1's auc: 0.788954\n",
      "[2720]\ttraining's auc: 0.872926\tvalid_1's auc: 0.788952\n",
      "[2721]\ttraining's auc: 0.872949\tvalid_1's auc: 0.788959\n",
      "[2722]\ttraining's auc: 0.87298\tvalid_1's auc: 0.788955\n",
      "[2723]\ttraining's auc: 0.872999\tvalid_1's auc: 0.788956\n",
      "[2724]\ttraining's auc: 0.873024\tvalid_1's auc: 0.788956\n",
      "[2725]\ttraining's auc: 0.873031\tvalid_1's auc: 0.788955\n",
      "[2726]\ttraining's auc: 0.873037\tvalid_1's auc: 0.788957\n",
      "[2727]\ttraining's auc: 0.87306\tvalid_1's auc: 0.788957\n",
      "[2728]\ttraining's auc: 0.87309\tvalid_1's auc: 0.788961\n",
      "[2729]\ttraining's auc: 0.873117\tvalid_1's auc: 0.788966\n",
      "[2730]\ttraining's auc: 0.873138\tvalid_1's auc: 0.788965\n",
      "[2731]\ttraining's auc: 0.873167\tvalid_1's auc: 0.788967\n",
      "[2732]\ttraining's auc: 0.873194\tvalid_1's auc: 0.788972\n",
      "[2733]\ttraining's auc: 0.873223\tvalid_1's auc: 0.78897\n",
      "[2734]\ttraining's auc: 0.873248\tvalid_1's auc: 0.788977\n",
      "[2735]\ttraining's auc: 0.87328\tvalid_1's auc: 0.788976\n",
      "[2736]\ttraining's auc: 0.873304\tvalid_1's auc: 0.788978\n",
      "[2737]\ttraining's auc: 0.873327\tvalid_1's auc: 0.788979\n",
      "[2738]\ttraining's auc: 0.873362\tvalid_1's auc: 0.788989\n",
      "[2739]\ttraining's auc: 0.873386\tvalid_1's auc: 0.788986\n",
      "[2740]\ttraining's auc: 0.873412\tvalid_1's auc: 0.78899\n",
      "[2741]\ttraining's auc: 0.873434\tvalid_1's auc: 0.788988\n",
      "[2742]\ttraining's auc: 0.873443\tvalid_1's auc: 0.78899\n",
      "[2743]\ttraining's auc: 0.873458\tvalid_1's auc: 0.788992\n",
      "[2744]\ttraining's auc: 0.873482\tvalid_1's auc: 0.788992\n",
      "[2745]\ttraining's auc: 0.873503\tvalid_1's auc: 0.78899\n",
      "[2746]\ttraining's auc: 0.873521\tvalid_1's auc: 0.788988\n",
      "[2747]\ttraining's auc: 0.873546\tvalid_1's auc: 0.789012\n",
      "[2748]\ttraining's auc: 0.873569\tvalid_1's auc: 0.789012\n",
      "[2749]\ttraining's auc: 0.873591\tvalid_1's auc: 0.789011\n",
      "[2750]\ttraining's auc: 0.873611\tvalid_1's auc: 0.789009\n",
      "[2751]\ttraining's auc: 0.873637\tvalid_1's auc: 0.789016\n",
      "[2752]\ttraining's auc: 0.873661\tvalid_1's auc: 0.789017\n",
      "[2753]\ttraining's auc: 0.873688\tvalid_1's auc: 0.789015\n",
      "[2754]\ttraining's auc: 0.873702\tvalid_1's auc: 0.789016\n",
      "[2755]\ttraining's auc: 0.873726\tvalid_1's auc: 0.789017\n",
      "[2756]\ttraining's auc: 0.873741\tvalid_1's auc: 0.789021\n",
      "[2757]\ttraining's auc: 0.873766\tvalid_1's auc: 0.789026\n",
      "[2758]\ttraining's auc: 0.873792\tvalid_1's auc: 0.789031\n",
      "[2759]\ttraining's auc: 0.873811\tvalid_1's auc: 0.789032\n",
      "[2760]\ttraining's auc: 0.873832\tvalid_1's auc: 0.789034\n",
      "[2761]\ttraining's auc: 0.873858\tvalid_1's auc: 0.789043\n",
      "[2762]\ttraining's auc: 0.873884\tvalid_1's auc: 0.789046\n",
      "[2763]\ttraining's auc: 0.873896\tvalid_1's auc: 0.789046\n",
      "[2764]\ttraining's auc: 0.873924\tvalid_1's auc: 0.789044\n",
      "[2765]\ttraining's auc: 0.873945\tvalid_1's auc: 0.789046\n",
      "[2766]\ttraining's auc: 0.87397\tvalid_1's auc: 0.789053\n",
      "[2767]\ttraining's auc: 0.873991\tvalid_1's auc: 0.789059\n",
      "[2768]\ttraining's auc: 0.874016\tvalid_1's auc: 0.789059\n",
      "[2769]\ttraining's auc: 0.874046\tvalid_1's auc: 0.789061\n",
      "[2770]\ttraining's auc: 0.874073\tvalid_1's auc: 0.789067\n",
      "[2771]\ttraining's auc: 0.874088\tvalid_1's auc: 0.789065\n",
      "[2772]\ttraining's auc: 0.874113\tvalid_1's auc: 0.789059\n",
      "[2773]\ttraining's auc: 0.874128\tvalid_1's auc: 0.789058\n",
      "[2774]\ttraining's auc: 0.874155\tvalid_1's auc: 0.789055\n",
      "[2775]\ttraining's auc: 0.874175\tvalid_1's auc: 0.789061\n",
      "[2776]\ttraining's auc: 0.874193\tvalid_1's auc: 0.789062\n",
      "[2777]\ttraining's auc: 0.874212\tvalid_1's auc: 0.789058\n",
      "[2778]\ttraining's auc: 0.87424\tvalid_1's auc: 0.78906\n",
      "[2779]\ttraining's auc: 0.874262\tvalid_1's auc: 0.78906\n",
      "[2780]\ttraining's auc: 0.874291\tvalid_1's auc: 0.78906\n",
      "[2781]\ttraining's auc: 0.874316\tvalid_1's auc: 0.789061\n",
      "[2782]\ttraining's auc: 0.874336\tvalid_1's auc: 0.789064\n",
      "[2783]\ttraining's auc: 0.874344\tvalid_1's auc: 0.789066\n",
      "[2784]\ttraining's auc: 0.874369\tvalid_1's auc: 0.789063\n",
      "[2785]\ttraining's auc: 0.874396\tvalid_1's auc: 0.789062\n",
      "[2786]\ttraining's auc: 0.874426\tvalid_1's auc: 0.789052\n",
      "[2787]\ttraining's auc: 0.874452\tvalid_1's auc: 0.789054\n",
      "[2788]\ttraining's auc: 0.874467\tvalid_1's auc: 0.789054\n",
      "[2789]\ttraining's auc: 0.874492\tvalid_1's auc: 0.789054\n",
      "[2790]\ttraining's auc: 0.874514\tvalid_1's auc: 0.78905\n",
      "[2791]\ttraining's auc: 0.87454\tvalid_1's auc: 0.789048\n",
      "[2792]\ttraining's auc: 0.874568\tvalid_1's auc: 0.789053\n",
      "[2793]\ttraining's auc: 0.874597\tvalid_1's auc: 0.789053\n",
      "[2794]\ttraining's auc: 0.874614\tvalid_1's auc: 0.789054\n",
      "[2795]\ttraining's auc: 0.874633\tvalid_1's auc: 0.789056\n",
      "[2796]\ttraining's auc: 0.874657\tvalid_1's auc: 0.789056\n",
      "[2797]\ttraining's auc: 0.874673\tvalid_1's auc: 0.789058\n",
      "[2798]\ttraining's auc: 0.874692\tvalid_1's auc: 0.789059\n",
      "[2799]\ttraining's auc: 0.874715\tvalid_1's auc: 0.789062\n",
      "[2800]\ttraining's auc: 0.874745\tvalid_1's auc: 0.78906\n",
      "[2801]\ttraining's auc: 0.874771\tvalid_1's auc: 0.789057\n",
      "[2802]\ttraining's auc: 0.874793\tvalid_1's auc: 0.789054\n",
      "[2803]\ttraining's auc: 0.874816\tvalid_1's auc: 0.789051\n",
      "[2804]\ttraining's auc: 0.874836\tvalid_1's auc: 0.789058\n",
      "[2805]\ttraining's auc: 0.874859\tvalid_1's auc: 0.789058\n",
      "[2806]\ttraining's auc: 0.874869\tvalid_1's auc: 0.789056\n",
      "[2807]\ttraining's auc: 0.874885\tvalid_1's auc: 0.789055\n",
      "[2808]\ttraining's auc: 0.874902\tvalid_1's auc: 0.789055\n",
      "[2809]\ttraining's auc: 0.874929\tvalid_1's auc: 0.789051\n",
      "[2810]\ttraining's auc: 0.874952\tvalid_1's auc: 0.789052\n",
      "[2811]\ttraining's auc: 0.874974\tvalid_1's auc: 0.789049\n",
      "[2812]\ttraining's auc: 0.874997\tvalid_1's auc: 0.789055\n",
      "[2813]\ttraining's auc: 0.87502\tvalid_1's auc: 0.789049\n",
      "[2814]\ttraining's auc: 0.875027\tvalid_1's auc: 0.78905\n",
      "[2815]\ttraining's auc: 0.875054\tvalid_1's auc: 0.78905\n",
      "[2816]\ttraining's auc: 0.875079\tvalid_1's auc: 0.789046\n",
      "[2817]\ttraining's auc: 0.875102\tvalid_1's auc: 0.789049\n",
      "[2818]\ttraining's auc: 0.875129\tvalid_1's auc: 0.789054\n",
      "[2819]\ttraining's auc: 0.875146\tvalid_1's auc: 0.789055\n",
      "[2820]\ttraining's auc: 0.875166\tvalid_1's auc: 0.789053\n",
      "[2821]\ttraining's auc: 0.875185\tvalid_1's auc: 0.789054\n",
      "[2822]\ttraining's auc: 0.875214\tvalid_1's auc: 0.789052\n",
      "[2823]\ttraining's auc: 0.875234\tvalid_1's auc: 0.78905\n",
      "[2824]\ttraining's auc: 0.875255\tvalid_1's auc: 0.789053\n",
      "[2825]\ttraining's auc: 0.875282\tvalid_1's auc: 0.789053\n",
      "[2826]\ttraining's auc: 0.875297\tvalid_1's auc: 0.789051\n",
      "[2827]\ttraining's auc: 0.875314\tvalid_1's auc: 0.789048\n",
      "[2828]\ttraining's auc: 0.875326\tvalid_1's auc: 0.789047\n",
      "[2829]\ttraining's auc: 0.87533\tvalid_1's auc: 0.789046\n",
      "[2830]\ttraining's auc: 0.875345\tvalid_1's auc: 0.789049\n",
      "[2831]\ttraining's auc: 0.875368\tvalid_1's auc: 0.789054\n",
      "[2832]\ttraining's auc: 0.875383\tvalid_1's auc: 0.789052\n",
      "[2833]\ttraining's auc: 0.875396\tvalid_1's auc: 0.789051\n",
      "[2834]\ttraining's auc: 0.875416\tvalid_1's auc: 0.789049\n",
      "[2835]\ttraining's auc: 0.87544\tvalid_1's auc: 0.789051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2836]\ttraining's auc: 0.875462\tvalid_1's auc: 0.789054\n",
      "[2837]\ttraining's auc: 0.875486\tvalid_1's auc: 0.789056\n",
      "[2838]\ttraining's auc: 0.87551\tvalid_1's auc: 0.789061\n",
      "[2839]\ttraining's auc: 0.875543\tvalid_1's auc: 0.789067\n",
      "[2840]\ttraining's auc: 0.875566\tvalid_1's auc: 0.789073\n",
      "[2841]\ttraining's auc: 0.875585\tvalid_1's auc: 0.789077\n",
      "[2842]\ttraining's auc: 0.875612\tvalid_1's auc: 0.789081\n",
      "[2843]\ttraining's auc: 0.875634\tvalid_1's auc: 0.789081\n",
      "[2844]\ttraining's auc: 0.875662\tvalid_1's auc: 0.789085\n",
      "[2845]\ttraining's auc: 0.875681\tvalid_1's auc: 0.789087\n",
      "[2846]\ttraining's auc: 0.875699\tvalid_1's auc: 0.789085\n",
      "[2847]\ttraining's auc: 0.875719\tvalid_1's auc: 0.789088\n",
      "[2848]\ttraining's auc: 0.875737\tvalid_1's auc: 0.789086\n",
      "[2849]\ttraining's auc: 0.87576\tvalid_1's auc: 0.789088\n",
      "[2850]\ttraining's auc: 0.875767\tvalid_1's auc: 0.789092\n",
      "[2851]\ttraining's auc: 0.875792\tvalid_1's auc: 0.78909\n",
      "[2852]\ttraining's auc: 0.875818\tvalid_1's auc: 0.789088\n",
      "[2853]\ttraining's auc: 0.875839\tvalid_1's auc: 0.789089\n",
      "[2854]\ttraining's auc: 0.875856\tvalid_1's auc: 0.789095\n",
      "[2855]\ttraining's auc: 0.875876\tvalid_1's auc: 0.789096\n",
      "[2856]\ttraining's auc: 0.875897\tvalid_1's auc: 0.789103\n",
      "[2857]\ttraining's auc: 0.875921\tvalid_1's auc: 0.789098\n",
      "[2858]\ttraining's auc: 0.875953\tvalid_1's auc: 0.789102\n",
      "[2859]\ttraining's auc: 0.875971\tvalid_1's auc: 0.789106\n",
      "[2860]\ttraining's auc: 0.875987\tvalid_1's auc: 0.789107\n",
      "[2861]\ttraining's auc: 0.876008\tvalid_1's auc: 0.789118\n",
      "[2862]\ttraining's auc: 0.876019\tvalid_1's auc: 0.78912\n",
      "[2863]\ttraining's auc: 0.876047\tvalid_1's auc: 0.789122\n",
      "[2864]\ttraining's auc: 0.876071\tvalid_1's auc: 0.789117\n",
      "[2865]\ttraining's auc: 0.876102\tvalid_1's auc: 0.789119\n",
      "[2866]\ttraining's auc: 0.876128\tvalid_1's auc: 0.789118\n",
      "[2867]\ttraining's auc: 0.876152\tvalid_1's auc: 0.78912\n",
      "[2868]\ttraining's auc: 0.876181\tvalid_1's auc: 0.789126\n",
      "[2869]\ttraining's auc: 0.876198\tvalid_1's auc: 0.78912\n",
      "[2870]\ttraining's auc: 0.876215\tvalid_1's auc: 0.789121\n",
      "[2871]\ttraining's auc: 0.876237\tvalid_1's auc: 0.789118\n",
      "[2872]\ttraining's auc: 0.876253\tvalid_1's auc: 0.789117\n",
      "[2873]\ttraining's auc: 0.87627\tvalid_1's auc: 0.789114\n",
      "[2874]\ttraining's auc: 0.87629\tvalid_1's auc: 0.789121\n",
      "[2875]\ttraining's auc: 0.876311\tvalid_1's auc: 0.789118\n",
      "[2876]\ttraining's auc: 0.876337\tvalid_1's auc: 0.78912\n",
      "[2877]\ttraining's auc: 0.876357\tvalid_1's auc: 0.789118\n",
      "[2878]\ttraining's auc: 0.876381\tvalid_1's auc: 0.789118\n",
      "[2879]\ttraining's auc: 0.876405\tvalid_1's auc: 0.789124\n",
      "[2880]\ttraining's auc: 0.876426\tvalid_1's auc: 0.789128\n",
      "[2881]\ttraining's auc: 0.876448\tvalid_1's auc: 0.789124\n",
      "[2882]\ttraining's auc: 0.87647\tvalid_1's auc: 0.789123\n",
      "[2883]\ttraining's auc: 0.876489\tvalid_1's auc: 0.789122\n",
      "[2884]\ttraining's auc: 0.876506\tvalid_1's auc: 0.789123\n",
      "[2885]\ttraining's auc: 0.876519\tvalid_1's auc: 0.789129\n",
      "[2886]\ttraining's auc: 0.876557\tvalid_1's auc: 0.789136\n",
      "[2887]\ttraining's auc: 0.876582\tvalid_1's auc: 0.789142\n",
      "[2888]\ttraining's auc: 0.87661\tvalid_1's auc: 0.789148\n",
      "[2889]\ttraining's auc: 0.876638\tvalid_1's auc: 0.789144\n",
      "[2890]\ttraining's auc: 0.876661\tvalid_1's auc: 0.789144\n",
      "[2891]\ttraining's auc: 0.876677\tvalid_1's auc: 0.789147\n",
      "[2892]\ttraining's auc: 0.876688\tvalid_1's auc: 0.789146\n",
      "[2893]\ttraining's auc: 0.87671\tvalid_1's auc: 0.789152\n",
      "[2894]\ttraining's auc: 0.876718\tvalid_1's auc: 0.789153\n",
      "[2895]\ttraining's auc: 0.876725\tvalid_1's auc: 0.789152\n",
      "[2896]\ttraining's auc: 0.87675\tvalid_1's auc: 0.789144\n",
      "[2897]\ttraining's auc: 0.876778\tvalid_1's auc: 0.789147\n",
      "[2898]\ttraining's auc: 0.876795\tvalid_1's auc: 0.789152\n",
      "[2899]\ttraining's auc: 0.876821\tvalid_1's auc: 0.789151\n",
      "[2900]\ttraining's auc: 0.876832\tvalid_1's auc: 0.789148\n",
      "[2901]\ttraining's auc: 0.876855\tvalid_1's auc: 0.789148\n",
      "[2902]\ttraining's auc: 0.876882\tvalid_1's auc: 0.789147\n",
      "[2903]\ttraining's auc: 0.876905\tvalid_1's auc: 0.789151\n",
      "[2904]\ttraining's auc: 0.876928\tvalid_1's auc: 0.789155\n",
      "[2905]\ttraining's auc: 0.876953\tvalid_1's auc: 0.789159\n",
      "[2906]\ttraining's auc: 0.876978\tvalid_1's auc: 0.789163\n",
      "[2907]\ttraining's auc: 0.877003\tvalid_1's auc: 0.789167\n",
      "[2908]\ttraining's auc: 0.877022\tvalid_1's auc: 0.789169\n",
      "[2909]\ttraining's auc: 0.877046\tvalid_1's auc: 0.789163\n",
      "[2910]\ttraining's auc: 0.877076\tvalid_1's auc: 0.78916\n",
      "[2911]\ttraining's auc: 0.877108\tvalid_1's auc: 0.789158\n",
      "[2912]\ttraining's auc: 0.877133\tvalid_1's auc: 0.789163\n",
      "[2913]\ttraining's auc: 0.877159\tvalid_1's auc: 0.789163\n",
      "[2914]\ttraining's auc: 0.877197\tvalid_1's auc: 0.789166\n",
      "[2915]\ttraining's auc: 0.87722\tvalid_1's auc: 0.789165\n",
      "[2916]\ttraining's auc: 0.877241\tvalid_1's auc: 0.78916\n",
      "[2917]\ttraining's auc: 0.877267\tvalid_1's auc: 0.789161\n",
      "[2918]\ttraining's auc: 0.87729\tvalid_1's auc: 0.789163\n",
      "[2919]\ttraining's auc: 0.877316\tvalid_1's auc: 0.789162\n",
      "[2920]\ttraining's auc: 0.877338\tvalid_1's auc: 0.789162\n",
      "[2921]\ttraining's auc: 0.877365\tvalid_1's auc: 0.789166\n",
      "[2922]\ttraining's auc: 0.877388\tvalid_1's auc: 0.789162\n",
      "[2923]\ttraining's auc: 0.877414\tvalid_1's auc: 0.789162\n",
      "[2924]\ttraining's auc: 0.87743\tvalid_1's auc: 0.789164\n",
      "[2925]\ttraining's auc: 0.877456\tvalid_1's auc: 0.789168\n",
      "[2926]\ttraining's auc: 0.877479\tvalid_1's auc: 0.789166\n",
      "[2927]\ttraining's auc: 0.877498\tvalid_1's auc: 0.789171\n",
      "[2928]\ttraining's auc: 0.877522\tvalid_1's auc: 0.789173\n",
      "[2929]\ttraining's auc: 0.877546\tvalid_1's auc: 0.789179\n",
      "[2930]\ttraining's auc: 0.877572\tvalid_1's auc: 0.789181\n",
      "[2931]\ttraining's auc: 0.877591\tvalid_1's auc: 0.789181\n",
      "[2932]\ttraining's auc: 0.877611\tvalid_1's auc: 0.789177\n",
      "[2933]\ttraining's auc: 0.877636\tvalid_1's auc: 0.789178\n",
      "[2934]\ttraining's auc: 0.877663\tvalid_1's auc: 0.789178\n",
      "[2935]\ttraining's auc: 0.877687\tvalid_1's auc: 0.789178\n",
      "[2936]\ttraining's auc: 0.877708\tvalid_1's auc: 0.789183\n",
      "[2937]\ttraining's auc: 0.877729\tvalid_1's auc: 0.789188\n",
      "[2938]\ttraining's auc: 0.877751\tvalid_1's auc: 0.789195\n",
      "[2939]\ttraining's auc: 0.877769\tvalid_1's auc: 0.789193\n",
      "[2940]\ttraining's auc: 0.877787\tvalid_1's auc: 0.789194\n",
      "[2941]\ttraining's auc: 0.877812\tvalid_1's auc: 0.789193\n",
      "[2942]\ttraining's auc: 0.877821\tvalid_1's auc: 0.789201\n",
      "[2943]\ttraining's auc: 0.877844\tvalid_1's auc: 0.789212\n",
      "[2944]\ttraining's auc: 0.877869\tvalid_1's auc: 0.789212\n",
      "[2945]\ttraining's auc: 0.877893\tvalid_1's auc: 0.789212\n",
      "[2946]\ttraining's auc: 0.877913\tvalid_1's auc: 0.789214\n",
      "[2947]\ttraining's auc: 0.877935\tvalid_1's auc: 0.789221\n",
      "[2948]\ttraining's auc: 0.877962\tvalid_1's auc: 0.789223\n",
      "[2949]\ttraining's auc: 0.877994\tvalid_1's auc: 0.789216\n",
      "[2950]\ttraining's auc: 0.878004\tvalid_1's auc: 0.789221\n",
      "[2951]\ttraining's auc: 0.878028\tvalid_1's auc: 0.789222\n",
      "[2952]\ttraining's auc: 0.878054\tvalid_1's auc: 0.789226\n",
      "[2953]\ttraining's auc: 0.878072\tvalid_1's auc: 0.789229\n",
      "[2954]\ttraining's auc: 0.87809\tvalid_1's auc: 0.789233\n",
      "[2955]\ttraining's auc: 0.878113\tvalid_1's auc: 0.789228\n",
      "[2956]\ttraining's auc: 0.878131\tvalid_1's auc: 0.789228\n",
      "[2957]\ttraining's auc: 0.878153\tvalid_1's auc: 0.789226\n",
      "[2958]\ttraining's auc: 0.87818\tvalid_1's auc: 0.789231\n",
      "[2959]\ttraining's auc: 0.878203\tvalid_1's auc: 0.789232\n",
      "[2960]\ttraining's auc: 0.87822\tvalid_1's auc: 0.789237\n",
      "[2961]\ttraining's auc: 0.878251\tvalid_1's auc: 0.789239\n",
      "[2962]\ttraining's auc: 0.878274\tvalid_1's auc: 0.789242\n",
      "[2963]\ttraining's auc: 0.878296\tvalid_1's auc: 0.789243\n",
      "[2964]\ttraining's auc: 0.878323\tvalid_1's auc: 0.789239\n",
      "[2965]\ttraining's auc: 0.878347\tvalid_1's auc: 0.789234\n",
      "[2966]\ttraining's auc: 0.878369\tvalid_1's auc: 0.789234\n",
      "[2967]\ttraining's auc: 0.878393\tvalid_1's auc: 0.789238\n",
      "[2968]\ttraining's auc: 0.878416\tvalid_1's auc: 0.789243\n",
      "[2969]\ttraining's auc: 0.87844\tvalid_1's auc: 0.789244\n",
      "[2970]\ttraining's auc: 0.878457\tvalid_1's auc: 0.789246\n",
      "[2971]\ttraining's auc: 0.87848\tvalid_1's auc: 0.789241\n",
      "[2972]\ttraining's auc: 0.87851\tvalid_1's auc: 0.789247\n",
      "[2973]\ttraining's auc: 0.878537\tvalid_1's auc: 0.789244\n",
      "[2974]\ttraining's auc: 0.878559\tvalid_1's auc: 0.789247\n",
      "[2975]\ttraining's auc: 0.878578\tvalid_1's auc: 0.789246\n",
      "[2976]\ttraining's auc: 0.87861\tvalid_1's auc: 0.78925\n",
      "[2977]\ttraining's auc: 0.878635\tvalid_1's auc: 0.789249\n",
      "[2978]\ttraining's auc: 0.878658\tvalid_1's auc: 0.789248\n",
      "[2979]\ttraining's auc: 0.878681\tvalid_1's auc: 0.78924\n",
      "[2980]\ttraining's auc: 0.878687\tvalid_1's auc: 0.789238\n",
      "[2981]\ttraining's auc: 0.878718\tvalid_1's auc: 0.789241\n",
      "[2982]\ttraining's auc: 0.878743\tvalid_1's auc: 0.789234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2983]\ttraining's auc: 0.878774\tvalid_1's auc: 0.789232\n",
      "[2984]\ttraining's auc: 0.878804\tvalid_1's auc: 0.78923\n",
      "[2985]\ttraining's auc: 0.87883\tvalid_1's auc: 0.789229\n",
      "[2986]\ttraining's auc: 0.87886\tvalid_1's auc: 0.789231\n",
      "[2987]\ttraining's auc: 0.878883\tvalid_1's auc: 0.789235\n",
      "[2988]\ttraining's auc: 0.878906\tvalid_1's auc: 0.789229\n",
      "[2989]\ttraining's auc: 0.878923\tvalid_1's auc: 0.789233\n",
      "[2990]\ttraining's auc: 0.878938\tvalid_1's auc: 0.789234\n",
      "[2991]\ttraining's auc: 0.878968\tvalid_1's auc: 0.78924\n",
      "[2992]\ttraining's auc: 0.878988\tvalid_1's auc: 0.789239\n",
      "[2993]\ttraining's auc: 0.87901\tvalid_1's auc: 0.789243\n",
      "[2994]\ttraining's auc: 0.879031\tvalid_1's auc: 0.789245\n",
      "[2995]\ttraining's auc: 0.879055\tvalid_1's auc: 0.789235\n",
      "[2996]\ttraining's auc: 0.879076\tvalid_1's auc: 0.789234\n",
      "[2997]\ttraining's auc: 0.879097\tvalid_1's auc: 0.78924\n",
      "[2998]\ttraining's auc: 0.879117\tvalid_1's auc: 0.789239\n",
      "[2999]\ttraining's auc: 0.879141\tvalid_1's auc: 0.789243\n",
      "[3000]\ttraining's auc: 0.879153\tvalid_1's auc: 0.789243\n",
      "[3001]\ttraining's auc: 0.879175\tvalid_1's auc: 0.789234\n",
      "[3002]\ttraining's auc: 0.879203\tvalid_1's auc: 0.789234\n",
      "[3003]\ttraining's auc: 0.879225\tvalid_1's auc: 0.789233\n",
      "[3004]\ttraining's auc: 0.879253\tvalid_1's auc: 0.789241\n",
      "[3005]\ttraining's auc: 0.879273\tvalid_1's auc: 0.789241\n",
      "[3006]\ttraining's auc: 0.879295\tvalid_1's auc: 0.789244\n",
      "[3007]\ttraining's auc: 0.879312\tvalid_1's auc: 0.789242\n",
      "[3008]\ttraining's auc: 0.879345\tvalid_1's auc: 0.78925\n",
      "[3009]\ttraining's auc: 0.879368\tvalid_1's auc: 0.789248\n",
      "[3010]\ttraining's auc: 0.879393\tvalid_1's auc: 0.789243\n",
      "[3011]\ttraining's auc: 0.879418\tvalid_1's auc: 0.789241\n",
      "[3012]\ttraining's auc: 0.879441\tvalid_1's auc: 0.789242\n",
      "[3013]\ttraining's auc: 0.879464\tvalid_1's auc: 0.789237\n",
      "[3014]\ttraining's auc: 0.87948\tvalid_1's auc: 0.78924\n",
      "[3015]\ttraining's auc: 0.879504\tvalid_1's auc: 0.789249\n",
      "[3016]\ttraining's auc: 0.879526\tvalid_1's auc: 0.78925\n",
      "[3017]\ttraining's auc: 0.879549\tvalid_1's auc: 0.789245\n",
      "[3018]\ttraining's auc: 0.879571\tvalid_1's auc: 0.789245\n",
      "[3019]\ttraining's auc: 0.879595\tvalid_1's auc: 0.789242\n",
      "[3020]\ttraining's auc: 0.879608\tvalid_1's auc: 0.789247\n",
      "[3021]\ttraining's auc: 0.879634\tvalid_1's auc: 0.789249\n",
      "[3022]\ttraining's auc: 0.879659\tvalid_1's auc: 0.789244\n",
      "[3023]\ttraining's auc: 0.879679\tvalid_1's auc: 0.789248\n",
      "[3024]\ttraining's auc: 0.8797\tvalid_1's auc: 0.789252\n",
      "[3025]\ttraining's auc: 0.879722\tvalid_1's auc: 0.789253\n",
      "[3026]\ttraining's auc: 0.879728\tvalid_1's auc: 0.789252\n",
      "[3027]\ttraining's auc: 0.879749\tvalid_1's auc: 0.789254\n",
      "[3028]\ttraining's auc: 0.87977\tvalid_1's auc: 0.789262\n",
      "[3029]\ttraining's auc: 0.879794\tvalid_1's auc: 0.789263\n",
      "[3030]\ttraining's auc: 0.879818\tvalid_1's auc: 0.789264\n",
      "[3031]\ttraining's auc: 0.879834\tvalid_1's auc: 0.789265\n",
      "[3032]\ttraining's auc: 0.879853\tvalid_1's auc: 0.789264\n",
      "[3033]\ttraining's auc: 0.879885\tvalid_1's auc: 0.789271\n",
      "[3034]\ttraining's auc: 0.879909\tvalid_1's auc: 0.789272\n",
      "[3035]\ttraining's auc: 0.879936\tvalid_1's auc: 0.789275\n",
      "[3036]\ttraining's auc: 0.879958\tvalid_1's auc: 0.789274\n",
      "[3037]\ttraining's auc: 0.879977\tvalid_1's auc: 0.789277\n",
      "[3038]\ttraining's auc: 0.880002\tvalid_1's auc: 0.789272\n",
      "[3039]\ttraining's auc: 0.880023\tvalid_1's auc: 0.78928\n",
      "[3040]\ttraining's auc: 0.880046\tvalid_1's auc: 0.789288\n",
      "[3041]\ttraining's auc: 0.880061\tvalid_1's auc: 0.78928\n",
      "[3042]\ttraining's auc: 0.88008\tvalid_1's auc: 0.789277\n",
      "[3043]\ttraining's auc: 0.880102\tvalid_1's auc: 0.78928\n",
      "[3044]\ttraining's auc: 0.880125\tvalid_1's auc: 0.789282\n",
      "[3045]\ttraining's auc: 0.880145\tvalid_1's auc: 0.789283\n",
      "[3046]\ttraining's auc: 0.880161\tvalid_1's auc: 0.789281\n",
      "[3047]\ttraining's auc: 0.880184\tvalid_1's auc: 0.789283\n",
      "[3048]\ttraining's auc: 0.880212\tvalid_1's auc: 0.789284\n",
      "[3049]\ttraining's auc: 0.880235\tvalid_1's auc: 0.789287\n",
      "[3050]\ttraining's auc: 0.880257\tvalid_1's auc: 0.789283\n",
      "[3051]\ttraining's auc: 0.880283\tvalid_1's auc: 0.789281\n",
      "[3052]\ttraining's auc: 0.88031\tvalid_1's auc: 0.789288\n",
      "[3053]\ttraining's auc: 0.880336\tvalid_1's auc: 0.789288\n",
      "[3054]\ttraining's auc: 0.880355\tvalid_1's auc: 0.789288\n",
      "[3055]\ttraining's auc: 0.880367\tvalid_1's auc: 0.789282\n",
      "[3056]\ttraining's auc: 0.88039\tvalid_1's auc: 0.789282\n",
      "[3057]\ttraining's auc: 0.880408\tvalid_1's auc: 0.789289\n",
      "[3058]\ttraining's auc: 0.880427\tvalid_1's auc: 0.789293\n",
      "[3059]\ttraining's auc: 0.880448\tvalid_1's auc: 0.789294\n",
      "[3060]\ttraining's auc: 0.880472\tvalid_1's auc: 0.789291\n",
      "[3061]\ttraining's auc: 0.880493\tvalid_1's auc: 0.789292\n",
      "[3062]\ttraining's auc: 0.880513\tvalid_1's auc: 0.789296\n",
      "[3063]\ttraining's auc: 0.880534\tvalid_1's auc: 0.789292\n",
      "[3064]\ttraining's auc: 0.88056\tvalid_1's auc: 0.789289\n",
      "[3065]\ttraining's auc: 0.880581\tvalid_1's auc: 0.789286\n",
      "[3066]\ttraining's auc: 0.880605\tvalid_1's auc: 0.789283\n",
      "[3067]\ttraining's auc: 0.880631\tvalid_1's auc: 0.789283\n",
      "[3068]\ttraining's auc: 0.88066\tvalid_1's auc: 0.78928\n",
      "[3069]\ttraining's auc: 0.880677\tvalid_1's auc: 0.789275\n",
      "[3070]\ttraining's auc: 0.880703\tvalid_1's auc: 0.789274\n",
      "[3071]\ttraining's auc: 0.880728\tvalid_1's auc: 0.789276\n",
      "[3072]\ttraining's auc: 0.880745\tvalid_1's auc: 0.789279\n",
      "[3073]\ttraining's auc: 0.880766\tvalid_1's auc: 0.789279\n",
      "[3074]\ttraining's auc: 0.88079\tvalid_1's auc: 0.789285\n",
      "[3075]\ttraining's auc: 0.880822\tvalid_1's auc: 0.789285\n",
      "[3076]\ttraining's auc: 0.880847\tvalid_1's auc: 0.789286\n",
      "[3077]\ttraining's auc: 0.880868\tvalid_1's auc: 0.789288\n",
      "[3078]\ttraining's auc: 0.880887\tvalid_1's auc: 0.789286\n",
      "[3079]\ttraining's auc: 0.880906\tvalid_1's auc: 0.789279\n",
      "[3080]\ttraining's auc: 0.880931\tvalid_1's auc: 0.789278\n",
      "[3081]\ttraining's auc: 0.880946\tvalid_1's auc: 0.789273\n",
      "[3082]\ttraining's auc: 0.880961\tvalid_1's auc: 0.789278\n",
      "[3083]\ttraining's auc: 0.880988\tvalid_1's auc: 0.789268\n",
      "[3084]\ttraining's auc: 0.881012\tvalid_1's auc: 0.789266\n",
      "[3085]\ttraining's auc: 0.881037\tvalid_1's auc: 0.789262\n",
      "[3086]\ttraining's auc: 0.881066\tvalid_1's auc: 0.789257\n",
      "[3087]\ttraining's auc: 0.881091\tvalid_1's auc: 0.789259\n",
      "[3088]\ttraining's auc: 0.881117\tvalid_1's auc: 0.789266\n",
      "[3089]\ttraining's auc: 0.881144\tvalid_1's auc: 0.789263\n",
      "[3090]\ttraining's auc: 0.881176\tvalid_1's auc: 0.789264\n",
      "[3091]\ttraining's auc: 0.881201\tvalid_1's auc: 0.789268\n",
      "[3092]\ttraining's auc: 0.881219\tvalid_1's auc: 0.789265\n",
      "[3093]\ttraining's auc: 0.881244\tvalid_1's auc: 0.789271\n",
      "[3094]\ttraining's auc: 0.881263\tvalid_1's auc: 0.789272\n",
      "[3095]\ttraining's auc: 0.881294\tvalid_1's auc: 0.789273\n",
      "[3096]\ttraining's auc: 0.881314\tvalid_1's auc: 0.789273\n",
      "[3097]\ttraining's auc: 0.881338\tvalid_1's auc: 0.789278\n",
      "[3098]\ttraining's auc: 0.881354\tvalid_1's auc: 0.789282\n",
      "[3099]\ttraining's auc: 0.881377\tvalid_1's auc: 0.78929\n",
      "[3100]\ttraining's auc: 0.881394\tvalid_1's auc: 0.789289\n",
      "[3101]\ttraining's auc: 0.881417\tvalid_1's auc: 0.789288\n",
      "[3102]\ttraining's auc: 0.881438\tvalid_1's auc: 0.789295\n",
      "[3103]\ttraining's auc: 0.881465\tvalid_1's auc: 0.789304\n",
      "[3104]\ttraining's auc: 0.881491\tvalid_1's auc: 0.789306\n",
      "[3105]\ttraining's auc: 0.88151\tvalid_1's auc: 0.789305\n",
      "[3106]\ttraining's auc: 0.881515\tvalid_1's auc: 0.789305\n",
      "[3107]\ttraining's auc: 0.881535\tvalid_1's auc: 0.789314\n",
      "[3108]\ttraining's auc: 0.881563\tvalid_1's auc: 0.789311\n",
      "[3109]\ttraining's auc: 0.881582\tvalid_1's auc: 0.789301\n",
      "[3110]\ttraining's auc: 0.881602\tvalid_1's auc: 0.789299\n",
      "[3111]\ttraining's auc: 0.881626\tvalid_1's auc: 0.789299\n",
      "[3112]\ttraining's auc: 0.881648\tvalid_1's auc: 0.789304\n",
      "[3113]\ttraining's auc: 0.881662\tvalid_1's auc: 0.7893\n",
      "[3114]\ttraining's auc: 0.881682\tvalid_1's auc: 0.789295\n",
      "[3115]\ttraining's auc: 0.881703\tvalid_1's auc: 0.789299\n",
      "[3116]\ttraining's auc: 0.881729\tvalid_1's auc: 0.789305\n",
      "[3117]\ttraining's auc: 0.88175\tvalid_1's auc: 0.789303\n",
      "[3118]\ttraining's auc: 0.881769\tvalid_1's auc: 0.789304\n",
      "[3119]\ttraining's auc: 0.881795\tvalid_1's auc: 0.789312\n",
      "[3120]\ttraining's auc: 0.881821\tvalid_1's auc: 0.789312\n",
      "[3121]\ttraining's auc: 0.881848\tvalid_1's auc: 0.789309\n",
      "[3122]\ttraining's auc: 0.881873\tvalid_1's auc: 0.789311\n",
      "[3123]\ttraining's auc: 0.881887\tvalid_1's auc: 0.789312\n",
      "[3124]\ttraining's auc: 0.881899\tvalid_1's auc: 0.789314\n",
      "[3125]\ttraining's auc: 0.881927\tvalid_1's auc: 0.78932\n",
      "[3126]\ttraining's auc: 0.881945\tvalid_1's auc: 0.789318\n",
      "[3127]\ttraining's auc: 0.881973\tvalid_1's auc: 0.789318\n",
      "[3128]\ttraining's auc: 0.881997\tvalid_1's auc: 0.78931\n",
      "[3129]\ttraining's auc: 0.882022\tvalid_1's auc: 0.789311\n",
      "[3130]\ttraining's auc: 0.882047\tvalid_1's auc: 0.789313\n",
      "[3131]\ttraining's auc: 0.882069\tvalid_1's auc: 0.789313\n",
      "[3132]\ttraining's auc: 0.882094\tvalid_1's auc: 0.789315\n",
      "[3133]\ttraining's auc: 0.882111\tvalid_1's auc: 0.789308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3134]\ttraining's auc: 0.882133\tvalid_1's auc: 0.789306\n",
      "[3135]\ttraining's auc: 0.882148\tvalid_1's auc: 0.789306\n",
      "[3136]\ttraining's auc: 0.88217\tvalid_1's auc: 0.789304\n",
      "[3137]\ttraining's auc: 0.882193\tvalid_1's auc: 0.7893\n",
      "[3138]\ttraining's auc: 0.882215\tvalid_1's auc: 0.789301\n",
      "[3139]\ttraining's auc: 0.88223\tvalid_1's auc: 0.789305\n",
      "[3140]\ttraining's auc: 0.882255\tvalid_1's auc: 0.789308\n",
      "[3141]\ttraining's auc: 0.88227\tvalid_1's auc: 0.789306\n",
      "[3142]\ttraining's auc: 0.882288\tvalid_1's auc: 0.789311\n",
      "[3143]\ttraining's auc: 0.882311\tvalid_1's auc: 0.789304\n",
      "[3144]\ttraining's auc: 0.88234\tvalid_1's auc: 0.78931\n",
      "[3145]\ttraining's auc: 0.882356\tvalid_1's auc: 0.78931\n",
      "[3146]\ttraining's auc: 0.882389\tvalid_1's auc: 0.789312\n",
      "[3147]\ttraining's auc: 0.882403\tvalid_1's auc: 0.789315\n",
      "[3148]\ttraining's auc: 0.882427\tvalid_1's auc: 0.78931\n",
      "[3149]\ttraining's auc: 0.882445\tvalid_1's auc: 0.789315\n",
      "[3150]\ttraining's auc: 0.882465\tvalid_1's auc: 0.789312\n",
      "[3151]\ttraining's auc: 0.882484\tvalid_1's auc: 0.78931\n",
      "[3152]\ttraining's auc: 0.882503\tvalid_1's auc: 0.789309\n",
      "[3153]\ttraining's auc: 0.882525\tvalid_1's auc: 0.789302\n",
      "[3154]\ttraining's auc: 0.882545\tvalid_1's auc: 0.789298\n",
      "[3155]\ttraining's auc: 0.882571\tvalid_1's auc: 0.789291\n",
      "[3156]\ttraining's auc: 0.882597\tvalid_1's auc: 0.789291\n",
      "[3157]\ttraining's auc: 0.882616\tvalid_1's auc: 0.789289\n",
      "[3158]\ttraining's auc: 0.882638\tvalid_1's auc: 0.789295\n",
      "[3159]\ttraining's auc: 0.882664\tvalid_1's auc: 0.789294\n",
      "[3160]\ttraining's auc: 0.882688\tvalid_1's auc: 0.789292\n",
      "[3161]\ttraining's auc: 0.882714\tvalid_1's auc: 0.789292\n",
      "[3162]\ttraining's auc: 0.882741\tvalid_1's auc: 0.789291\n",
      "[3163]\ttraining's auc: 0.882752\tvalid_1's auc: 0.789288\n",
      "[3164]\ttraining's auc: 0.882771\tvalid_1's auc: 0.789292\n",
      "[3165]\ttraining's auc: 0.882786\tvalid_1's auc: 0.789294\n",
      "[3166]\ttraining's auc: 0.882802\tvalid_1's auc: 0.789291\n",
      "[3167]\ttraining's auc: 0.882822\tvalid_1's auc: 0.789294\n",
      "[3168]\ttraining's auc: 0.88285\tvalid_1's auc: 0.789292\n",
      "[3169]\ttraining's auc: 0.882865\tvalid_1's auc: 0.789298\n",
      "[3170]\ttraining's auc: 0.882876\tvalid_1's auc: 0.789299\n",
      "[3171]\ttraining's auc: 0.882898\tvalid_1's auc: 0.789293\n",
      "[3172]\ttraining's auc: 0.882913\tvalid_1's auc: 0.789295\n",
      "[3173]\ttraining's auc: 0.882926\tvalid_1's auc: 0.789293\n",
      "[3174]\ttraining's auc: 0.882945\tvalid_1's auc: 0.789293\n",
      "[3175]\ttraining's auc: 0.882973\tvalid_1's auc: 0.789292\n",
      "[3176]\ttraining's auc: 0.883002\tvalid_1's auc: 0.789293\n",
      "[3177]\ttraining's auc: 0.883022\tvalid_1's auc: 0.789298\n",
      "[3178]\ttraining's auc: 0.883041\tvalid_1's auc: 0.789293\n",
      "[3179]\ttraining's auc: 0.883064\tvalid_1's auc: 0.789284\n",
      "[3180]\ttraining's auc: 0.88308\tvalid_1's auc: 0.789285\n",
      "[3181]\ttraining's auc: 0.883097\tvalid_1's auc: 0.789289\n",
      "[3182]\ttraining's auc: 0.883106\tvalid_1's auc: 0.789289\n",
      "[3183]\ttraining's auc: 0.883114\tvalid_1's auc: 0.789291\n",
      "[3184]\ttraining's auc: 0.883132\tvalid_1's auc: 0.789293\n",
      "[3185]\ttraining's auc: 0.88315\tvalid_1's auc: 0.789287\n",
      "[3186]\ttraining's auc: 0.883167\tvalid_1's auc: 0.789284\n",
      "[3187]\ttraining's auc: 0.883186\tvalid_1's auc: 0.789289\n",
      "[3188]\ttraining's auc: 0.883215\tvalid_1's auc: 0.789289\n",
      "[3189]\ttraining's auc: 0.883225\tvalid_1's auc: 0.789283\n",
      "[3190]\ttraining's auc: 0.883242\tvalid_1's auc: 0.789278\n",
      "[3191]\ttraining's auc: 0.883265\tvalid_1's auc: 0.789283\n",
      "[3192]\ttraining's auc: 0.883292\tvalid_1's auc: 0.789284\n",
      "[3193]\ttraining's auc: 0.883315\tvalid_1's auc: 0.789287\n",
      "[3194]\ttraining's auc: 0.883326\tvalid_1's auc: 0.78929\n",
      "[3195]\ttraining's auc: 0.883348\tvalid_1's auc: 0.789289\n",
      "[3196]\ttraining's auc: 0.883367\tvalid_1's auc: 0.789293\n",
      "[3197]\ttraining's auc: 0.883388\tvalid_1's auc: 0.789295\n",
      "[3198]\ttraining's auc: 0.883417\tvalid_1's auc: 0.789298\n",
      "[3199]\ttraining's auc: 0.883444\tvalid_1's auc: 0.789294\n",
      "[3200]\ttraining's auc: 0.883465\tvalid_1's auc: 0.789294\n",
      "[3201]\ttraining's auc: 0.883491\tvalid_1's auc: 0.789292\n",
      "[3202]\ttraining's auc: 0.883508\tvalid_1's auc: 0.789292\n",
      "[3203]\ttraining's auc: 0.883532\tvalid_1's auc: 0.789285\n",
      "[3204]\ttraining's auc: 0.883558\tvalid_1's auc: 0.789288\n",
      "[3205]\ttraining's auc: 0.883582\tvalid_1's auc: 0.78929\n",
      "[3206]\ttraining's auc: 0.883599\tvalid_1's auc: 0.789292\n",
      "[3207]\ttraining's auc: 0.883622\tvalid_1's auc: 0.789296\n",
      "[3208]\ttraining's auc: 0.88364\tvalid_1's auc: 0.789297\n",
      "[3209]\ttraining's auc: 0.883648\tvalid_1's auc: 0.789298\n",
      "[3210]\ttraining's auc: 0.883662\tvalid_1's auc: 0.789306\n",
      "[3211]\ttraining's auc: 0.883689\tvalid_1's auc: 0.789303\n",
      "[3212]\ttraining's auc: 0.883711\tvalid_1's auc: 0.789302\n",
      "[3213]\ttraining's auc: 0.883726\tvalid_1's auc: 0.789303\n",
      "[3214]\ttraining's auc: 0.883749\tvalid_1's auc: 0.789302\n",
      "[3215]\ttraining's auc: 0.883768\tvalid_1's auc: 0.789303\n",
      "[3216]\ttraining's auc: 0.883793\tvalid_1's auc: 0.789298\n",
      "[3217]\ttraining's auc: 0.883812\tvalid_1's auc: 0.789298\n",
      "[3218]\ttraining's auc: 0.883829\tvalid_1's auc: 0.789299\n",
      "[3219]\ttraining's auc: 0.883855\tvalid_1's auc: 0.789297\n",
      "[3220]\ttraining's auc: 0.883873\tvalid_1's auc: 0.789297\n",
      "[3221]\ttraining's auc: 0.883904\tvalid_1's auc: 0.789298\n",
      "[3222]\ttraining's auc: 0.883925\tvalid_1's auc: 0.789299\n",
      "[3223]\ttraining's auc: 0.883951\tvalid_1's auc: 0.789307\n",
      "[3224]\ttraining's auc: 0.88397\tvalid_1's auc: 0.78931\n",
      "[3225]\ttraining's auc: 0.883994\tvalid_1's auc: 0.789306\n",
      "[3226]\ttraining's auc: 0.884016\tvalid_1's auc: 0.789304\n",
      "[3227]\ttraining's auc: 0.884037\tvalid_1's auc: 0.7893\n",
      "[3228]\ttraining's auc: 0.884065\tvalid_1's auc: 0.7893\n",
      "[3229]\ttraining's auc: 0.884092\tvalid_1's auc: 0.789302\n",
      "[3230]\ttraining's auc: 0.88411\tvalid_1's auc: 0.7893\n",
      "[3231]\ttraining's auc: 0.884132\tvalid_1's auc: 0.789303\n",
      "[3232]\ttraining's auc: 0.884156\tvalid_1's auc: 0.789305\n",
      "[3233]\ttraining's auc: 0.884173\tvalid_1's auc: 0.789305\n",
      "[3234]\ttraining's auc: 0.884193\tvalid_1's auc: 0.789306\n",
      "[3235]\ttraining's auc: 0.884216\tvalid_1's auc: 0.789314\n",
      "[3236]\ttraining's auc: 0.884235\tvalid_1's auc: 0.789317\n",
      "[3237]\ttraining's auc: 0.884254\tvalid_1's auc: 0.789325\n",
      "[3238]\ttraining's auc: 0.884275\tvalid_1's auc: 0.78933\n",
      "[3239]\ttraining's auc: 0.884292\tvalid_1's auc: 0.789333\n",
      "[3240]\ttraining's auc: 0.884309\tvalid_1's auc: 0.78933\n",
      "[3241]\ttraining's auc: 0.88432\tvalid_1's auc: 0.789328\n",
      "[3242]\ttraining's auc: 0.884341\tvalid_1's auc: 0.78933\n",
      "[3243]\ttraining's auc: 0.884361\tvalid_1's auc: 0.789326\n",
      "[3244]\ttraining's auc: 0.884386\tvalid_1's auc: 0.789327\n",
      "[3245]\ttraining's auc: 0.884398\tvalid_1's auc: 0.789322\n",
      "[3246]\ttraining's auc: 0.884412\tvalid_1's auc: 0.789324\n",
      "[3247]\ttraining's auc: 0.884426\tvalid_1's auc: 0.789318\n",
      "[3248]\ttraining's auc: 0.88445\tvalid_1's auc: 0.789335\n",
      "[3249]\ttraining's auc: 0.884467\tvalid_1's auc: 0.789335\n",
      "[3250]\ttraining's auc: 0.884487\tvalid_1's auc: 0.789333\n",
      "[3251]\ttraining's auc: 0.884504\tvalid_1's auc: 0.789336\n",
      "[3252]\ttraining's auc: 0.884527\tvalid_1's auc: 0.789336\n",
      "[3253]\ttraining's auc: 0.884549\tvalid_1's auc: 0.789345\n",
      "[3254]\ttraining's auc: 0.88456\tvalid_1's auc: 0.789343\n",
      "[3255]\ttraining's auc: 0.884572\tvalid_1's auc: 0.789345\n",
      "[3256]\ttraining's auc: 0.884595\tvalid_1's auc: 0.789335\n",
      "[3257]\ttraining's auc: 0.884614\tvalid_1's auc: 0.789337\n",
      "[3258]\ttraining's auc: 0.884643\tvalid_1's auc: 0.789338\n",
      "[3259]\ttraining's auc: 0.884658\tvalid_1's auc: 0.789334\n",
      "[3260]\ttraining's auc: 0.884671\tvalid_1's auc: 0.789342\n",
      "[3261]\ttraining's auc: 0.88469\tvalid_1's auc: 0.789343\n",
      "[3262]\ttraining's auc: 0.884708\tvalid_1's auc: 0.789342\n",
      "[3263]\ttraining's auc: 0.884729\tvalid_1's auc: 0.789342\n",
      "[3264]\ttraining's auc: 0.884755\tvalid_1's auc: 0.78934\n",
      "[3265]\ttraining's auc: 0.884774\tvalid_1's auc: 0.789336\n",
      "[3266]\ttraining's auc: 0.884793\tvalid_1's auc: 0.789332\n",
      "[3267]\ttraining's auc: 0.884818\tvalid_1's auc: 0.789329\n",
      "[3268]\ttraining's auc: 0.884845\tvalid_1's auc: 0.78933\n",
      "[3269]\ttraining's auc: 0.884861\tvalid_1's auc: 0.789326\n",
      "[3270]\ttraining's auc: 0.884884\tvalid_1's auc: 0.78933\n",
      "[3271]\ttraining's auc: 0.884908\tvalid_1's auc: 0.78933\n",
      "[3272]\ttraining's auc: 0.884937\tvalid_1's auc: 0.789342\n",
      "[3273]\ttraining's auc: 0.884956\tvalid_1's auc: 0.789343\n",
      "[3274]\ttraining's auc: 0.884983\tvalid_1's auc: 0.789341\n",
      "[3275]\ttraining's auc: 0.885006\tvalid_1's auc: 0.789336\n",
      "[3276]\ttraining's auc: 0.885026\tvalid_1's auc: 0.789338\n",
      "[3277]\ttraining's auc: 0.885043\tvalid_1's auc: 0.789333\n",
      "[3278]\ttraining's auc: 0.885061\tvalid_1's auc: 0.789333\n",
      "[3279]\ttraining's auc: 0.885076\tvalid_1's auc: 0.789329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3280]\ttraining's auc: 0.885103\tvalid_1's auc: 0.789332\n",
      "[3281]\ttraining's auc: 0.885128\tvalid_1's auc: 0.789331\n",
      "[3282]\ttraining's auc: 0.885144\tvalid_1's auc: 0.789327\n",
      "[3283]\ttraining's auc: 0.885168\tvalid_1's auc: 0.78933\n",
      "[3284]\ttraining's auc: 0.885188\tvalid_1's auc: 0.789328\n",
      "[3285]\ttraining's auc: 0.885209\tvalid_1's auc: 0.789331\n",
      "[3286]\ttraining's auc: 0.885231\tvalid_1's auc: 0.789325\n",
      "[3287]\ttraining's auc: 0.885243\tvalid_1's auc: 0.789322\n",
      "[3288]\ttraining's auc: 0.885267\tvalid_1's auc: 0.789323\n",
      "[3289]\ttraining's auc: 0.885288\tvalid_1's auc: 0.789319\n",
      "[3290]\ttraining's auc: 0.885311\tvalid_1's auc: 0.78931\n",
      "[3291]\ttraining's auc: 0.88533\tvalid_1's auc: 0.789322\n",
      "[3292]\ttraining's auc: 0.885353\tvalid_1's auc: 0.789326\n",
      "[3293]\ttraining's auc: 0.885371\tvalid_1's auc: 0.789324\n",
      "[3294]\ttraining's auc: 0.885393\tvalid_1's auc: 0.789327\n",
      "[3295]\ttraining's auc: 0.88542\tvalid_1's auc: 0.789324\n",
      "[3296]\ttraining's auc: 0.885448\tvalid_1's auc: 0.789326\n",
      "[3297]\ttraining's auc: 0.885462\tvalid_1's auc: 0.789325\n",
      "[3298]\ttraining's auc: 0.885487\tvalid_1's auc: 0.789323\n",
      "[3299]\ttraining's auc: 0.885504\tvalid_1's auc: 0.789324\n",
      "[3300]\ttraining's auc: 0.885516\tvalid_1's auc: 0.789326\n",
      "[3301]\ttraining's auc: 0.885533\tvalid_1's auc: 0.789329\n",
      "[3302]\ttraining's auc: 0.885557\tvalid_1's auc: 0.789332\n",
      "[3303]\ttraining's auc: 0.88558\tvalid_1's auc: 0.78934\n",
      "[3304]\ttraining's auc: 0.885605\tvalid_1's auc: 0.789344\n",
      "[3305]\ttraining's auc: 0.885623\tvalid_1's auc: 0.789343\n",
      "[3306]\ttraining's auc: 0.885646\tvalid_1's auc: 0.789338\n",
      "[3307]\ttraining's auc: 0.885676\tvalid_1's auc: 0.78934\n",
      "[3308]\ttraining's auc: 0.885693\tvalid_1's auc: 0.789342\n",
      "[3309]\ttraining's auc: 0.885708\tvalid_1's auc: 0.789342\n",
      "[3310]\ttraining's auc: 0.885729\tvalid_1's auc: 0.789344\n",
      "[3311]\ttraining's auc: 0.885754\tvalid_1's auc: 0.789353\n",
      "[3312]\ttraining's auc: 0.885769\tvalid_1's auc: 0.789354\n",
      "[3313]\ttraining's auc: 0.885794\tvalid_1's auc: 0.789352\n",
      "[3314]\ttraining's auc: 0.885812\tvalid_1's auc: 0.789358\n",
      "[3315]\ttraining's auc: 0.885831\tvalid_1's auc: 0.789366\n",
      "[3316]\ttraining's auc: 0.885852\tvalid_1's auc: 0.78937\n",
      "[3317]\ttraining's auc: 0.885857\tvalid_1's auc: 0.789371\n",
      "[3318]\ttraining's auc: 0.885879\tvalid_1's auc: 0.789369\n",
      "[3319]\ttraining's auc: 0.885903\tvalid_1's auc: 0.789366\n",
      "[3320]\ttraining's auc: 0.885926\tvalid_1's auc: 0.789369\n",
      "[3321]\ttraining's auc: 0.885948\tvalid_1's auc: 0.789367\n",
      "[3322]\ttraining's auc: 0.885974\tvalid_1's auc: 0.789357\n",
      "[3323]\ttraining's auc: 0.886005\tvalid_1's auc: 0.789358\n",
      "[3324]\ttraining's auc: 0.886021\tvalid_1's auc: 0.789356\n",
      "[3325]\ttraining's auc: 0.88604\tvalid_1's auc: 0.789351\n",
      "[3326]\ttraining's auc: 0.886063\tvalid_1's auc: 0.789349\n",
      "[3327]\ttraining's auc: 0.886085\tvalid_1's auc: 0.789352\n",
      "[3328]\ttraining's auc: 0.886103\tvalid_1's auc: 0.78935\n",
      "[3329]\ttraining's auc: 0.886123\tvalid_1's auc: 0.789343\n",
      "[3330]\ttraining's auc: 0.886135\tvalid_1's auc: 0.789341\n",
      "[3331]\ttraining's auc: 0.886155\tvalid_1's auc: 0.789334\n",
      "[3332]\ttraining's auc: 0.886173\tvalid_1's auc: 0.789334\n",
      "[3333]\ttraining's auc: 0.886186\tvalid_1's auc: 0.789336\n",
      "[3334]\ttraining's auc: 0.886208\tvalid_1's auc: 0.789337\n",
      "[3335]\ttraining's auc: 0.88623\tvalid_1's auc: 0.789342\n",
      "[3336]\ttraining's auc: 0.886256\tvalid_1's auc: 0.789331\n",
      "[3337]\ttraining's auc: 0.886281\tvalid_1's auc: 0.789335\n",
      "[3338]\ttraining's auc: 0.886292\tvalid_1's auc: 0.789336\n",
      "[3339]\ttraining's auc: 0.886311\tvalid_1's auc: 0.789334\n",
      "[3340]\ttraining's auc: 0.886322\tvalid_1's auc: 0.789336\n",
      "[3341]\ttraining's auc: 0.886334\tvalid_1's auc: 0.789333\n",
      "[3342]\ttraining's auc: 0.886341\tvalid_1's auc: 0.78933\n",
      "[3343]\ttraining's auc: 0.886349\tvalid_1's auc: 0.789326\n",
      "[3344]\ttraining's auc: 0.886378\tvalid_1's auc: 0.789329\n",
      "[3345]\ttraining's auc: 0.886406\tvalid_1's auc: 0.789333\n",
      "[3346]\ttraining's auc: 0.886429\tvalid_1's auc: 0.78933\n",
      "[3347]\ttraining's auc: 0.88645\tvalid_1's auc: 0.789333\n",
      "[3348]\ttraining's auc: 0.886468\tvalid_1's auc: 0.789331\n",
      "[3349]\ttraining's auc: 0.886489\tvalid_1's auc: 0.789333\n",
      "[3350]\ttraining's auc: 0.886513\tvalid_1's auc: 0.789338\n",
      "[3351]\ttraining's auc: 0.886532\tvalid_1's auc: 0.789341\n",
      "[3352]\ttraining's auc: 0.886553\tvalid_1's auc: 0.789349\n",
      "[3353]\ttraining's auc: 0.886566\tvalid_1's auc: 0.789346\n",
      "[3354]\ttraining's auc: 0.886581\tvalid_1's auc: 0.789348\n",
      "[3355]\ttraining's auc: 0.886601\tvalid_1's auc: 0.78934\n",
      "[3356]\ttraining's auc: 0.88662\tvalid_1's auc: 0.789341\n",
      "[3357]\ttraining's auc: 0.88665\tvalid_1's auc: 0.789345\n",
      "[3358]\ttraining's auc: 0.886664\tvalid_1's auc: 0.789341\n",
      "[3359]\ttraining's auc: 0.886684\tvalid_1's auc: 0.789344\n",
      "[3360]\ttraining's auc: 0.886706\tvalid_1's auc: 0.789343\n",
      "[3361]\ttraining's auc: 0.88673\tvalid_1's auc: 0.789344\n",
      "[3362]\ttraining's auc: 0.886743\tvalid_1's auc: 0.789342\n",
      "[3363]\ttraining's auc: 0.886755\tvalid_1's auc: 0.789338\n",
      "[3364]\ttraining's auc: 0.886775\tvalid_1's auc: 0.789341\n",
      "[3365]\ttraining's auc: 0.886795\tvalid_1's auc: 0.789343\n",
      "[3366]\ttraining's auc: 0.886814\tvalid_1's auc: 0.789336\n",
      "[3367]\ttraining's auc: 0.886831\tvalid_1's auc: 0.78934\n",
      "[3368]\ttraining's auc: 0.886854\tvalid_1's auc: 0.789335\n",
      "[3369]\ttraining's auc: 0.886871\tvalid_1's auc: 0.789331\n",
      "[3370]\ttraining's auc: 0.886888\tvalid_1's auc: 0.789331\n",
      "[3371]\ttraining's auc: 0.8869\tvalid_1's auc: 0.789334\n",
      "[3372]\ttraining's auc: 0.886918\tvalid_1's auc: 0.789332\n",
      "[3373]\ttraining's auc: 0.886941\tvalid_1's auc: 0.78933\n",
      "[3374]\ttraining's auc: 0.886952\tvalid_1's auc: 0.789331\n",
      "[3375]\ttraining's auc: 0.88697\tvalid_1's auc: 0.789323\n",
      "[3376]\ttraining's auc: 0.886985\tvalid_1's auc: 0.789329\n",
      "[3377]\ttraining's auc: 0.886994\tvalid_1's auc: 0.789329\n",
      "[3378]\ttraining's auc: 0.887012\tvalid_1's auc: 0.789333\n",
      "[3379]\ttraining's auc: 0.887028\tvalid_1's auc: 0.789336\n",
      "[3380]\ttraining's auc: 0.887048\tvalid_1's auc: 0.789342\n",
      "[3381]\ttraining's auc: 0.887074\tvalid_1's auc: 0.789344\n",
      "[3382]\ttraining's auc: 0.887098\tvalid_1's auc: 0.789348\n",
      "[3383]\ttraining's auc: 0.887116\tvalid_1's auc: 0.789348\n",
      "[3384]\ttraining's auc: 0.88713\tvalid_1's auc: 0.789352\n",
      "[3385]\ttraining's auc: 0.887151\tvalid_1's auc: 0.789351\n",
      "[3386]\ttraining's auc: 0.88717\tvalid_1's auc: 0.789352\n",
      "[3387]\ttraining's auc: 0.887193\tvalid_1's auc: 0.789356\n",
      "[3388]\ttraining's auc: 0.887212\tvalid_1's auc: 0.789355\n",
      "[3389]\ttraining's auc: 0.887233\tvalid_1's auc: 0.789357\n",
      "[3390]\ttraining's auc: 0.887245\tvalid_1's auc: 0.789354\n",
      "[3391]\ttraining's auc: 0.887264\tvalid_1's auc: 0.78935\n",
      "[3392]\ttraining's auc: 0.887279\tvalid_1's auc: 0.789353\n",
      "[3393]\ttraining's auc: 0.887295\tvalid_1's auc: 0.789349\n",
      "[3394]\ttraining's auc: 0.887315\tvalid_1's auc: 0.78935\n",
      "[3395]\ttraining's auc: 0.88734\tvalid_1's auc: 0.789356\n",
      "[3396]\ttraining's auc: 0.887362\tvalid_1's auc: 0.789349\n",
      "[3397]\ttraining's auc: 0.88737\tvalid_1's auc: 0.789348\n",
      "[3398]\ttraining's auc: 0.887382\tvalid_1's auc: 0.78935\n",
      "[3399]\ttraining's auc: 0.887408\tvalid_1's auc: 0.789352\n",
      "[3400]\ttraining's auc: 0.887426\tvalid_1's auc: 0.789356\n",
      "[3401]\ttraining's auc: 0.88744\tvalid_1's auc: 0.789353\n",
      "[3402]\ttraining's auc: 0.887455\tvalid_1's auc: 0.789352\n",
      "[3403]\ttraining's auc: 0.887481\tvalid_1's auc: 0.789344\n",
      "[3404]\ttraining's auc: 0.887506\tvalid_1's auc: 0.789345\n",
      "[3405]\ttraining's auc: 0.887539\tvalid_1's auc: 0.789353\n",
      "[3406]\ttraining's auc: 0.887554\tvalid_1's auc: 0.789356\n",
      "[3407]\ttraining's auc: 0.887576\tvalid_1's auc: 0.789361\n",
      "[3408]\ttraining's auc: 0.887585\tvalid_1's auc: 0.78936\n",
      "[3409]\ttraining's auc: 0.887603\tvalid_1's auc: 0.789361\n",
      "[3410]\ttraining's auc: 0.887623\tvalid_1's auc: 0.789369\n",
      "[3411]\ttraining's auc: 0.887644\tvalid_1's auc: 0.789375\n",
      "[3412]\ttraining's auc: 0.887666\tvalid_1's auc: 0.789374\n",
      "[3413]\ttraining's auc: 0.887691\tvalid_1's auc: 0.789378\n",
      "[3414]\ttraining's auc: 0.887708\tvalid_1's auc: 0.789372\n",
      "[3415]\ttraining's auc: 0.88773\tvalid_1's auc: 0.789371\n",
      "[3416]\ttraining's auc: 0.887754\tvalid_1's auc: 0.789372\n",
      "[3417]\ttraining's auc: 0.887775\tvalid_1's auc: 0.789375\n",
      "[3418]\ttraining's auc: 0.887806\tvalid_1's auc: 0.789372\n",
      "[3419]\ttraining's auc: 0.88783\tvalid_1's auc: 0.789369\n",
      "[3420]\ttraining's auc: 0.887847\tvalid_1's auc: 0.789374\n",
      "[3421]\ttraining's auc: 0.887864\tvalid_1's auc: 0.789381\n",
      "[3422]\ttraining's auc: 0.887896\tvalid_1's auc: 0.789383\n",
      "[3423]\ttraining's auc: 0.887916\tvalid_1's auc: 0.78938\n",
      "[3424]\ttraining's auc: 0.88793\tvalid_1's auc: 0.789383\n",
      "[3425]\ttraining's auc: 0.887946\tvalid_1's auc: 0.78938\n",
      "[3426]\ttraining's auc: 0.887966\tvalid_1's auc: 0.789378\n",
      "[3427]\ttraining's auc: 0.88798\tvalid_1's auc: 0.789373\n",
      "[3428]\ttraining's auc: 0.888\tvalid_1's auc: 0.789371\n",
      "[3429]\ttraining's auc: 0.888011\tvalid_1's auc: 0.789374\n",
      "[3430]\ttraining's auc: 0.888029\tvalid_1's auc: 0.789377\n",
      "[3431]\ttraining's auc: 0.888052\tvalid_1's auc: 0.789382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3432]\ttraining's auc: 0.888076\tvalid_1's auc: 0.789376\n",
      "[3433]\ttraining's auc: 0.888103\tvalid_1's auc: 0.789375\n",
      "[3434]\ttraining's auc: 0.888118\tvalid_1's auc: 0.789375\n",
      "[3435]\ttraining's auc: 0.88814\tvalid_1's auc: 0.789371\n",
      "[3436]\ttraining's auc: 0.888162\tvalid_1's auc: 0.789377\n",
      "[3437]\ttraining's auc: 0.888178\tvalid_1's auc: 0.789375\n",
      "[3438]\ttraining's auc: 0.888198\tvalid_1's auc: 0.789375\n",
      "[3439]\ttraining's auc: 0.888217\tvalid_1's auc: 0.789371\n",
      "[3440]\ttraining's auc: 0.888238\tvalid_1's auc: 0.789368\n",
      "[3441]\ttraining's auc: 0.888259\tvalid_1's auc: 0.789363\n",
      "[3442]\ttraining's auc: 0.888286\tvalid_1's auc: 0.789356\n",
      "[3443]\ttraining's auc: 0.888307\tvalid_1's auc: 0.789351\n",
      "[3444]\ttraining's auc: 0.888317\tvalid_1's auc: 0.789352\n",
      "[3445]\ttraining's auc: 0.888333\tvalid_1's auc: 0.789347\n",
      "[3446]\ttraining's auc: 0.888359\tvalid_1's auc: 0.789345\n",
      "[3447]\ttraining's auc: 0.888378\tvalid_1's auc: 0.789358\n",
      "[3448]\ttraining's auc: 0.888406\tvalid_1's auc: 0.789357\n",
      "[3449]\ttraining's auc: 0.888413\tvalid_1's auc: 0.789359\n",
      "[3450]\ttraining's auc: 0.888432\tvalid_1's auc: 0.78936\n",
      "[3451]\ttraining's auc: 0.888447\tvalid_1's auc: 0.789357\n",
      "[3452]\ttraining's auc: 0.888476\tvalid_1's auc: 0.789352\n",
      "[3453]\ttraining's auc: 0.888499\tvalid_1's auc: 0.78935\n",
      "[3454]\ttraining's auc: 0.888521\tvalid_1's auc: 0.789348\n",
      "[3455]\ttraining's auc: 0.888532\tvalid_1's auc: 0.789351\n",
      "[3456]\ttraining's auc: 0.888553\tvalid_1's auc: 0.789346\n",
      "[3457]\ttraining's auc: 0.888575\tvalid_1's auc: 0.78935\n",
      "[3458]\ttraining's auc: 0.888603\tvalid_1's auc: 0.789351\n",
      "[3459]\ttraining's auc: 0.888628\tvalid_1's auc: 0.789345\n",
      "[3460]\ttraining's auc: 0.888647\tvalid_1's auc: 0.789342\n",
      "[3461]\ttraining's auc: 0.888664\tvalid_1's auc: 0.789343\n",
      "[3462]\ttraining's auc: 0.888682\tvalid_1's auc: 0.789333\n",
      "[3463]\ttraining's auc: 0.888708\tvalid_1's auc: 0.789332\n",
      "[3464]\ttraining's auc: 0.888731\tvalid_1's auc: 0.789334\n",
      "[3465]\ttraining's auc: 0.888741\tvalid_1's auc: 0.789335\n",
      "[3466]\ttraining's auc: 0.888764\tvalid_1's auc: 0.789335\n",
      "[3467]\ttraining's auc: 0.888778\tvalid_1's auc: 0.789334\n",
      "[3468]\ttraining's auc: 0.88879\tvalid_1's auc: 0.789334\n",
      "[3469]\ttraining's auc: 0.88881\tvalid_1's auc: 0.78934\n",
      "[3470]\ttraining's auc: 0.888828\tvalid_1's auc: 0.78934\n",
      "[3471]\ttraining's auc: 0.888851\tvalid_1's auc: 0.789334\n",
      "[3472]\ttraining's auc: 0.888867\tvalid_1's auc: 0.78933\n",
      "[3473]\ttraining's auc: 0.888877\tvalid_1's auc: 0.789331\n",
      "[3474]\ttraining's auc: 0.888901\tvalid_1's auc: 0.789329\n",
      "[3475]\ttraining's auc: 0.888916\tvalid_1's auc: 0.789327\n",
      "[3476]\ttraining's auc: 0.888941\tvalid_1's auc: 0.789325\n",
      "[3477]\ttraining's auc: 0.888965\tvalid_1's auc: 0.789321\n",
      "[3478]\ttraining's auc: 0.888983\tvalid_1's auc: 0.789317\n",
      "[3479]\ttraining's auc: 0.889006\tvalid_1's auc: 0.789313\n",
      "[3480]\ttraining's auc: 0.889025\tvalid_1's auc: 0.78931\n",
      "[3481]\ttraining's auc: 0.889044\tvalid_1's auc: 0.789308\n",
      "[3482]\ttraining's auc: 0.889063\tvalid_1's auc: 0.789314\n",
      "[3483]\ttraining's auc: 0.88909\tvalid_1's auc: 0.789315\n",
      "[3484]\ttraining's auc: 0.889096\tvalid_1's auc: 0.789314\n",
      "[3485]\ttraining's auc: 0.889114\tvalid_1's auc: 0.789315\n",
      "[3486]\ttraining's auc: 0.889138\tvalid_1's auc: 0.789313\n",
      "[3487]\ttraining's auc: 0.889156\tvalid_1's auc: 0.789328\n",
      "[3488]\ttraining's auc: 0.889177\tvalid_1's auc: 0.789324\n",
      "[3489]\ttraining's auc: 0.889198\tvalid_1's auc: 0.789319\n",
      "[3490]\ttraining's auc: 0.889208\tvalid_1's auc: 0.789315\n",
      "[3491]\ttraining's auc: 0.889223\tvalid_1's auc: 0.789317\n",
      "[3492]\ttraining's auc: 0.889235\tvalid_1's auc: 0.789315\n",
      "[3493]\ttraining's auc: 0.889255\tvalid_1's auc: 0.789322\n",
      "[3494]\ttraining's auc: 0.889268\tvalid_1's auc: 0.78932\n",
      "[3495]\ttraining's auc: 0.889295\tvalid_1's auc: 0.789321\n",
      "[3496]\ttraining's auc: 0.889321\tvalid_1's auc: 0.789316\n",
      "[3497]\ttraining's auc: 0.889343\tvalid_1's auc: 0.789324\n",
      "[3498]\ttraining's auc: 0.889375\tvalid_1's auc: 0.789331\n",
      "[3499]\ttraining's auc: 0.889396\tvalid_1's auc: 0.789334\n",
      "[3500]\ttraining's auc: 0.889415\tvalid_1's auc: 0.789336\n",
      "[3501]\ttraining's auc: 0.889438\tvalid_1's auc: 0.789335\n",
      "[3502]\ttraining's auc: 0.889464\tvalid_1's auc: 0.789336\n",
      "[3503]\ttraining's auc: 0.889487\tvalid_1's auc: 0.789338\n",
      "[3504]\ttraining's auc: 0.889513\tvalid_1's auc: 0.789337\n",
      "[3505]\ttraining's auc: 0.889533\tvalid_1's auc: 0.789338\n",
      "[3506]\ttraining's auc: 0.889554\tvalid_1's auc: 0.789335\n",
      "[3507]\ttraining's auc: 0.889574\tvalid_1's auc: 0.789336\n",
      "[3508]\ttraining's auc: 0.889593\tvalid_1's auc: 0.789341\n",
      "[3509]\ttraining's auc: 0.889617\tvalid_1's auc: 0.789338\n",
      "[3510]\ttraining's auc: 0.889638\tvalid_1's auc: 0.789339\n",
      "[3511]\ttraining's auc: 0.889656\tvalid_1's auc: 0.789344\n",
      "[3512]\ttraining's auc: 0.88968\tvalid_1's auc: 0.789347\n",
      "[3513]\ttraining's auc: 0.889699\tvalid_1's auc: 0.789343\n",
      "[3514]\ttraining's auc: 0.889718\tvalid_1's auc: 0.789339\n",
      "[3515]\ttraining's auc: 0.889745\tvalid_1's auc: 0.78934\n",
      "[3516]\ttraining's auc: 0.889763\tvalid_1's auc: 0.789337\n",
      "[3517]\ttraining's auc: 0.889786\tvalid_1's auc: 0.789343\n",
      "[3518]\ttraining's auc: 0.8898\tvalid_1's auc: 0.789345\n",
      "[3519]\ttraining's auc: 0.889818\tvalid_1's auc: 0.789342\n",
      "[3520]\ttraining's auc: 0.889837\tvalid_1's auc: 0.789343\n",
      "[3521]\ttraining's auc: 0.889861\tvalid_1's auc: 0.789342\n",
      "[3522]\ttraining's auc: 0.88987\tvalid_1's auc: 0.789339\n",
      "[3523]\ttraining's auc: 0.88989\tvalid_1's auc: 0.789339\n",
      "[3524]\ttraining's auc: 0.889911\tvalid_1's auc: 0.78934\n",
      "[3525]\ttraining's auc: 0.88993\tvalid_1's auc: 0.789342\n",
      "[3526]\ttraining's auc: 0.889937\tvalid_1's auc: 0.789343\n",
      "[3527]\ttraining's auc: 0.889962\tvalid_1's auc: 0.789341\n",
      "[3528]\ttraining's auc: 0.889984\tvalid_1's auc: 0.789346\n",
      "[3529]\ttraining's auc: 0.890006\tvalid_1's auc: 0.789353\n",
      "[3530]\ttraining's auc: 0.890019\tvalid_1's auc: 0.789349\n",
      "[3531]\ttraining's auc: 0.890039\tvalid_1's auc: 0.78935\n",
      "[3532]\ttraining's auc: 0.890057\tvalid_1's auc: 0.789355\n",
      "[3533]\ttraining's auc: 0.890079\tvalid_1's auc: 0.789357\n",
      "[3534]\ttraining's auc: 0.890089\tvalid_1's auc: 0.789352\n",
      "[3535]\ttraining's auc: 0.890099\tvalid_1's auc: 0.789356\n",
      "[3536]\ttraining's auc: 0.890125\tvalid_1's auc: 0.789352\n",
      "[3537]\ttraining's auc: 0.890143\tvalid_1's auc: 0.78935\n",
      "[3538]\ttraining's auc: 0.890159\tvalid_1's auc: 0.789347\n",
      "[3539]\ttraining's auc: 0.890181\tvalid_1's auc: 0.78935\n",
      "[3540]\ttraining's auc: 0.890196\tvalid_1's auc: 0.789347\n",
      "[3541]\ttraining's auc: 0.890219\tvalid_1's auc: 0.789345\n",
      "[3542]\ttraining's auc: 0.89024\tvalid_1's auc: 0.789343\n",
      "[3543]\ttraining's auc: 0.890257\tvalid_1's auc: 0.789345\n",
      "[3544]\ttraining's auc: 0.890284\tvalid_1's auc: 0.789348\n",
      "[3545]\ttraining's auc: 0.890309\tvalid_1's auc: 0.789346\n",
      "[3546]\ttraining's auc: 0.890331\tvalid_1's auc: 0.789336\n",
      "[3547]\ttraining's auc: 0.890348\tvalid_1's auc: 0.789336\n",
      "[3548]\ttraining's auc: 0.890365\tvalid_1's auc: 0.789334\n",
      "[3549]\ttraining's auc: 0.890385\tvalid_1's auc: 0.789338\n",
      "[3550]\ttraining's auc: 0.890401\tvalid_1's auc: 0.789334\n",
      "[3551]\ttraining's auc: 0.890426\tvalid_1's auc: 0.789335\n",
      "[3552]\ttraining's auc: 0.890444\tvalid_1's auc: 0.789339\n",
      "[3553]\ttraining's auc: 0.890469\tvalid_1's auc: 0.789353\n",
      "[3554]\ttraining's auc: 0.89049\tvalid_1's auc: 0.789356\n",
      "[3555]\ttraining's auc: 0.89051\tvalid_1's auc: 0.789348\n",
      "[3556]\ttraining's auc: 0.890522\tvalid_1's auc: 0.789347\n",
      "[3557]\ttraining's auc: 0.890546\tvalid_1's auc: 0.789342\n",
      "[3558]\ttraining's auc: 0.890567\tvalid_1's auc: 0.789337\n",
      "[3559]\ttraining's auc: 0.89057\tvalid_1's auc: 0.789339\n",
      "[3560]\ttraining's auc: 0.890575\tvalid_1's auc: 0.789342\n",
      "[3561]\ttraining's auc: 0.890604\tvalid_1's auc: 0.789338\n",
      "[3562]\ttraining's auc: 0.890625\tvalid_1's auc: 0.789336\n",
      "[3563]\ttraining's auc: 0.89064\tvalid_1's auc: 0.789332\n",
      "[3564]\ttraining's auc: 0.890663\tvalid_1's auc: 0.789327\n",
      "[3565]\ttraining's auc: 0.890678\tvalid_1's auc: 0.789327\n",
      "[3566]\ttraining's auc: 0.8907\tvalid_1's auc: 0.789323\n",
      "[3567]\ttraining's auc: 0.890717\tvalid_1's auc: 0.789333\n",
      "[3568]\ttraining's auc: 0.890735\tvalid_1's auc: 0.789332\n",
      "[3569]\ttraining's auc: 0.890757\tvalid_1's auc: 0.789337\n",
      "[3570]\ttraining's auc: 0.890771\tvalid_1's auc: 0.789335\n",
      "[3571]\ttraining's auc: 0.890779\tvalid_1's auc: 0.789331\n",
      "[3572]\ttraining's auc: 0.890801\tvalid_1's auc: 0.789333\n",
      "[3573]\ttraining's auc: 0.890825\tvalid_1's auc: 0.789335\n",
      "[3574]\ttraining's auc: 0.89085\tvalid_1's auc: 0.789339\n",
      "[3575]\ttraining's auc: 0.890857\tvalid_1's auc: 0.78934\n",
      "[3576]\ttraining's auc: 0.890878\tvalid_1's auc: 0.789335\n",
      "[3577]\ttraining's auc: 0.890894\tvalid_1's auc: 0.789335\n",
      "[3578]\ttraining's auc: 0.890908\tvalid_1's auc: 0.789335\n",
      "[3579]\ttraining's auc: 0.89093\tvalid_1's auc: 0.789344\n",
      "[3580]\ttraining's auc: 0.890937\tvalid_1's auc: 0.789343\n",
      "[3581]\ttraining's auc: 0.890954\tvalid_1's auc: 0.78935\n",
      "[3582]\ttraining's auc: 0.890976\tvalid_1's auc: 0.789346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3583]\ttraining's auc: 0.890993\tvalid_1's auc: 0.789346\n",
      "[3584]\ttraining's auc: 0.89102\tvalid_1's auc: 0.789346\n",
      "[3585]\ttraining's auc: 0.891038\tvalid_1's auc: 0.78935\n",
      "[3586]\ttraining's auc: 0.891053\tvalid_1's auc: 0.789358\n",
      "[3587]\ttraining's auc: 0.891064\tvalid_1's auc: 0.789357\n",
      "[3588]\ttraining's auc: 0.89109\tvalid_1's auc: 0.789357\n",
      "[3589]\ttraining's auc: 0.89112\tvalid_1's auc: 0.789362\n",
      "[3590]\ttraining's auc: 0.891143\tvalid_1's auc: 0.789365\n",
      "[3591]\ttraining's auc: 0.891156\tvalid_1's auc: 0.789366\n",
      "[3592]\ttraining's auc: 0.891182\tvalid_1's auc: 0.789372\n",
      "[3593]\ttraining's auc: 0.8912\tvalid_1's auc: 0.789369\n",
      "[3594]\ttraining's auc: 0.891222\tvalid_1's auc: 0.789369\n",
      "[3595]\ttraining's auc: 0.891239\tvalid_1's auc: 0.789372\n",
      "[3596]\ttraining's auc: 0.891256\tvalid_1's auc: 0.789373\n",
      "[3597]\ttraining's auc: 0.891274\tvalid_1's auc: 0.789374\n",
      "[3598]\ttraining's auc: 0.891283\tvalid_1's auc: 0.789373\n",
      "[3599]\ttraining's auc: 0.8913\tvalid_1's auc: 0.789377\n",
      "[3600]\ttraining's auc: 0.891317\tvalid_1's auc: 0.789379\n",
      "[3601]\ttraining's auc: 0.891335\tvalid_1's auc: 0.78938\n",
      "[3602]\ttraining's auc: 0.891339\tvalid_1's auc: 0.789382\n",
      "[3603]\ttraining's auc: 0.891355\tvalid_1's auc: 0.789378\n",
      "[3604]\ttraining's auc: 0.891373\tvalid_1's auc: 0.789383\n",
      "[3605]\ttraining's auc: 0.891388\tvalid_1's auc: 0.789388\n",
      "[3606]\ttraining's auc: 0.891405\tvalid_1's auc: 0.789379\n",
      "[3607]\ttraining's auc: 0.891419\tvalid_1's auc: 0.789382\n",
      "[3608]\ttraining's auc: 0.89144\tvalid_1's auc: 0.789383\n",
      "[3609]\ttraining's auc: 0.891451\tvalid_1's auc: 0.789381\n",
      "[3610]\ttraining's auc: 0.891467\tvalid_1's auc: 0.78938\n",
      "[3611]\ttraining's auc: 0.891479\tvalid_1's auc: 0.789384\n",
      "[3612]\ttraining's auc: 0.891494\tvalid_1's auc: 0.789387\n",
      "[3613]\ttraining's auc: 0.89152\tvalid_1's auc: 0.789388\n",
      "[3614]\ttraining's auc: 0.891533\tvalid_1's auc: 0.789399\n",
      "[3615]\ttraining's auc: 0.891557\tvalid_1's auc: 0.789397\n",
      "[3616]\ttraining's auc: 0.891571\tvalid_1's auc: 0.789397\n",
      "[3617]\ttraining's auc: 0.891597\tvalid_1's auc: 0.789394\n",
      "[3618]\ttraining's auc: 0.891618\tvalid_1's auc: 0.789393\n",
      "[3619]\ttraining's auc: 0.891635\tvalid_1's auc: 0.789398\n",
      "[3620]\ttraining's auc: 0.891651\tvalid_1's auc: 0.789399\n",
      "[3621]\ttraining's auc: 0.891667\tvalid_1's auc: 0.789399\n",
      "[3622]\ttraining's auc: 0.891685\tvalid_1's auc: 0.7894\n",
      "[3623]\ttraining's auc: 0.891706\tvalid_1's auc: 0.789394\n",
      "[3624]\ttraining's auc: 0.891726\tvalid_1's auc: 0.789398\n",
      "[3625]\ttraining's auc: 0.891745\tvalid_1's auc: 0.7894\n",
      "[3626]\ttraining's auc: 0.891766\tvalid_1's auc: 0.789405\n",
      "[3627]\ttraining's auc: 0.891776\tvalid_1's auc: 0.789408\n",
      "[3628]\ttraining's auc: 0.891794\tvalid_1's auc: 0.789405\n",
      "[3629]\ttraining's auc: 0.891819\tvalid_1's auc: 0.789407\n",
      "[3630]\ttraining's auc: 0.891841\tvalid_1's auc: 0.789408\n",
      "[3631]\ttraining's auc: 0.891855\tvalid_1's auc: 0.78941\n",
      "[3632]\ttraining's auc: 0.891881\tvalid_1's auc: 0.789408\n",
      "[3633]\ttraining's auc: 0.8919\tvalid_1's auc: 0.789415\n",
      "[3634]\ttraining's auc: 0.891921\tvalid_1's auc: 0.789416\n",
      "[3635]\ttraining's auc: 0.89194\tvalid_1's auc: 0.789416\n",
      "[3636]\ttraining's auc: 0.891958\tvalid_1's auc: 0.789418\n",
      "[3637]\ttraining's auc: 0.891973\tvalid_1's auc: 0.789414\n",
      "[3638]\ttraining's auc: 0.891989\tvalid_1's auc: 0.789411\n",
      "[3639]\ttraining's auc: 0.892017\tvalid_1's auc: 0.789412\n",
      "[3640]\ttraining's auc: 0.892035\tvalid_1's auc: 0.789412\n",
      "[3641]\ttraining's auc: 0.892053\tvalid_1's auc: 0.789401\n",
      "[3642]\ttraining's auc: 0.892072\tvalid_1's auc: 0.789404\n",
      "[3643]\ttraining's auc: 0.892089\tvalid_1's auc: 0.789405\n",
      "[3644]\ttraining's auc: 0.892105\tvalid_1's auc: 0.789394\n",
      "[3645]\ttraining's auc: 0.892111\tvalid_1's auc: 0.789396\n",
      "[3646]\ttraining's auc: 0.892119\tvalid_1's auc: 0.789395\n",
      "[3647]\ttraining's auc: 0.892127\tvalid_1's auc: 0.789394\n",
      "[3648]\ttraining's auc: 0.892148\tvalid_1's auc: 0.789391\n",
      "[3649]\ttraining's auc: 0.892173\tvalid_1's auc: 0.789399\n",
      "[3650]\ttraining's auc: 0.892198\tvalid_1's auc: 0.789399\n",
      "[3651]\ttraining's auc: 0.892215\tvalid_1's auc: 0.789396\n",
      "[3652]\ttraining's auc: 0.892236\tvalid_1's auc: 0.789399\n",
      "[3653]\ttraining's auc: 0.892257\tvalid_1's auc: 0.7894\n",
      "[3654]\ttraining's auc: 0.892275\tvalid_1's auc: 0.789403\n",
      "[3655]\ttraining's auc: 0.892294\tvalid_1's auc: 0.789407\n",
      "[3656]\ttraining's auc: 0.892312\tvalid_1's auc: 0.789409\n",
      "[3657]\ttraining's auc: 0.892332\tvalid_1's auc: 0.789406\n",
      "[3658]\ttraining's auc: 0.892348\tvalid_1's auc: 0.789408\n",
      "[3659]\ttraining's auc: 0.892368\tvalid_1's auc: 0.789418\n",
      "[3660]\ttraining's auc: 0.892396\tvalid_1's auc: 0.789412\n",
      "[3661]\ttraining's auc: 0.89241\tvalid_1's auc: 0.78941\n",
      "[3662]\ttraining's auc: 0.892427\tvalid_1's auc: 0.789405\n",
      "[3663]\ttraining's auc: 0.892453\tvalid_1's auc: 0.789397\n",
      "[3664]\ttraining's auc: 0.892475\tvalid_1's auc: 0.789402\n",
      "[3665]\ttraining's auc: 0.892494\tvalid_1's auc: 0.789404\n",
      "[3666]\ttraining's auc: 0.892503\tvalid_1's auc: 0.789398\n",
      "[3667]\ttraining's auc: 0.892518\tvalid_1's auc: 0.789399\n",
      "[3668]\ttraining's auc: 0.892536\tvalid_1's auc: 0.789398\n",
      "[3669]\ttraining's auc: 0.892558\tvalid_1's auc: 0.789399\n",
      "[3670]\ttraining's auc: 0.892573\tvalid_1's auc: 0.789399\n",
      "[3671]\ttraining's auc: 0.892587\tvalid_1's auc: 0.789392\n",
      "[3672]\ttraining's auc: 0.892614\tvalid_1's auc: 0.789391\n",
      "[3673]\ttraining's auc: 0.892632\tvalid_1's auc: 0.789394\n",
      "[3674]\ttraining's auc: 0.892654\tvalid_1's auc: 0.789394\n",
      "[3675]\ttraining's auc: 0.892672\tvalid_1's auc: 0.789394\n",
      "[3676]\ttraining's auc: 0.892695\tvalid_1's auc: 0.789391\n",
      "[3677]\ttraining's auc: 0.892707\tvalid_1's auc: 0.789393\n",
      "[3678]\ttraining's auc: 0.892732\tvalid_1's auc: 0.789393\n",
      "[3679]\ttraining's auc: 0.892747\tvalid_1's auc: 0.789391\n",
      "[3680]\ttraining's auc: 0.892775\tvalid_1's auc: 0.789385\n",
      "[3681]\ttraining's auc: 0.892797\tvalid_1's auc: 0.789381\n",
      "[3682]\ttraining's auc: 0.892813\tvalid_1's auc: 0.789379\n",
      "[3683]\ttraining's auc: 0.892825\tvalid_1's auc: 0.789379\n",
      "[3684]\ttraining's auc: 0.892844\tvalid_1's auc: 0.789386\n",
      "[3685]\ttraining's auc: 0.892853\tvalid_1's auc: 0.789388\n",
      "[3686]\ttraining's auc: 0.892875\tvalid_1's auc: 0.789385\n",
      "[3687]\ttraining's auc: 0.892887\tvalid_1's auc: 0.789391\n",
      "[3688]\ttraining's auc: 0.892903\tvalid_1's auc: 0.789397\n",
      "[3689]\ttraining's auc: 0.892928\tvalid_1's auc: 0.789405\n",
      "[3690]\ttraining's auc: 0.892932\tvalid_1's auc: 0.789406\n",
      "[3691]\ttraining's auc: 0.892946\tvalid_1's auc: 0.789412\n",
      "[3692]\ttraining's auc: 0.892966\tvalid_1's auc: 0.789419\n",
      "[3693]\ttraining's auc: 0.89298\tvalid_1's auc: 0.78942\n",
      "[3694]\ttraining's auc: 0.892999\tvalid_1's auc: 0.789425\n",
      "[3695]\ttraining's auc: 0.893015\tvalid_1's auc: 0.78943\n",
      "[3696]\ttraining's auc: 0.893021\tvalid_1's auc: 0.789432\n",
      "[3697]\ttraining's auc: 0.893046\tvalid_1's auc: 0.789433\n",
      "[3698]\ttraining's auc: 0.893064\tvalid_1's auc: 0.78943\n",
      "[3699]\ttraining's auc: 0.893082\tvalid_1's auc: 0.789422\n",
      "[3700]\ttraining's auc: 0.8931\tvalid_1's auc: 0.78942\n",
      "[3701]\ttraining's auc: 0.893111\tvalid_1's auc: 0.789421\n",
      "[3702]\ttraining's auc: 0.893135\tvalid_1's auc: 0.789417\n",
      "[3703]\ttraining's auc: 0.893155\tvalid_1's auc: 0.789413\n",
      "[3704]\ttraining's auc: 0.89317\tvalid_1's auc: 0.789409\n",
      "[3705]\ttraining's auc: 0.89319\tvalid_1's auc: 0.789402\n",
      "[3706]\ttraining's auc: 0.893206\tvalid_1's auc: 0.789404\n",
      "[3707]\ttraining's auc: 0.893222\tvalid_1's auc: 0.789402\n",
      "[3708]\ttraining's auc: 0.893248\tvalid_1's auc: 0.789404\n",
      "[3709]\ttraining's auc: 0.893265\tvalid_1's auc: 0.789405\n",
      "[3710]\ttraining's auc: 0.893282\tvalid_1's auc: 0.789407\n",
      "[3711]\ttraining's auc: 0.893306\tvalid_1's auc: 0.789408\n",
      "[3712]\ttraining's auc: 0.893319\tvalid_1's auc: 0.789406\n",
      "[3713]\ttraining's auc: 0.893331\tvalid_1's auc: 0.789401\n",
      "[3714]\ttraining's auc: 0.893348\tvalid_1's auc: 0.7894\n",
      "[3715]\ttraining's auc: 0.893368\tvalid_1's auc: 0.789398\n",
      "[3716]\ttraining's auc: 0.893391\tvalid_1's auc: 0.7894\n",
      "[3717]\ttraining's auc: 0.89341\tvalid_1's auc: 0.789397\n",
      "[3718]\ttraining's auc: 0.893417\tvalid_1's auc: 0.789397\n",
      "[3719]\ttraining's auc: 0.893436\tvalid_1's auc: 0.789396\n",
      "[3720]\ttraining's auc: 0.893451\tvalid_1's auc: 0.789392\n",
      "[3721]\ttraining's auc: 0.893472\tvalid_1's auc: 0.789389\n",
      "[3722]\ttraining's auc: 0.893499\tvalid_1's auc: 0.789388\n",
      "[3723]\ttraining's auc: 0.893516\tvalid_1's auc: 0.78938\n",
      "[3724]\ttraining's auc: 0.893538\tvalid_1's auc: 0.789382\n",
      "[3725]\ttraining's auc: 0.89356\tvalid_1's auc: 0.789386\n",
      "[3726]\ttraining's auc: 0.89358\tvalid_1's auc: 0.789385\n",
      "[3727]\ttraining's auc: 0.8936\tvalid_1's auc: 0.789383\n",
      "[3728]\ttraining's auc: 0.893625\tvalid_1's auc: 0.789375\n",
      "[3729]\ttraining's auc: 0.893639\tvalid_1's auc: 0.789376\n",
      "[3730]\ttraining's auc: 0.893662\tvalid_1's auc: 0.789373\n",
      "[3731]\ttraining's auc: 0.893682\tvalid_1's auc: 0.78937\n",
      "[3732]\ttraining's auc: 0.893705\tvalid_1's auc: 0.789372\n",
      "[3733]\ttraining's auc: 0.89373\tvalid_1's auc: 0.789373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3734]\ttraining's auc: 0.893749\tvalid_1's auc: 0.789376\n",
      "[3735]\ttraining's auc: 0.893768\tvalid_1's auc: 0.789379\n",
      "[3736]\ttraining's auc: 0.893792\tvalid_1's auc: 0.789382\n",
      "[3737]\ttraining's auc: 0.893809\tvalid_1's auc: 0.789382\n",
      "[3738]\ttraining's auc: 0.893826\tvalid_1's auc: 0.789387\n",
      "[3739]\ttraining's auc: 0.893846\tvalid_1's auc: 0.789382\n",
      "[3740]\ttraining's auc: 0.893862\tvalid_1's auc: 0.789382\n",
      "[3741]\ttraining's auc: 0.893882\tvalid_1's auc: 0.789378\n",
      "[3742]\ttraining's auc: 0.893899\tvalid_1's auc: 0.789381\n",
      "[3743]\ttraining's auc: 0.893919\tvalid_1's auc: 0.789384\n",
      "[3744]\ttraining's auc: 0.893943\tvalid_1's auc: 0.789388\n",
      "[3745]\ttraining's auc: 0.893963\tvalid_1's auc: 0.789388\n",
      "[3746]\ttraining's auc: 0.893985\tvalid_1's auc: 0.789392\n",
      "[3747]\ttraining's auc: 0.894006\tvalid_1's auc: 0.789387\n",
      "[3748]\ttraining's auc: 0.894015\tvalid_1's auc: 0.789385\n",
      "[3749]\ttraining's auc: 0.894034\tvalid_1's auc: 0.789386\n",
      "[3750]\ttraining's auc: 0.894055\tvalid_1's auc: 0.789384\n",
      "[3751]\ttraining's auc: 0.894074\tvalid_1's auc: 0.789385\n",
      "[3752]\ttraining's auc: 0.894092\tvalid_1's auc: 0.789385\n",
      "[3753]\ttraining's auc: 0.894114\tvalid_1's auc: 0.789379\n",
      "[3754]\ttraining's auc: 0.894125\tvalid_1's auc: 0.789381\n",
      "[3755]\ttraining's auc: 0.894134\tvalid_1's auc: 0.789384\n",
      "[3756]\ttraining's auc: 0.894152\tvalid_1's auc: 0.789384\n",
      "[3757]\ttraining's auc: 0.89417\tvalid_1's auc: 0.789382\n",
      "[3758]\ttraining's auc: 0.894192\tvalid_1's auc: 0.789378\n",
      "[3759]\ttraining's auc: 0.894196\tvalid_1's auc: 0.789376\n",
      "[3760]\ttraining's auc: 0.894222\tvalid_1's auc: 0.789372\n",
      "[3761]\ttraining's auc: 0.894244\tvalid_1's auc: 0.789375\n",
      "[3762]\ttraining's auc: 0.894262\tvalid_1's auc: 0.789369\n",
      "[3763]\ttraining's auc: 0.894279\tvalid_1's auc: 0.789369\n",
      "[3764]\ttraining's auc: 0.894303\tvalid_1's auc: 0.789369\n",
      "[3765]\ttraining's auc: 0.894325\tvalid_1's auc: 0.789381\n",
      "[3766]\ttraining's auc: 0.894347\tvalid_1's auc: 0.789371\n",
      "[3767]\ttraining's auc: 0.894364\tvalid_1's auc: 0.789376\n",
      "[3768]\ttraining's auc: 0.894375\tvalid_1's auc: 0.789378\n",
      "[3769]\ttraining's auc: 0.894397\tvalid_1's auc: 0.789379\n",
      "[3770]\ttraining's auc: 0.894416\tvalid_1's auc: 0.789378\n",
      "[3771]\ttraining's auc: 0.894432\tvalid_1's auc: 0.789377\n",
      "[3772]\ttraining's auc: 0.89445\tvalid_1's auc: 0.78938\n",
      "[3773]\ttraining's auc: 0.894454\tvalid_1's auc: 0.789379\n",
      "[3774]\ttraining's auc: 0.894468\tvalid_1's auc: 0.789377\n",
      "[3775]\ttraining's auc: 0.894495\tvalid_1's auc: 0.789378\n",
      "[3776]\ttraining's auc: 0.894504\tvalid_1's auc: 0.789378\n",
      "[3777]\ttraining's auc: 0.894524\tvalid_1's auc: 0.789378\n",
      "[3778]\ttraining's auc: 0.894539\tvalid_1's auc: 0.789381\n",
      "[3779]\ttraining's auc: 0.894554\tvalid_1's auc: 0.789382\n",
      "[3780]\ttraining's auc: 0.894573\tvalid_1's auc: 0.789386\n",
      "[3781]\ttraining's auc: 0.894595\tvalid_1's auc: 0.789389\n",
      "[3782]\ttraining's auc: 0.894626\tvalid_1's auc: 0.789389\n",
      "[3783]\ttraining's auc: 0.894647\tvalid_1's auc: 0.78939\n",
      "[3784]\ttraining's auc: 0.894665\tvalid_1's auc: 0.78939\n",
      "[3785]\ttraining's auc: 0.894688\tvalid_1's auc: 0.789391\n",
      "[3786]\ttraining's auc: 0.894704\tvalid_1's auc: 0.789394\n",
      "[3787]\ttraining's auc: 0.894724\tvalid_1's auc: 0.789395\n",
      "[3788]\ttraining's auc: 0.894739\tvalid_1's auc: 0.789398\n",
      "[3789]\ttraining's auc: 0.894757\tvalid_1's auc: 0.789403\n",
      "[3790]\ttraining's auc: 0.894776\tvalid_1's auc: 0.789401\n",
      "[3791]\ttraining's auc: 0.894779\tvalid_1's auc: 0.789401\n",
      "[3792]\ttraining's auc: 0.894792\tvalid_1's auc: 0.789397\n",
      "[3793]\ttraining's auc: 0.89481\tvalid_1's auc: 0.789394\n",
      "[3794]\ttraining's auc: 0.894828\tvalid_1's auc: 0.789399\n",
      "[3795]\ttraining's auc: 0.894844\tvalid_1's auc: 0.789403\n",
      "[3796]\ttraining's auc: 0.894863\tvalid_1's auc: 0.789402\n",
      "[3797]\ttraining's auc: 0.894885\tvalid_1's auc: 0.789403\n",
      "[3798]\ttraining's auc: 0.894906\tvalid_1's auc: 0.789402\n",
      "[3799]\ttraining's auc: 0.894931\tvalid_1's auc: 0.789413\n",
      "[3800]\ttraining's auc: 0.894945\tvalid_1's auc: 0.789414\n",
      "[3801]\ttraining's auc: 0.894961\tvalid_1's auc: 0.789413\n",
      "[3802]\ttraining's auc: 0.894968\tvalid_1's auc: 0.789414\n",
      "[3803]\ttraining's auc: 0.894986\tvalid_1's auc: 0.789413\n",
      "[3804]\ttraining's auc: 0.895003\tvalid_1's auc: 0.78941\n",
      "[3805]\ttraining's auc: 0.89502\tvalid_1's auc: 0.789413\n",
      "[3806]\ttraining's auc: 0.895031\tvalid_1's auc: 0.78941\n",
      "[3807]\ttraining's auc: 0.895039\tvalid_1's auc: 0.78941\n",
      "[3808]\ttraining's auc: 0.895059\tvalid_1's auc: 0.789407\n",
      "[3809]\ttraining's auc: 0.895081\tvalid_1's auc: 0.789408\n",
      "[3810]\ttraining's auc: 0.895103\tvalid_1's auc: 0.789405\n",
      "[3811]\ttraining's auc: 0.895125\tvalid_1's auc: 0.789398\n",
      "[3812]\ttraining's auc: 0.895146\tvalid_1's auc: 0.789395\n",
      "[3813]\ttraining's auc: 0.895164\tvalid_1's auc: 0.789395\n",
      "[3814]\ttraining's auc: 0.895189\tvalid_1's auc: 0.789396\n",
      "[3815]\ttraining's auc: 0.89521\tvalid_1's auc: 0.78939\n",
      "[3816]\ttraining's auc: 0.895227\tvalid_1's auc: 0.789395\n",
      "[3817]\ttraining's auc: 0.895246\tvalid_1's auc: 0.789402\n",
      "[3818]\ttraining's auc: 0.895263\tvalid_1's auc: 0.789402\n",
      "[3819]\ttraining's auc: 0.895283\tvalid_1's auc: 0.789403\n",
      "[3820]\ttraining's auc: 0.895303\tvalid_1's auc: 0.789398\n",
      "[3821]\ttraining's auc: 0.895318\tvalid_1's auc: 0.7894\n",
      "[3822]\ttraining's auc: 0.895342\tvalid_1's auc: 0.789397\n",
      "[3823]\ttraining's auc: 0.895369\tvalid_1's auc: 0.789406\n",
      "[3824]\ttraining's auc: 0.895393\tvalid_1's auc: 0.789407\n",
      "[3825]\ttraining's auc: 0.895414\tvalid_1's auc: 0.789407\n",
      "[3826]\ttraining's auc: 0.895425\tvalid_1's auc: 0.789411\n",
      "[3827]\ttraining's auc: 0.89544\tvalid_1's auc: 0.789415\n",
      "[3828]\ttraining's auc: 0.895458\tvalid_1's auc: 0.789414\n",
      "[3829]\ttraining's auc: 0.895477\tvalid_1's auc: 0.789414\n",
      "[3830]\ttraining's auc: 0.895501\tvalid_1's auc: 0.789412\n",
      "[3831]\ttraining's auc: 0.895515\tvalid_1's auc: 0.789416\n",
      "[3832]\ttraining's auc: 0.895538\tvalid_1's auc: 0.789419\n",
      "[3833]\ttraining's auc: 0.895558\tvalid_1's auc: 0.789422\n",
      "[3834]\ttraining's auc: 0.895578\tvalid_1's auc: 0.789417\n",
      "[3835]\ttraining's auc: 0.895598\tvalid_1's auc: 0.789417\n",
      "[3836]\ttraining's auc: 0.89562\tvalid_1's auc: 0.789411\n",
      "[3837]\ttraining's auc: 0.895636\tvalid_1's auc: 0.789414\n",
      "[3838]\ttraining's auc: 0.895652\tvalid_1's auc: 0.789411\n",
      "[3839]\ttraining's auc: 0.895677\tvalid_1's auc: 0.789414\n",
      "[3840]\ttraining's auc: 0.895694\tvalid_1's auc: 0.789413\n",
      "[3841]\ttraining's auc: 0.895713\tvalid_1's auc: 0.789409\n",
      "[3842]\ttraining's auc: 0.895732\tvalid_1's auc: 0.789408\n",
      "[3843]\ttraining's auc: 0.895747\tvalid_1's auc: 0.789407\n",
      "[3844]\ttraining's auc: 0.895767\tvalid_1's auc: 0.789407\n",
      "[3845]\ttraining's auc: 0.895786\tvalid_1's auc: 0.789406\n",
      "[3846]\ttraining's auc: 0.895804\tvalid_1's auc: 0.78941\n",
      "[3847]\ttraining's auc: 0.895823\tvalid_1's auc: 0.789411\n",
      "[3848]\ttraining's auc: 0.89584\tvalid_1's auc: 0.789408\n",
      "[3849]\ttraining's auc: 0.895856\tvalid_1's auc: 0.789407\n",
      "[3850]\ttraining's auc: 0.895868\tvalid_1's auc: 0.789407\n",
      "[3851]\ttraining's auc: 0.895886\tvalid_1's auc: 0.789413\n",
      "[3852]\ttraining's auc: 0.895906\tvalid_1's auc: 0.789415\n",
      "[3853]\ttraining's auc: 0.895922\tvalid_1's auc: 0.789422\n",
      "[3854]\ttraining's auc: 0.895936\tvalid_1's auc: 0.789424\n",
      "[3855]\ttraining's auc: 0.895954\tvalid_1's auc: 0.789435\n",
      "[3856]\ttraining's auc: 0.89596\tvalid_1's auc: 0.789437\n",
      "[3857]\ttraining's auc: 0.895977\tvalid_1's auc: 0.78944\n",
      "[3858]\ttraining's auc: 0.895991\tvalid_1's auc: 0.789437\n",
      "[3859]\ttraining's auc: 0.896011\tvalid_1's auc: 0.789435\n",
      "[3860]\ttraining's auc: 0.896026\tvalid_1's auc: 0.789431\n",
      "[3861]\ttraining's auc: 0.896043\tvalid_1's auc: 0.789432\n",
      "[3862]\ttraining's auc: 0.896065\tvalid_1's auc: 0.789437\n",
      "[3863]\ttraining's auc: 0.89609\tvalid_1's auc: 0.789439\n",
      "[3864]\ttraining's auc: 0.896099\tvalid_1's auc: 0.789439\n",
      "[3865]\ttraining's auc: 0.896119\tvalid_1's auc: 0.789434\n",
      "[3866]\ttraining's auc: 0.89614\tvalid_1's auc: 0.789432\n",
      "[3867]\ttraining's auc: 0.896158\tvalid_1's auc: 0.78943\n",
      "[3868]\ttraining's auc: 0.896176\tvalid_1's auc: 0.789426\n",
      "[3869]\ttraining's auc: 0.896195\tvalid_1's auc: 0.78943\n",
      "[3870]\ttraining's auc: 0.896215\tvalid_1's auc: 0.789434\n",
      "[3871]\ttraining's auc: 0.896237\tvalid_1's auc: 0.78944\n",
      "[3872]\ttraining's auc: 0.896263\tvalid_1's auc: 0.789435\n",
      "[3873]\ttraining's auc: 0.896283\tvalid_1's auc: 0.78943\n",
      "[3874]\ttraining's auc: 0.896299\tvalid_1's auc: 0.789433\n",
      "[3875]\ttraining's auc: 0.896318\tvalid_1's auc: 0.789426\n",
      "[3876]\ttraining's auc: 0.896336\tvalid_1's auc: 0.789434\n",
      "[3877]\ttraining's auc: 0.896356\tvalid_1's auc: 0.789439\n",
      "[3878]\ttraining's auc: 0.896372\tvalid_1's auc: 0.789438\n",
      "[3879]\ttraining's auc: 0.896389\tvalid_1's auc: 0.789435\n",
      "[3880]\ttraining's auc: 0.896412\tvalid_1's auc: 0.78943\n",
      "[3881]\ttraining's auc: 0.896438\tvalid_1's auc: 0.789433\n",
      "[3882]\ttraining's auc: 0.896445\tvalid_1's auc: 0.789429\n",
      "[3883]\ttraining's auc: 0.896455\tvalid_1's auc: 0.789432\n",
      "[3884]\ttraining's auc: 0.896479\tvalid_1's auc: 0.789432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3885]\ttraining's auc: 0.896503\tvalid_1's auc: 0.789434\n",
      "[3886]\ttraining's auc: 0.896514\tvalid_1's auc: 0.789433\n",
      "[3887]\ttraining's auc: 0.896532\tvalid_1's auc: 0.789434\n",
      "[3888]\ttraining's auc: 0.89654\tvalid_1's auc: 0.789432\n",
      "[3889]\ttraining's auc: 0.89656\tvalid_1's auc: 0.789432\n",
      "[3890]\ttraining's auc: 0.896581\tvalid_1's auc: 0.789433\n",
      "[3891]\ttraining's auc: 0.896608\tvalid_1's auc: 0.789434\n",
      "[3892]\ttraining's auc: 0.896635\tvalid_1's auc: 0.789433\n",
      "[3893]\ttraining's auc: 0.896653\tvalid_1's auc: 0.789436\n",
      "[3894]\ttraining's auc: 0.896667\tvalid_1's auc: 0.789434\n",
      "[3895]\ttraining's auc: 0.896679\tvalid_1's auc: 0.789436\n",
      "[3896]\ttraining's auc: 0.896696\tvalid_1's auc: 0.789435\n",
      "[3897]\ttraining's auc: 0.896707\tvalid_1's auc: 0.789437\n",
      "[3898]\ttraining's auc: 0.896725\tvalid_1's auc: 0.789435\n",
      "[3899]\ttraining's auc: 0.896748\tvalid_1's auc: 0.789433\n",
      "[3900]\ttraining's auc: 0.896766\tvalid_1's auc: 0.789435\n",
      "[3901]\ttraining's auc: 0.896788\tvalid_1's auc: 0.789433\n",
      "[3902]\ttraining's auc: 0.896816\tvalid_1's auc: 0.789435\n",
      "[3903]\ttraining's auc: 0.896827\tvalid_1's auc: 0.789437\n",
      "[3904]\ttraining's auc: 0.896844\tvalid_1's auc: 0.789428\n",
      "[3905]\ttraining's auc: 0.89686\tvalid_1's auc: 0.789421\n",
      "[3906]\ttraining's auc: 0.896882\tvalid_1's auc: 0.789416\n",
      "[3907]\ttraining's auc: 0.896899\tvalid_1's auc: 0.789421\n",
      "[3908]\ttraining's auc: 0.896915\tvalid_1's auc: 0.789421\n",
      "[3909]\ttraining's auc: 0.89693\tvalid_1's auc: 0.789424\n",
      "[3910]\ttraining's auc: 0.896948\tvalid_1's auc: 0.78942\n",
      "[3911]\ttraining's auc: 0.896961\tvalid_1's auc: 0.789418\n",
      "[3912]\ttraining's auc: 0.896978\tvalid_1's auc: 0.789423\n",
      "[3913]\ttraining's auc: 0.897\tvalid_1's auc: 0.789427\n",
      "[3914]\ttraining's auc: 0.897025\tvalid_1's auc: 0.789433\n",
      "[3915]\ttraining's auc: 0.897041\tvalid_1's auc: 0.789432\n",
      "[3916]\ttraining's auc: 0.897058\tvalid_1's auc: 0.789431\n",
      "[3917]\ttraining's auc: 0.897075\tvalid_1's auc: 0.789428\n",
      "[3918]\ttraining's auc: 0.897097\tvalid_1's auc: 0.78943\n",
      "[3919]\ttraining's auc: 0.897113\tvalid_1's auc: 0.789433\n",
      "[3920]\ttraining's auc: 0.89713\tvalid_1's auc: 0.789434\n",
      "[3921]\ttraining's auc: 0.89714\tvalid_1's auc: 0.789432\n",
      "[3922]\ttraining's auc: 0.897157\tvalid_1's auc: 0.789433\n",
      "[3923]\ttraining's auc: 0.897172\tvalid_1's auc: 0.789436\n",
      "[3924]\ttraining's auc: 0.897191\tvalid_1's auc: 0.789431\n",
      "[3925]\ttraining's auc: 0.897212\tvalid_1's auc: 0.789433\n",
      "[3926]\ttraining's auc: 0.897232\tvalid_1's auc: 0.789437\n",
      "[3927]\ttraining's auc: 0.897248\tvalid_1's auc: 0.78944\n",
      "[3928]\ttraining's auc: 0.897267\tvalid_1's auc: 0.789444\n",
      "[3929]\ttraining's auc: 0.897278\tvalid_1's auc: 0.789442\n",
      "[3930]\ttraining's auc: 0.897296\tvalid_1's auc: 0.789439\n",
      "[3931]\ttraining's auc: 0.897312\tvalid_1's auc: 0.78944\n",
      "[3932]\ttraining's auc: 0.897326\tvalid_1's auc: 0.789434\n",
      "[3933]\ttraining's auc: 0.897335\tvalid_1's auc: 0.789438\n",
      "[3934]\ttraining's auc: 0.897361\tvalid_1's auc: 0.789443\n",
      "[3935]\ttraining's auc: 0.89738\tvalid_1's auc: 0.789435\n",
      "[3936]\ttraining's auc: 0.8974\tvalid_1's auc: 0.789441\n",
      "[3937]\ttraining's auc: 0.897421\tvalid_1's auc: 0.789438\n",
      "[3938]\ttraining's auc: 0.897439\tvalid_1's auc: 0.789436\n",
      "[3939]\ttraining's auc: 0.897455\tvalid_1's auc: 0.789428\n",
      "[3940]\ttraining's auc: 0.897471\tvalid_1's auc: 0.789424\n",
      "[3941]\ttraining's auc: 0.897481\tvalid_1's auc: 0.789423\n",
      "[3942]\ttraining's auc: 0.897488\tvalid_1's auc: 0.789419\n",
      "[3943]\ttraining's auc: 0.897509\tvalid_1's auc: 0.789409\n",
      "[3944]\ttraining's auc: 0.897533\tvalid_1's auc: 0.789409\n",
      "[3945]\ttraining's auc: 0.897551\tvalid_1's auc: 0.789421\n",
      "[3946]\ttraining's auc: 0.897566\tvalid_1's auc: 0.789421\n",
      "[3947]\ttraining's auc: 0.897588\tvalid_1's auc: 0.78942\n",
      "[3948]\ttraining's auc: 0.897615\tvalid_1's auc: 0.789419\n",
      "[3949]\ttraining's auc: 0.897621\tvalid_1's auc: 0.789424\n",
      "[3950]\ttraining's auc: 0.89764\tvalid_1's auc: 0.789419\n",
      "[3951]\ttraining's auc: 0.897656\tvalid_1's auc: 0.789414\n",
      "[3952]\ttraining's auc: 0.897666\tvalid_1's auc: 0.789419\n",
      "[3953]\ttraining's auc: 0.897689\tvalid_1's auc: 0.789417\n",
      "[3954]\ttraining's auc: 0.897709\tvalid_1's auc: 0.789414\n",
      "[3955]\ttraining's auc: 0.897728\tvalid_1's auc: 0.789406\n",
      "[3956]\ttraining's auc: 0.897747\tvalid_1's auc: 0.7894\n",
      "[3957]\ttraining's auc: 0.897766\tvalid_1's auc: 0.789404\n",
      "[3958]\ttraining's auc: 0.897785\tvalid_1's auc: 0.7894\n",
      "[3959]\ttraining's auc: 0.897806\tvalid_1's auc: 0.789402\n",
      "[3960]\ttraining's auc: 0.897821\tvalid_1's auc: 0.789402\n",
      "[3961]\ttraining's auc: 0.897837\tvalid_1's auc: 0.789405\n",
      "[3962]\ttraining's auc: 0.897849\tvalid_1's auc: 0.789404\n",
      "[3963]\ttraining's auc: 0.897859\tvalid_1's auc: 0.789406\n",
      "[3964]\ttraining's auc: 0.897878\tvalid_1's auc: 0.789408\n",
      "[3965]\ttraining's auc: 0.897896\tvalid_1's auc: 0.789409\n",
      "[3966]\ttraining's auc: 0.897912\tvalid_1's auc: 0.789411\n",
      "[3967]\ttraining's auc: 0.897925\tvalid_1's auc: 0.789409\n",
      "[3968]\ttraining's auc: 0.897949\tvalid_1's auc: 0.789413\n",
      "[3969]\ttraining's auc: 0.897967\tvalid_1's auc: 0.789406\n",
      "[3970]\ttraining's auc: 0.897973\tvalid_1's auc: 0.789405\n",
      "[3971]\ttraining's auc: 0.897988\tvalid_1's auc: 0.789404\n",
      "[3972]\ttraining's auc: 0.898006\tvalid_1's auc: 0.789409\n",
      "[3973]\ttraining's auc: 0.898023\tvalid_1's auc: 0.789412\n",
      "[3974]\ttraining's auc: 0.898049\tvalid_1's auc: 0.78941\n",
      "[3975]\ttraining's auc: 0.89806\tvalid_1's auc: 0.789406\n",
      "[3976]\ttraining's auc: 0.898078\tvalid_1's auc: 0.789401\n",
      "[3977]\ttraining's auc: 0.898091\tvalid_1's auc: 0.789404\n",
      "[3978]\ttraining's auc: 0.898102\tvalid_1's auc: 0.789405\n",
      "[3979]\ttraining's auc: 0.898116\tvalid_1's auc: 0.789404\n",
      "[3980]\ttraining's auc: 0.898138\tvalid_1's auc: 0.7894\n",
      "[3981]\ttraining's auc: 0.89816\tvalid_1's auc: 0.789403\n",
      "[3982]\ttraining's auc: 0.89817\tvalid_1's auc: 0.789403\n",
      "[3983]\ttraining's auc: 0.89819\tvalid_1's auc: 0.789401\n",
      "[3984]\ttraining's auc: 0.898213\tvalid_1's auc: 0.78941\n",
      "[3985]\ttraining's auc: 0.898226\tvalid_1's auc: 0.789414\n",
      "[3986]\ttraining's auc: 0.898248\tvalid_1's auc: 0.789409\n",
      "[3987]\ttraining's auc: 0.898269\tvalid_1's auc: 0.789407\n",
      "[3988]\ttraining's auc: 0.898289\tvalid_1's auc: 0.789411\n",
      "[3989]\ttraining's auc: 0.898304\tvalid_1's auc: 0.789414\n",
      "[3990]\ttraining's auc: 0.898317\tvalid_1's auc: 0.789415\n",
      "[3991]\ttraining's auc: 0.898345\tvalid_1's auc: 0.789415\n",
      "[3992]\ttraining's auc: 0.89836\tvalid_1's auc: 0.789405\n",
      "[3993]\ttraining's auc: 0.898373\tvalid_1's auc: 0.78941\n",
      "[3994]\ttraining's auc: 0.898392\tvalid_1's auc: 0.789413\n",
      "[3995]\ttraining's auc: 0.898408\tvalid_1's auc: 0.789412\n",
      "[3996]\ttraining's auc: 0.898429\tvalid_1's auc: 0.789416\n",
      "[3997]\ttraining's auc: 0.898431\tvalid_1's auc: 0.789414\n",
      "[3998]\ttraining's auc: 0.898444\tvalid_1's auc: 0.789415\n",
      "[3999]\ttraining's auc: 0.898462\tvalid_1's auc: 0.789415\n",
      "[4000]\ttraining's auc: 0.898483\tvalid_1's auc: 0.789416\n",
      "[4001]\ttraining's auc: 0.898493\tvalid_1's auc: 0.789418\n",
      "[4002]\ttraining's auc: 0.898508\tvalid_1's auc: 0.789422\n",
      "[4003]\ttraining's auc: 0.898526\tvalid_1's auc: 0.789423\n",
      "[4004]\ttraining's auc: 0.898539\tvalid_1's auc: 0.789421\n",
      "[4005]\ttraining's auc: 0.89855\tvalid_1's auc: 0.789422\n",
      "[4006]\ttraining's auc: 0.898558\tvalid_1's auc: 0.78942\n",
      "[4007]\ttraining's auc: 0.898579\tvalid_1's auc: 0.789426\n",
      "[4008]\ttraining's auc: 0.898594\tvalid_1's auc: 0.789422\n",
      "[4009]\ttraining's auc: 0.898613\tvalid_1's auc: 0.789422\n",
      "[4010]\ttraining's auc: 0.898644\tvalid_1's auc: 0.789424\n",
      "[4011]\ttraining's auc: 0.89866\tvalid_1's auc: 0.789425\n",
      "[4012]\ttraining's auc: 0.898683\tvalid_1's auc: 0.789424\n",
      "[4013]\ttraining's auc: 0.898696\tvalid_1's auc: 0.789423\n",
      "[4014]\ttraining's auc: 0.898713\tvalid_1's auc: 0.789423\n",
      "[4015]\ttraining's auc: 0.898738\tvalid_1's auc: 0.789423\n",
      "[4016]\ttraining's auc: 0.898754\tvalid_1's auc: 0.789422\n",
      "[4017]\ttraining's auc: 0.89877\tvalid_1's auc: 0.789422\n",
      "[4018]\ttraining's auc: 0.898777\tvalid_1's auc: 0.789421\n",
      "[4019]\ttraining's auc: 0.898795\tvalid_1's auc: 0.789414\n",
      "[4020]\ttraining's auc: 0.898823\tvalid_1's auc: 0.789423\n",
      "[4021]\ttraining's auc: 0.898832\tvalid_1's auc: 0.789427\n",
      "[4022]\ttraining's auc: 0.898839\tvalid_1's auc: 0.789425\n",
      "[4023]\ttraining's auc: 0.898847\tvalid_1's auc: 0.789424\n",
      "[4024]\ttraining's auc: 0.898864\tvalid_1's auc: 0.789424\n",
      "[4025]\ttraining's auc: 0.898883\tvalid_1's auc: 0.789422\n",
      "[4026]\ttraining's auc: 0.898892\tvalid_1's auc: 0.789424\n",
      "[4027]\ttraining's auc: 0.898909\tvalid_1's auc: 0.789421\n",
      "[4028]\ttraining's auc: 0.898923\tvalid_1's auc: 0.789423\n",
      "[4029]\ttraining's auc: 0.898944\tvalid_1's auc: 0.789423\n",
      "[4030]\ttraining's auc: 0.898952\tvalid_1's auc: 0.789428\n",
      "[4031]\ttraining's auc: 0.89898\tvalid_1's auc: 0.789432\n",
      "[4032]\ttraining's auc: 0.898999\tvalid_1's auc: 0.789433\n",
      "[4033]\ttraining's auc: 0.899014\tvalid_1's auc: 0.789431\n",
      "[4034]\ttraining's auc: 0.89903\tvalid_1's auc: 0.789429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4035]\ttraining's auc: 0.899046\tvalid_1's auc: 0.789429\n",
      "[4036]\ttraining's auc: 0.899065\tvalid_1's auc: 0.789429\n",
      "[4037]\ttraining's auc: 0.899081\tvalid_1's auc: 0.789429\n",
      "[4038]\ttraining's auc: 0.899101\tvalid_1's auc: 0.789426\n",
      "[4039]\ttraining's auc: 0.899115\tvalid_1's auc: 0.789425\n",
      "[4040]\ttraining's auc: 0.89913\tvalid_1's auc: 0.789422\n",
      "[4041]\ttraining's auc: 0.899143\tvalid_1's auc: 0.789423\n",
      "[4042]\ttraining's auc: 0.899163\tvalid_1's auc: 0.789417\n",
      "[4043]\ttraining's auc: 0.899184\tvalid_1's auc: 0.789418\n",
      "[4044]\ttraining's auc: 0.899199\tvalid_1's auc: 0.789424\n",
      "[4045]\ttraining's auc: 0.899214\tvalid_1's auc: 0.789429\n",
      "[4046]\ttraining's auc: 0.899235\tvalid_1's auc: 0.78943\n",
      "[4047]\ttraining's auc: 0.899257\tvalid_1's auc: 0.789429\n",
      "[4048]\ttraining's auc: 0.899273\tvalid_1's auc: 0.789425\n",
      "[4049]\ttraining's auc: 0.899289\tvalid_1's auc: 0.789425\n",
      "[4050]\ttraining's auc: 0.899313\tvalid_1's auc: 0.789426\n",
      "[4051]\ttraining's auc: 0.89933\tvalid_1's auc: 0.789431\n",
      "[4052]\ttraining's auc: 0.899347\tvalid_1's auc: 0.789431\n",
      "[4053]\ttraining's auc: 0.899364\tvalid_1's auc: 0.789426\n",
      "[4054]\ttraining's auc: 0.899375\tvalid_1's auc: 0.789428\n",
      "[4055]\ttraining's auc: 0.899396\tvalid_1's auc: 0.789426\n",
      "[4056]\ttraining's auc: 0.899408\tvalid_1's auc: 0.789423\n",
      "[4057]\ttraining's auc: 0.899431\tvalid_1's auc: 0.789423\n",
      "[4058]\ttraining's auc: 0.899448\tvalid_1's auc: 0.789426\n",
      "[4059]\ttraining's auc: 0.89946\tvalid_1's auc: 0.789429\n",
      "[4060]\ttraining's auc: 0.899477\tvalid_1's auc: 0.789431\n",
      "[4061]\ttraining's auc: 0.899492\tvalid_1's auc: 0.789429\n",
      "[4062]\ttraining's auc: 0.899512\tvalid_1's auc: 0.789432\n",
      "[4063]\ttraining's auc: 0.899528\tvalid_1's auc: 0.789438\n",
      "[4064]\ttraining's auc: 0.899544\tvalid_1's auc: 0.789433\n",
      "[4065]\ttraining's auc: 0.899565\tvalid_1's auc: 0.789437\n",
      "[4066]\ttraining's auc: 0.899579\tvalid_1's auc: 0.789438\n",
      "[4067]\ttraining's auc: 0.899602\tvalid_1's auc: 0.789443\n",
      "[4068]\ttraining's auc: 0.899616\tvalid_1's auc: 0.789443\n",
      "[4069]\ttraining's auc: 0.899633\tvalid_1's auc: 0.789441\n",
      "[4070]\ttraining's auc: 0.899638\tvalid_1's auc: 0.789441\n",
      "[4071]\ttraining's auc: 0.899642\tvalid_1's auc: 0.78944\n",
      "[4072]\ttraining's auc: 0.899658\tvalid_1's auc: 0.789441\n",
      "[4073]\ttraining's auc: 0.899677\tvalid_1's auc: 0.789441\n",
      "[4074]\ttraining's auc: 0.899689\tvalid_1's auc: 0.789442\n",
      "[4075]\ttraining's auc: 0.899709\tvalid_1's auc: 0.789447\n",
      "[4076]\ttraining's auc: 0.899722\tvalid_1's auc: 0.789445\n",
      "[4077]\ttraining's auc: 0.89974\tvalid_1's auc: 0.789444\n",
      "[4078]\ttraining's auc: 0.899758\tvalid_1's auc: 0.789444\n",
      "[4079]\ttraining's auc: 0.899776\tvalid_1's auc: 0.789435\n",
      "[4080]\ttraining's auc: 0.899793\tvalid_1's auc: 0.789439\n",
      "[4081]\ttraining's auc: 0.899811\tvalid_1's auc: 0.789444\n",
      "[4082]\ttraining's auc: 0.899829\tvalid_1's auc: 0.789444\n",
      "[4083]\ttraining's auc: 0.89985\tvalid_1's auc: 0.789445\n",
      "[4084]\ttraining's auc: 0.899868\tvalid_1's auc: 0.789454\n",
      "[4085]\ttraining's auc: 0.899884\tvalid_1's auc: 0.789458\n",
      "[4086]\ttraining's auc: 0.899904\tvalid_1's auc: 0.789457\n",
      "[4087]\ttraining's auc: 0.899924\tvalid_1's auc: 0.789461\n",
      "[4088]\ttraining's auc: 0.899942\tvalid_1's auc: 0.789459\n",
      "[4089]\ttraining's auc: 0.899948\tvalid_1's auc: 0.789458\n",
      "[4090]\ttraining's auc: 0.899964\tvalid_1's auc: 0.789454\n",
      "[4091]\ttraining's auc: 0.899986\tvalid_1's auc: 0.789455\n",
      "[4092]\ttraining's auc: 0.900004\tvalid_1's auc: 0.789456\n",
      "[4093]\ttraining's auc: 0.900024\tvalid_1's auc: 0.789451\n",
      "[4094]\ttraining's auc: 0.900035\tvalid_1's auc: 0.789448\n",
      "[4095]\ttraining's auc: 0.900053\tvalid_1's auc: 0.789454\n",
      "[4096]\ttraining's auc: 0.900073\tvalid_1's auc: 0.789455\n",
      "[4097]\ttraining's auc: 0.90009\tvalid_1's auc: 0.789458\n",
      "[4098]\ttraining's auc: 0.900108\tvalid_1's auc: 0.789459\n",
      "[4099]\ttraining's auc: 0.900129\tvalid_1's auc: 0.789457\n",
      "[4100]\ttraining's auc: 0.900141\tvalid_1's auc: 0.789453\n",
      "[4101]\ttraining's auc: 0.90016\tvalid_1's auc: 0.789453\n",
      "[4102]\ttraining's auc: 0.900165\tvalid_1's auc: 0.78945\n",
      "[4103]\ttraining's auc: 0.900171\tvalid_1's auc: 0.789453\n",
      "[4104]\ttraining's auc: 0.900183\tvalid_1's auc: 0.789447\n",
      "[4105]\ttraining's auc: 0.900198\tvalid_1's auc: 0.789445\n",
      "[4106]\ttraining's auc: 0.900216\tvalid_1's auc: 0.789445\n",
      "[4107]\ttraining's auc: 0.900242\tvalid_1's auc: 0.789446\n",
      "[4108]\ttraining's auc: 0.900254\tvalid_1's auc: 0.789441\n",
      "[4109]\ttraining's auc: 0.900268\tvalid_1's auc: 0.789443\n",
      "[4110]\ttraining's auc: 0.900272\tvalid_1's auc: 0.789443\n",
      "[4111]\ttraining's auc: 0.900287\tvalid_1's auc: 0.789447\n",
      "[4112]\ttraining's auc: 0.900308\tvalid_1's auc: 0.789445\n",
      "[4113]\ttraining's auc: 0.900323\tvalid_1's auc: 0.789448\n",
      "[4114]\ttraining's auc: 0.900338\tvalid_1's auc: 0.789451\n",
      "[4115]\ttraining's auc: 0.900361\tvalid_1's auc: 0.789455\n",
      "[4116]\ttraining's auc: 0.90038\tvalid_1's auc: 0.789454\n",
      "[4117]\ttraining's auc: 0.900398\tvalid_1's auc: 0.789453\n",
      "[4118]\ttraining's auc: 0.900412\tvalid_1's auc: 0.789452\n",
      "[4119]\ttraining's auc: 0.900433\tvalid_1's auc: 0.789453\n",
      "[4120]\ttraining's auc: 0.900452\tvalid_1's auc: 0.789452\n",
      "[4121]\ttraining's auc: 0.900467\tvalid_1's auc: 0.789445\n",
      "[4122]\ttraining's auc: 0.900489\tvalid_1's auc: 0.789444\n",
      "[4123]\ttraining's auc: 0.900511\tvalid_1's auc: 0.789444\n",
      "[4124]\ttraining's auc: 0.900518\tvalid_1's auc: 0.789446\n",
      "[4125]\ttraining's auc: 0.900538\tvalid_1's auc: 0.789446\n",
      "[4126]\ttraining's auc: 0.900553\tvalid_1's auc: 0.789446\n",
      "[4127]\ttraining's auc: 0.900575\tvalid_1's auc: 0.789443\n",
      "[4128]\ttraining's auc: 0.900591\tvalid_1's auc: 0.789446\n",
      "[4129]\ttraining's auc: 0.900604\tvalid_1's auc: 0.789444\n",
      "[4130]\ttraining's auc: 0.900614\tvalid_1's auc: 0.789441\n",
      "[4131]\ttraining's auc: 0.900633\tvalid_1's auc: 0.789438\n",
      "[4132]\ttraining's auc: 0.900651\tvalid_1's auc: 0.789444\n",
      "[4133]\ttraining's auc: 0.900669\tvalid_1's auc: 0.789442\n",
      "[4134]\ttraining's auc: 0.900679\tvalid_1's auc: 0.789435\n",
      "[4135]\ttraining's auc: 0.900697\tvalid_1's auc: 0.789431\n",
      "[4136]\ttraining's auc: 0.900716\tvalid_1's auc: 0.789426\n",
      "[4137]\ttraining's auc: 0.900735\tvalid_1's auc: 0.78942\n",
      "[4138]\ttraining's auc: 0.900749\tvalid_1's auc: 0.789419\n",
      "[4139]\ttraining's auc: 0.90078\tvalid_1's auc: 0.789418\n",
      "[4140]\ttraining's auc: 0.900789\tvalid_1's auc: 0.789417\n",
      "[4141]\ttraining's auc: 0.900809\tvalid_1's auc: 0.789416\n",
      "[4142]\ttraining's auc: 0.900829\tvalid_1's auc: 0.789414\n",
      "[4143]\ttraining's auc: 0.900847\tvalid_1's auc: 0.78942\n",
      "[4144]\ttraining's auc: 0.900862\tvalid_1's auc: 0.789425\n",
      "[4145]\ttraining's auc: 0.900884\tvalid_1's auc: 0.789416\n",
      "[4146]\ttraining's auc: 0.9009\tvalid_1's auc: 0.789419\n",
      "[4147]\ttraining's auc: 0.900918\tvalid_1's auc: 0.789423\n",
      "[4148]\ttraining's auc: 0.900931\tvalid_1's auc: 0.78942\n",
      "[4149]\ttraining's auc: 0.900949\tvalid_1's auc: 0.789423\n",
      "[4150]\ttraining's auc: 0.900962\tvalid_1's auc: 0.789423\n",
      "[4151]\ttraining's auc: 0.900978\tvalid_1's auc: 0.789423\n",
      "[4152]\ttraining's auc: 0.901003\tvalid_1's auc: 0.789427\n",
      "[4153]\ttraining's auc: 0.90102\tvalid_1's auc: 0.789432\n",
      "[4154]\ttraining's auc: 0.901039\tvalid_1's auc: 0.789426\n",
      "[4155]\ttraining's auc: 0.901056\tvalid_1's auc: 0.78943\n",
      "[4156]\ttraining's auc: 0.901074\tvalid_1's auc: 0.789426\n",
      "[4157]\ttraining's auc: 0.901092\tvalid_1's auc: 0.789421\n",
      "[4158]\ttraining's auc: 0.901115\tvalid_1's auc: 0.78942\n",
      "[4159]\ttraining's auc: 0.901139\tvalid_1's auc: 0.789419\n",
      "[4160]\ttraining's auc: 0.901163\tvalid_1's auc: 0.789419\n",
      "[4161]\ttraining's auc: 0.90118\tvalid_1's auc: 0.789419\n",
      "[4162]\ttraining's auc: 0.901199\tvalid_1's auc: 0.789415\n",
      "[4163]\ttraining's auc: 0.901202\tvalid_1's auc: 0.789414\n",
      "[4164]\ttraining's auc: 0.901221\tvalid_1's auc: 0.789419\n",
      "[4165]\ttraining's auc: 0.901243\tvalid_1's auc: 0.789417\n",
      "[4166]\ttraining's auc: 0.901259\tvalid_1's auc: 0.789421\n",
      "[4167]\ttraining's auc: 0.901278\tvalid_1's auc: 0.789415\n",
      "[4168]\ttraining's auc: 0.901298\tvalid_1's auc: 0.789419\n",
      "[4169]\ttraining's auc: 0.901317\tvalid_1's auc: 0.789421\n",
      "[4170]\ttraining's auc: 0.901344\tvalid_1's auc: 0.789418\n",
      "[4171]\ttraining's auc: 0.901367\tvalid_1's auc: 0.789422\n",
      "[4172]\ttraining's auc: 0.901389\tvalid_1's auc: 0.789425\n",
      "[4173]\ttraining's auc: 0.901411\tvalid_1's auc: 0.789426\n",
      "[4174]\ttraining's auc: 0.901433\tvalid_1's auc: 0.789428\n",
      "[4175]\ttraining's auc: 0.901455\tvalid_1's auc: 0.789436\n",
      "[4176]\ttraining's auc: 0.90147\tvalid_1's auc: 0.789434\n",
      "[4177]\ttraining's auc: 0.901487\tvalid_1's auc: 0.789435\n",
      "[4178]\ttraining's auc: 0.90151\tvalid_1's auc: 0.789435\n",
      "[4179]\ttraining's auc: 0.901531\tvalid_1's auc: 0.789432\n",
      "[4180]\ttraining's auc: 0.901536\tvalid_1's auc: 0.789433\n",
      "[4181]\ttraining's auc: 0.901553\tvalid_1's auc: 0.789431\n",
      "[4182]\ttraining's auc: 0.901573\tvalid_1's auc: 0.789431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4183]\ttraining's auc: 0.901591\tvalid_1's auc: 0.789435\n",
      "[4184]\ttraining's auc: 0.901618\tvalid_1's auc: 0.789432\n",
      "[4185]\ttraining's auc: 0.901642\tvalid_1's auc: 0.789435\n",
      "[4186]\ttraining's auc: 0.901657\tvalid_1's auc: 0.789435\n",
      "[4187]\ttraining's auc: 0.901679\tvalid_1's auc: 0.789437\n",
      "[4188]\ttraining's auc: 0.901682\tvalid_1's auc: 0.789437\n",
      "[4189]\ttraining's auc: 0.901696\tvalid_1's auc: 0.789441\n",
      "[4190]\ttraining's auc: 0.901711\tvalid_1's auc: 0.789443\n",
      "[4191]\ttraining's auc: 0.901718\tvalid_1's auc: 0.789446\n",
      "[4192]\ttraining's auc: 0.901738\tvalid_1's auc: 0.789435\n",
      "[4193]\ttraining's auc: 0.901761\tvalid_1's auc: 0.789429\n",
      "[4194]\ttraining's auc: 0.901782\tvalid_1's auc: 0.789427\n",
      "[4195]\ttraining's auc: 0.901801\tvalid_1's auc: 0.789421\n",
      "[4196]\ttraining's auc: 0.901826\tvalid_1's auc: 0.789418\n",
      "[4197]\ttraining's auc: 0.901848\tvalid_1's auc: 0.789414\n",
      "[4198]\ttraining's auc: 0.901867\tvalid_1's auc: 0.789415\n",
      "[4199]\ttraining's auc: 0.90189\tvalid_1's auc: 0.789416\n",
      "[4200]\ttraining's auc: 0.901911\tvalid_1's auc: 0.78942\n",
      "[4201]\ttraining's auc: 0.901927\tvalid_1's auc: 0.789421\n",
      "[4202]\ttraining's auc: 0.901945\tvalid_1's auc: 0.789419\n",
      "[4203]\ttraining's auc: 0.901962\tvalid_1's auc: 0.78942\n",
      "[4204]\ttraining's auc: 0.90198\tvalid_1's auc: 0.789426\n",
      "[4205]\ttraining's auc: 0.902\tvalid_1's auc: 0.789427\n",
      "[4206]\ttraining's auc: 0.902012\tvalid_1's auc: 0.789424\n",
      "[4207]\ttraining's auc: 0.90203\tvalid_1's auc: 0.78942\n",
      "[4208]\ttraining's auc: 0.902053\tvalid_1's auc: 0.789417\n",
      "[4209]\ttraining's auc: 0.902073\tvalid_1's auc: 0.789415\n",
      "[4210]\ttraining's auc: 0.90209\tvalid_1's auc: 0.789412\n",
      "[4211]\ttraining's auc: 0.902111\tvalid_1's auc: 0.789409\n",
      "[4212]\ttraining's auc: 0.902129\tvalid_1's auc: 0.789408\n",
      "[4213]\ttraining's auc: 0.902143\tvalid_1's auc: 0.789405\n",
      "[4214]\ttraining's auc: 0.902163\tvalid_1's auc: 0.789405\n",
      "[4215]\ttraining's auc: 0.902186\tvalid_1's auc: 0.7894\n",
      "[4216]\ttraining's auc: 0.902192\tvalid_1's auc: 0.789401\n",
      "[4217]\ttraining's auc: 0.902204\tvalid_1's auc: 0.7894\n",
      "[4218]\ttraining's auc: 0.902223\tvalid_1's auc: 0.789405\n",
      "[4219]\ttraining's auc: 0.902241\tvalid_1's auc: 0.789401\n",
      "[4220]\ttraining's auc: 0.902265\tvalid_1's auc: 0.789404\n",
      "[4221]\ttraining's auc: 0.902276\tvalid_1's auc: 0.789406\n",
      "[4222]\ttraining's auc: 0.902295\tvalid_1's auc: 0.789404\n",
      "[4223]\ttraining's auc: 0.902308\tvalid_1's auc: 0.789401\n",
      "[4224]\ttraining's auc: 0.902329\tvalid_1's auc: 0.789401\n",
      "[4225]\ttraining's auc: 0.902351\tvalid_1's auc: 0.7894\n",
      "[4226]\ttraining's auc: 0.902361\tvalid_1's auc: 0.789398\n",
      "[4227]\ttraining's auc: 0.902379\tvalid_1's auc: 0.789402\n",
      "[4228]\ttraining's auc: 0.902394\tvalid_1's auc: 0.7894\n",
      "[4229]\ttraining's auc: 0.902415\tvalid_1's auc: 0.789399\n",
      "[4230]\ttraining's auc: 0.902438\tvalid_1's auc: 0.789392\n",
      "[4231]\ttraining's auc: 0.902456\tvalid_1's auc: 0.789394\n",
      "[4232]\ttraining's auc: 0.902472\tvalid_1's auc: 0.789397\n",
      "[4233]\ttraining's auc: 0.90248\tvalid_1's auc: 0.789396\n",
      "[4234]\ttraining's auc: 0.902497\tvalid_1's auc: 0.789397\n",
      "[4235]\ttraining's auc: 0.902514\tvalid_1's auc: 0.789397\n",
      "[4236]\ttraining's auc: 0.902534\tvalid_1's auc: 0.789398\n",
      "[4237]\ttraining's auc: 0.902544\tvalid_1's auc: 0.7894\n",
      "[4238]\ttraining's auc: 0.902564\tvalid_1's auc: 0.7894\n",
      "[4239]\ttraining's auc: 0.902587\tvalid_1's auc: 0.7894\n",
      "[4240]\ttraining's auc: 0.902598\tvalid_1's auc: 0.789396\n",
      "[4241]\ttraining's auc: 0.902621\tvalid_1's auc: 0.789401\n",
      "[4242]\ttraining's auc: 0.90263\tvalid_1's auc: 0.789404\n",
      "[4243]\ttraining's auc: 0.902643\tvalid_1's auc: 0.789404\n",
      "[4244]\ttraining's auc: 0.90266\tvalid_1's auc: 0.789397\n",
      "[4245]\ttraining's auc: 0.902674\tvalid_1's auc: 0.789394\n",
      "[4246]\ttraining's auc: 0.902694\tvalid_1's auc: 0.789391\n",
      "[4247]\ttraining's auc: 0.902714\tvalid_1's auc: 0.789387\n",
      "[4248]\ttraining's auc: 0.902731\tvalid_1's auc: 0.789385\n",
      "[4249]\ttraining's auc: 0.902745\tvalid_1's auc: 0.789383\n",
      "[4250]\ttraining's auc: 0.902767\tvalid_1's auc: 0.78938\n",
      "[4251]\ttraining's auc: 0.902786\tvalid_1's auc: 0.789383\n",
      "[4252]\ttraining's auc: 0.902808\tvalid_1's auc: 0.789382\n",
      "[4253]\ttraining's auc: 0.902833\tvalid_1's auc: 0.78938\n",
      "[4254]\ttraining's auc: 0.902849\tvalid_1's auc: 0.789372\n",
      "[4255]\ttraining's auc: 0.902864\tvalid_1's auc: 0.789372\n",
      "[4256]\ttraining's auc: 0.902871\tvalid_1's auc: 0.789371\n",
      "[4257]\ttraining's auc: 0.902891\tvalid_1's auc: 0.789369\n",
      "[4258]\ttraining's auc: 0.902912\tvalid_1's auc: 0.789372\n",
      "[4259]\ttraining's auc: 0.902934\tvalid_1's auc: 0.78937\n",
      "[4260]\ttraining's auc: 0.902949\tvalid_1's auc: 0.789373\n",
      "[4261]\ttraining's auc: 0.902957\tvalid_1's auc: 0.789374\n",
      "[4262]\ttraining's auc: 0.902975\tvalid_1's auc: 0.789366\n",
      "[4263]\ttraining's auc: 0.902993\tvalid_1's auc: 0.789365\n",
      "[4264]\ttraining's auc: 0.90301\tvalid_1's auc: 0.789358\n",
      "[4265]\ttraining's auc: 0.903024\tvalid_1's auc: 0.78936\n",
      "[4266]\ttraining's auc: 0.903029\tvalid_1's auc: 0.78936\n",
      "[4267]\ttraining's auc: 0.903055\tvalid_1's auc: 0.789358\n",
      "[4268]\ttraining's auc: 0.903074\tvalid_1's auc: 0.789358\n",
      "[4269]\ttraining's auc: 0.903092\tvalid_1's auc: 0.789355\n",
      "[4270]\ttraining's auc: 0.90311\tvalid_1's auc: 0.789357\n",
      "[4271]\ttraining's auc: 0.903131\tvalid_1's auc: 0.789351\n",
      "[4272]\ttraining's auc: 0.903144\tvalid_1's auc: 0.789351\n",
      "[4273]\ttraining's auc: 0.903155\tvalid_1's auc: 0.789352\n",
      "[4274]\ttraining's auc: 0.903169\tvalid_1's auc: 0.789356\n",
      "[4275]\ttraining's auc: 0.903188\tvalid_1's auc: 0.78936\n",
      "[4276]\ttraining's auc: 0.903199\tvalid_1's auc: 0.789356\n",
      "[4277]\ttraining's auc: 0.903214\tvalid_1's auc: 0.789354\n",
      "[4278]\ttraining's auc: 0.903232\tvalid_1's auc: 0.789353\n",
      "[4279]\ttraining's auc: 0.903245\tvalid_1's auc: 0.789353\n",
      "[4280]\ttraining's auc: 0.903252\tvalid_1's auc: 0.789355\n",
      "[4281]\ttraining's auc: 0.903271\tvalid_1's auc: 0.789348\n",
      "[4282]\ttraining's auc: 0.903292\tvalid_1's auc: 0.78935\n",
      "[4283]\ttraining's auc: 0.903299\tvalid_1's auc: 0.789349\n",
      "[4284]\ttraining's auc: 0.903318\tvalid_1's auc: 0.789348\n",
      "[4285]\ttraining's auc: 0.903322\tvalid_1's auc: 0.789349\n",
      "[4286]\ttraining's auc: 0.903339\tvalid_1's auc: 0.789349\n",
      "[4287]\ttraining's auc: 0.903358\tvalid_1's auc: 0.789349\n",
      "[4288]\ttraining's auc: 0.903371\tvalid_1's auc: 0.789345\n",
      "[4289]\ttraining's auc: 0.903393\tvalid_1's auc: 0.789341\n",
      "[4290]\ttraining's auc: 0.903402\tvalid_1's auc: 0.789342\n",
      "[4291]\ttraining's auc: 0.903417\tvalid_1's auc: 0.789337\n",
      "[4292]\ttraining's auc: 0.903434\tvalid_1's auc: 0.789332\n",
      "[4293]\ttraining's auc: 0.903445\tvalid_1's auc: 0.789338\n",
      "[4294]\ttraining's auc: 0.903461\tvalid_1's auc: 0.789341\n",
      "[4295]\ttraining's auc: 0.903475\tvalid_1's auc: 0.789338\n",
      "[4296]\ttraining's auc: 0.903495\tvalid_1's auc: 0.789339\n",
      "[4297]\ttraining's auc: 0.903513\tvalid_1's auc: 0.789341\n",
      "[4298]\ttraining's auc: 0.903519\tvalid_1's auc: 0.78934\n",
      "[4299]\ttraining's auc: 0.903538\tvalid_1's auc: 0.789344\n",
      "[4300]\ttraining's auc: 0.903555\tvalid_1's auc: 0.789342\n",
      "[4301]\ttraining's auc: 0.90357\tvalid_1's auc: 0.789343\n",
      "[4302]\ttraining's auc: 0.903588\tvalid_1's auc: 0.789348\n",
      "[4303]\ttraining's auc: 0.9036\tvalid_1's auc: 0.789344\n",
      "[4304]\ttraining's auc: 0.903615\tvalid_1's auc: 0.789339\n",
      "[4305]\ttraining's auc: 0.903631\tvalid_1's auc: 0.789338\n",
      "[4306]\ttraining's auc: 0.903648\tvalid_1's auc: 0.789342\n",
      "[4307]\ttraining's auc: 0.90366\tvalid_1's auc: 0.789335\n",
      "[4308]\ttraining's auc: 0.903675\tvalid_1's auc: 0.789335\n",
      "[4309]\ttraining's auc: 0.903693\tvalid_1's auc: 0.789334\n",
      "[4310]\ttraining's auc: 0.903712\tvalid_1's auc: 0.789339\n",
      "[4311]\ttraining's auc: 0.90373\tvalid_1's auc: 0.789335\n",
      "[4312]\ttraining's auc: 0.903746\tvalid_1's auc: 0.789332\n",
      "[4313]\ttraining's auc: 0.903765\tvalid_1's auc: 0.789331\n",
      "[4314]\ttraining's auc: 0.90378\tvalid_1's auc: 0.789325\n",
      "[4315]\ttraining's auc: 0.903801\tvalid_1's auc: 0.789325\n",
      "[4316]\ttraining's auc: 0.903823\tvalid_1's auc: 0.789327\n",
      "[4317]\ttraining's auc: 0.903833\tvalid_1's auc: 0.789324\n",
      "[4318]\ttraining's auc: 0.903849\tvalid_1's auc: 0.789321\n",
      "[4319]\ttraining's auc: 0.903867\tvalid_1's auc: 0.789318\n",
      "[4320]\ttraining's auc: 0.903889\tvalid_1's auc: 0.789314\n",
      "[4321]\ttraining's auc: 0.903905\tvalid_1's auc: 0.789312\n",
      "[4322]\ttraining's auc: 0.90392\tvalid_1's auc: 0.789308\n",
      "[4323]\ttraining's auc: 0.903937\tvalid_1's auc: 0.789312\n",
      "[4324]\ttraining's auc: 0.903956\tvalid_1's auc: 0.789311\n",
      "[4325]\ttraining's auc: 0.903976\tvalid_1's auc: 0.789307\n",
      "[4326]\ttraining's auc: 0.903992\tvalid_1's auc: 0.789308\n",
      "[4327]\ttraining's auc: 0.904015\tvalid_1's auc: 0.789308\n",
      "[4328]\ttraining's auc: 0.904041\tvalid_1's auc: 0.78931\n",
      "[4329]\ttraining's auc: 0.904059\tvalid_1's auc: 0.789302\n",
      "[4330]\ttraining's auc: 0.904078\tvalid_1's auc: 0.789302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4331]\ttraining's auc: 0.904105\tvalid_1's auc: 0.789299\n",
      "[4332]\ttraining's auc: 0.904118\tvalid_1's auc: 0.789297\n",
      "[4333]\ttraining's auc: 0.904133\tvalid_1's auc: 0.789298\n",
      "[4334]\ttraining's auc: 0.90414\tvalid_1's auc: 0.789297\n",
      "[4335]\ttraining's auc: 0.904156\tvalid_1's auc: 0.789299\n",
      "[4336]\ttraining's auc: 0.904173\tvalid_1's auc: 0.789296\n",
      "[4337]\ttraining's auc: 0.904178\tvalid_1's auc: 0.789299\n",
      "[4338]\ttraining's auc: 0.90419\tvalid_1's auc: 0.789303\n",
      "[4339]\ttraining's auc: 0.904208\tvalid_1's auc: 0.789305\n",
      "[4340]\ttraining's auc: 0.904225\tvalid_1's auc: 0.789309\n",
      "[4341]\ttraining's auc: 0.904246\tvalid_1's auc: 0.789314\n",
      "[4342]\ttraining's auc: 0.904265\tvalid_1's auc: 0.789314\n",
      "[4343]\ttraining's auc: 0.904283\tvalid_1's auc: 0.789312\n",
      "[4344]\ttraining's auc: 0.904306\tvalid_1's auc: 0.789321\n",
      "[4345]\ttraining's auc: 0.904318\tvalid_1's auc: 0.789322\n",
      "[4346]\ttraining's auc: 0.904335\tvalid_1's auc: 0.789322\n",
      "[4347]\ttraining's auc: 0.904356\tvalid_1's auc: 0.78933\n",
      "[4348]\ttraining's auc: 0.904378\tvalid_1's auc: 0.78933\n",
      "[4349]\ttraining's auc: 0.904393\tvalid_1's auc: 0.789329\n",
      "[4350]\ttraining's auc: 0.904404\tvalid_1's auc: 0.789327\n",
      "[4351]\ttraining's auc: 0.90442\tvalid_1's auc: 0.789335\n",
      "[4352]\ttraining's auc: 0.904434\tvalid_1's auc: 0.789342\n",
      "[4353]\ttraining's auc: 0.904448\tvalid_1's auc: 0.789334\n",
      "[4354]\ttraining's auc: 0.904476\tvalid_1's auc: 0.789329\n",
      "[4355]\ttraining's auc: 0.904495\tvalid_1's auc: 0.789324\n",
      "[4356]\ttraining's auc: 0.904509\tvalid_1's auc: 0.789322\n",
      "[4357]\ttraining's auc: 0.904514\tvalid_1's auc: 0.789327\n",
      "[4358]\ttraining's auc: 0.904533\tvalid_1's auc: 0.789329\n",
      "[4359]\ttraining's auc: 0.904542\tvalid_1's auc: 0.789323\n",
      "[4360]\ttraining's auc: 0.904567\tvalid_1's auc: 0.789325\n",
      "[4361]\ttraining's auc: 0.904588\tvalid_1's auc: 0.789327\n",
      "[4362]\ttraining's auc: 0.904595\tvalid_1's auc: 0.789326\n",
      "[4363]\ttraining's auc: 0.904608\tvalid_1's auc: 0.78933\n",
      "[4364]\ttraining's auc: 0.904621\tvalid_1's auc: 0.789331\n",
      "[4365]\ttraining's auc: 0.904632\tvalid_1's auc: 0.789329\n",
      "[4366]\ttraining's auc: 0.904649\tvalid_1's auc: 0.789328\n",
      "[4367]\ttraining's auc: 0.904658\tvalid_1's auc: 0.789327\n",
      "[4368]\ttraining's auc: 0.904673\tvalid_1's auc: 0.789325\n",
      "[4369]\ttraining's auc: 0.90469\tvalid_1's auc: 0.789325\n",
      "[4370]\ttraining's auc: 0.904707\tvalid_1's auc: 0.789326\n",
      "[4371]\ttraining's auc: 0.904729\tvalid_1's auc: 0.789337\n",
      "[4372]\ttraining's auc: 0.904754\tvalid_1's auc: 0.789337\n",
      "[4373]\ttraining's auc: 0.90477\tvalid_1's auc: 0.789336\n",
      "[4374]\ttraining's auc: 0.904792\tvalid_1's auc: 0.789329\n",
      "[4375]\ttraining's auc: 0.904816\tvalid_1's auc: 0.789325\n",
      "[4376]\ttraining's auc: 0.904833\tvalid_1's auc: 0.789327\n",
      "[4377]\ttraining's auc: 0.904852\tvalid_1's auc: 0.789327\n",
      "[4378]\ttraining's auc: 0.904868\tvalid_1's auc: 0.789326\n",
      "[4379]\ttraining's auc: 0.904886\tvalid_1's auc: 0.789333\n",
      "[4380]\ttraining's auc: 0.9049\tvalid_1's auc: 0.789335\n",
      "[4381]\ttraining's auc: 0.904911\tvalid_1's auc: 0.789333\n",
      "[4382]\ttraining's auc: 0.904925\tvalid_1's auc: 0.789332\n",
      "[4383]\ttraining's auc: 0.904944\tvalid_1's auc: 0.789334\n",
      "[4384]\ttraining's auc: 0.90496\tvalid_1's auc: 0.789335\n",
      "[4385]\ttraining's auc: 0.904975\tvalid_1's auc: 0.789341\n",
      "[4386]\ttraining's auc: 0.904984\tvalid_1's auc: 0.789335\n",
      "[4387]\ttraining's auc: 0.904996\tvalid_1's auc: 0.789334\n",
      "[4388]\ttraining's auc: 0.905006\tvalid_1's auc: 0.789332\n",
      "[4389]\ttraining's auc: 0.905023\tvalid_1's auc: 0.789329\n",
      "[4390]\ttraining's auc: 0.905027\tvalid_1's auc: 0.789327\n",
      "[4391]\ttraining's auc: 0.905039\tvalid_1's auc: 0.789332\n",
      "[4392]\ttraining's auc: 0.905058\tvalid_1's auc: 0.78933\n",
      "[4393]\ttraining's auc: 0.905074\tvalid_1's auc: 0.789331\n",
      "[4394]\ttraining's auc: 0.905097\tvalid_1's auc: 0.789334\n",
      "[4395]\ttraining's auc: 0.905111\tvalid_1's auc: 0.789345\n",
      "[4396]\ttraining's auc: 0.905127\tvalid_1's auc: 0.789352\n",
      "[4397]\ttraining's auc: 0.905141\tvalid_1's auc: 0.789347\n",
      "[4398]\ttraining's auc: 0.905155\tvalid_1's auc: 0.789354\n",
      "[4399]\ttraining's auc: 0.905171\tvalid_1's auc: 0.789352\n",
      "[4400]\ttraining's auc: 0.905189\tvalid_1's auc: 0.789355\n",
      "[4401]\ttraining's auc: 0.905209\tvalid_1's auc: 0.789351\n",
      "[4402]\ttraining's auc: 0.905217\tvalid_1's auc: 0.789351\n",
      "[4403]\ttraining's auc: 0.905234\tvalid_1's auc: 0.78935\n",
      "[4404]\ttraining's auc: 0.905242\tvalid_1's auc: 0.78935\n",
      "[4405]\ttraining's auc: 0.905258\tvalid_1's auc: 0.789348\n",
      "[4406]\ttraining's auc: 0.905263\tvalid_1's auc: 0.789349\n",
      "[4407]\ttraining's auc: 0.905275\tvalid_1's auc: 0.789347\n",
      "[4408]\ttraining's auc: 0.905295\tvalid_1's auc: 0.789348\n",
      "[4409]\ttraining's auc: 0.905308\tvalid_1's auc: 0.789349\n",
      "[4410]\ttraining's auc: 0.905314\tvalid_1's auc: 0.789347\n",
      "[4411]\ttraining's auc: 0.905337\tvalid_1's auc: 0.789353\n",
      "[4412]\ttraining's auc: 0.905352\tvalid_1's auc: 0.789353\n",
      "[4413]\ttraining's auc: 0.905369\tvalid_1's auc: 0.789348\n",
      "[4414]\ttraining's auc: 0.905387\tvalid_1's auc: 0.789354\n",
      "[4415]\ttraining's auc: 0.905408\tvalid_1's auc: 0.789348\n",
      "[4416]\ttraining's auc: 0.905429\tvalid_1's auc: 0.789339\n",
      "[4417]\ttraining's auc: 0.905443\tvalid_1's auc: 0.789336\n",
      "[4418]\ttraining's auc: 0.905462\tvalid_1's auc: 0.789335\n",
      "[4419]\ttraining's auc: 0.905483\tvalid_1's auc: 0.789333\n",
      "[4420]\ttraining's auc: 0.905506\tvalid_1's auc: 0.789335\n",
      "[4421]\ttraining's auc: 0.905522\tvalid_1's auc: 0.789342\n",
      "[4422]\ttraining's auc: 0.90554\tvalid_1's auc: 0.789338\n",
      "[4423]\ttraining's auc: 0.905559\tvalid_1's auc: 0.789329\n",
      "[4424]\ttraining's auc: 0.90557\tvalid_1's auc: 0.789329\n",
      "[4425]\ttraining's auc: 0.905577\tvalid_1's auc: 0.78933\n",
      "[4426]\ttraining's auc: 0.905584\tvalid_1's auc: 0.789331\n",
      "[4427]\ttraining's auc: 0.905603\tvalid_1's auc: 0.789339\n",
      "[4428]\ttraining's auc: 0.905618\tvalid_1's auc: 0.789338\n",
      "[4429]\ttraining's auc: 0.905638\tvalid_1's auc: 0.789331\n",
      "[4430]\ttraining's auc: 0.905655\tvalid_1's auc: 0.789335\n",
      "[4431]\ttraining's auc: 0.905673\tvalid_1's auc: 0.789335\n",
      "[4432]\ttraining's auc: 0.905696\tvalid_1's auc: 0.789333\n",
      "[4433]\ttraining's auc: 0.905703\tvalid_1's auc: 0.789335\n",
      "[4434]\ttraining's auc: 0.90572\tvalid_1's auc: 0.789339\n",
      "[4435]\ttraining's auc: 0.905739\tvalid_1's auc: 0.78934\n",
      "[4436]\ttraining's auc: 0.905752\tvalid_1's auc: 0.789333\n",
      "[4437]\ttraining's auc: 0.905759\tvalid_1's auc: 0.78933\n",
      "[4438]\ttraining's auc: 0.905765\tvalid_1's auc: 0.78933\n",
      "[4439]\ttraining's auc: 0.905782\tvalid_1's auc: 0.789334\n",
      "[4440]\ttraining's auc: 0.905794\tvalid_1's auc: 0.789332\n",
      "[4441]\ttraining's auc: 0.905807\tvalid_1's auc: 0.789333\n",
      "[4442]\ttraining's auc: 0.905822\tvalid_1's auc: 0.789334\n",
      "[4443]\ttraining's auc: 0.905824\tvalid_1's auc: 0.789333\n",
      "[4444]\ttraining's auc: 0.905837\tvalid_1's auc: 0.789334\n",
      "[4445]\ttraining's auc: 0.905852\tvalid_1's auc: 0.789331\n",
      "[4446]\ttraining's auc: 0.905868\tvalid_1's auc: 0.789323\n",
      "[4447]\ttraining's auc: 0.905882\tvalid_1's auc: 0.789322\n",
      "[4448]\ttraining's auc: 0.905897\tvalid_1's auc: 0.78932\n",
      "[4449]\ttraining's auc: 0.905904\tvalid_1's auc: 0.789323\n",
      "[4450]\ttraining's auc: 0.905927\tvalid_1's auc: 0.789322\n",
      "[4451]\ttraining's auc: 0.905944\tvalid_1's auc: 0.789322\n",
      "[4452]\ttraining's auc: 0.905964\tvalid_1's auc: 0.789322\n",
      "[4453]\ttraining's auc: 0.905982\tvalid_1's auc: 0.789322\n",
      "[4454]\ttraining's auc: 0.906002\tvalid_1's auc: 0.789322\n",
      "[4455]\ttraining's auc: 0.906026\tvalid_1's auc: 0.789322\n",
      "[4456]\ttraining's auc: 0.906029\tvalid_1's auc: 0.789322\n",
      "[4457]\ttraining's auc: 0.906044\tvalid_1's auc: 0.789323\n",
      "[4458]\ttraining's auc: 0.906065\tvalid_1's auc: 0.789329\n",
      "[4459]\ttraining's auc: 0.906084\tvalid_1's auc: 0.789333\n",
      "[4460]\ttraining's auc: 0.906086\tvalid_1's auc: 0.789333\n",
      "[4461]\ttraining's auc: 0.906101\tvalid_1's auc: 0.789329\n",
      "[4462]\ttraining's auc: 0.906112\tvalid_1's auc: 0.789331\n",
      "[4463]\ttraining's auc: 0.906117\tvalid_1's auc: 0.78933\n",
      "[4464]\ttraining's auc: 0.906131\tvalid_1's auc: 0.789331\n",
      "[4465]\ttraining's auc: 0.906152\tvalid_1's auc: 0.789332\n",
      "[4466]\ttraining's auc: 0.906172\tvalid_1's auc: 0.789331\n",
      "[4467]\ttraining's auc: 0.906177\tvalid_1's auc: 0.789331\n",
      "[4468]\ttraining's auc: 0.906199\tvalid_1's auc: 0.789339\n",
      "[4469]\ttraining's auc: 0.906213\tvalid_1's auc: 0.789336\n",
      "[4470]\ttraining's auc: 0.906234\tvalid_1's auc: 0.789334\n",
      "[4471]\ttraining's auc: 0.906253\tvalid_1's auc: 0.789332\n",
      "[4472]\ttraining's auc: 0.906271\tvalid_1's auc: 0.78933\n",
      "[4473]\ttraining's auc: 0.906284\tvalid_1's auc: 0.789334\n",
      "[4474]\ttraining's auc: 0.906299\tvalid_1's auc: 0.789332\n",
      "[4475]\ttraining's auc: 0.90632\tvalid_1's auc: 0.789329\n",
      "[4476]\ttraining's auc: 0.90634\tvalid_1's auc: 0.789331\n",
      "[4477]\ttraining's auc: 0.906347\tvalid_1's auc: 0.789335\n",
      "[4478]\ttraining's auc: 0.906364\tvalid_1's auc: 0.789335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4479]\ttraining's auc: 0.906387\tvalid_1's auc: 0.789332\n",
      "[4480]\ttraining's auc: 0.906405\tvalid_1's auc: 0.789332\n",
      "[4481]\ttraining's auc: 0.906415\tvalid_1's auc: 0.789328\n",
      "[4482]\ttraining's auc: 0.906432\tvalid_1's auc: 0.789327\n",
      "[4483]\ttraining's auc: 0.906447\tvalid_1's auc: 0.789321\n",
      "[4484]\ttraining's auc: 0.906463\tvalid_1's auc: 0.789317\n",
      "[4485]\ttraining's auc: 0.90648\tvalid_1's auc: 0.789315\n",
      "[4486]\ttraining's auc: 0.9065\tvalid_1's auc: 0.789312\n",
      "[4487]\ttraining's auc: 0.906527\tvalid_1's auc: 0.789307\n",
      "[4488]\ttraining's auc: 0.906537\tvalid_1's auc: 0.78931\n",
      "[4489]\ttraining's auc: 0.906555\tvalid_1's auc: 0.789314\n",
      "[4490]\ttraining's auc: 0.906567\tvalid_1's auc: 0.789319\n",
      "[4491]\ttraining's auc: 0.906584\tvalid_1's auc: 0.789321\n",
      "[4492]\ttraining's auc: 0.906609\tvalid_1's auc: 0.789317\n",
      "[4493]\ttraining's auc: 0.906619\tvalid_1's auc: 0.789318\n",
      "[4494]\ttraining's auc: 0.906641\tvalid_1's auc: 0.789323\n",
      "[4495]\ttraining's auc: 0.906657\tvalid_1's auc: 0.789321\n",
      "[4496]\ttraining's auc: 0.90666\tvalid_1's auc: 0.789321\n",
      "[4497]\ttraining's auc: 0.906678\tvalid_1's auc: 0.789317\n",
      "[4498]\ttraining's auc: 0.906693\tvalid_1's auc: 0.789311\n",
      "[4499]\ttraining's auc: 0.906711\tvalid_1's auc: 0.789305\n",
      "[4500]\ttraining's auc: 0.906718\tvalid_1's auc: 0.789305\n",
      "[4501]\ttraining's auc: 0.906734\tvalid_1's auc: 0.789307\n",
      "[4502]\ttraining's auc: 0.906746\tvalid_1's auc: 0.789308\n",
      "[4503]\ttraining's auc: 0.906764\tvalid_1's auc: 0.789301\n",
      "[4504]\ttraining's auc: 0.906782\tvalid_1's auc: 0.789304\n",
      "[4505]\ttraining's auc: 0.906802\tvalid_1's auc: 0.789308\n",
      "[4506]\ttraining's auc: 0.906821\tvalid_1's auc: 0.789314\n",
      "[4507]\ttraining's auc: 0.906834\tvalid_1's auc: 0.789313\n",
      "[4508]\ttraining's auc: 0.906853\tvalid_1's auc: 0.789316\n",
      "[4509]\ttraining's auc: 0.906876\tvalid_1's auc: 0.789311\n",
      "[4510]\ttraining's auc: 0.906894\tvalid_1's auc: 0.789308\n",
      "[4511]\ttraining's auc: 0.906909\tvalid_1's auc: 0.789306\n",
      "[4512]\ttraining's auc: 0.90692\tvalid_1's auc: 0.789309\n",
      "[4513]\ttraining's auc: 0.906935\tvalid_1's auc: 0.789307\n",
      "[4514]\ttraining's auc: 0.906957\tvalid_1's auc: 0.789306\n",
      "[4515]\ttraining's auc: 0.90698\tvalid_1's auc: 0.789305\n",
      "[4516]\ttraining's auc: 0.906988\tvalid_1's auc: 0.789304\n",
      "[4517]\ttraining's auc: 0.906996\tvalid_1's auc: 0.789303\n",
      "[4518]\ttraining's auc: 0.907011\tvalid_1's auc: 0.7893\n",
      "[4519]\ttraining's auc: 0.907024\tvalid_1's auc: 0.789302\n",
      "[4520]\ttraining's auc: 0.907042\tvalid_1's auc: 0.789304\n",
      "[4521]\ttraining's auc: 0.907063\tvalid_1's auc: 0.789302\n",
      "[4522]\ttraining's auc: 0.907082\tvalid_1's auc: 0.789302\n",
      "[4523]\ttraining's auc: 0.907098\tvalid_1's auc: 0.789296\n",
      "[4524]\ttraining's auc: 0.907114\tvalid_1's auc: 0.789293\n",
      "[4525]\ttraining's auc: 0.907134\tvalid_1's auc: 0.789292\n",
      "[4526]\ttraining's auc: 0.907147\tvalid_1's auc: 0.789292\n",
      "[4527]\ttraining's auc: 0.907162\tvalid_1's auc: 0.789299\n",
      "[4528]\ttraining's auc: 0.907188\tvalid_1's auc: 0.7893\n",
      "[4529]\ttraining's auc: 0.907202\tvalid_1's auc: 0.789299\n",
      "[4530]\ttraining's auc: 0.907219\tvalid_1's auc: 0.789301\n",
      "[4531]\ttraining's auc: 0.907233\tvalid_1's auc: 0.789299\n",
      "[4532]\ttraining's auc: 0.90725\tvalid_1's auc: 0.789297\n",
      "[4533]\ttraining's auc: 0.907266\tvalid_1's auc: 0.789293\n",
      "[4534]\ttraining's auc: 0.90728\tvalid_1's auc: 0.789295\n",
      "[4535]\ttraining's auc: 0.907293\tvalid_1's auc: 0.789295\n",
      "[4536]\ttraining's auc: 0.907306\tvalid_1's auc: 0.789298\n",
      "[4537]\ttraining's auc: 0.907325\tvalid_1's auc: 0.789298\n",
      "[4538]\ttraining's auc: 0.907344\tvalid_1's auc: 0.789305\n",
      "[4539]\ttraining's auc: 0.907365\tvalid_1's auc: 0.789297\n",
      "[4540]\ttraining's auc: 0.907386\tvalid_1's auc: 0.789303\n",
      "[4541]\ttraining's auc: 0.907406\tvalid_1's auc: 0.789303\n",
      "[4542]\ttraining's auc: 0.907422\tvalid_1's auc: 0.789306\n",
      "[4543]\ttraining's auc: 0.907444\tvalid_1's auc: 0.789306\n",
      "[4544]\ttraining's auc: 0.907463\tvalid_1's auc: 0.789304\n",
      "[4545]\ttraining's auc: 0.907472\tvalid_1's auc: 0.789307\n",
      "[4546]\ttraining's auc: 0.907488\tvalid_1's auc: 0.789309\n",
      "[4547]\ttraining's auc: 0.907497\tvalid_1's auc: 0.789308\n",
      "[4548]\ttraining's auc: 0.907518\tvalid_1's auc: 0.789307\n",
      "[4549]\ttraining's auc: 0.907544\tvalid_1's auc: 0.789304\n",
      "[4550]\ttraining's auc: 0.907558\tvalid_1's auc: 0.78931\n",
      "[4551]\ttraining's auc: 0.907578\tvalid_1's auc: 0.78931\n",
      "[4552]\ttraining's auc: 0.907592\tvalid_1's auc: 0.789307\n",
      "[4553]\ttraining's auc: 0.907605\tvalid_1's auc: 0.789303\n",
      "[4554]\ttraining's auc: 0.907623\tvalid_1's auc: 0.789303\n",
      "[4555]\ttraining's auc: 0.907639\tvalid_1's auc: 0.789305\n",
      "[4556]\ttraining's auc: 0.907648\tvalid_1's auc: 0.789304\n",
      "[4557]\ttraining's auc: 0.907669\tvalid_1's auc: 0.789302\n",
      "[4558]\ttraining's auc: 0.907679\tvalid_1's auc: 0.789303\n",
      "[4559]\ttraining's auc: 0.907694\tvalid_1's auc: 0.789297\n",
      "[4560]\ttraining's auc: 0.907713\tvalid_1's auc: 0.789298\n",
      "[4561]\ttraining's auc: 0.907738\tvalid_1's auc: 0.789294\n",
      "[4562]\ttraining's auc: 0.907756\tvalid_1's auc: 0.789289\n",
      "[4563]\ttraining's auc: 0.907771\tvalid_1's auc: 0.789292\n",
      "[4564]\ttraining's auc: 0.907786\tvalid_1's auc: 0.789295\n",
      "[4565]\ttraining's auc: 0.907794\tvalid_1's auc: 0.789294\n",
      "[4566]\ttraining's auc: 0.907812\tvalid_1's auc: 0.789299\n",
      "[4567]\ttraining's auc: 0.907842\tvalid_1's auc: 0.789304\n",
      "[4568]\ttraining's auc: 0.907845\tvalid_1's auc: 0.789303\n",
      "[4569]\ttraining's auc: 0.90787\tvalid_1's auc: 0.789298\n",
      "[4570]\ttraining's auc: 0.907889\tvalid_1's auc: 0.789298\n",
      "[4571]\ttraining's auc: 0.907907\tvalid_1's auc: 0.789297\n",
      "[4572]\ttraining's auc: 0.90792\tvalid_1's auc: 0.789293\n",
      "[4573]\ttraining's auc: 0.907936\tvalid_1's auc: 0.789291\n",
      "[4574]\ttraining's auc: 0.907952\tvalid_1's auc: 0.789289\n",
      "[4575]\ttraining's auc: 0.907972\tvalid_1's auc: 0.789286\n",
      "[4576]\ttraining's auc: 0.907992\tvalid_1's auc: 0.789284\n",
      "[4577]\ttraining's auc: 0.908011\tvalid_1's auc: 0.789283\n",
      "[4578]\ttraining's auc: 0.908027\tvalid_1's auc: 0.789286\n",
      "[4579]\ttraining's auc: 0.908043\tvalid_1's auc: 0.78928\n",
      "[4580]\ttraining's auc: 0.908049\tvalid_1's auc: 0.789281\n",
      "[4581]\ttraining's auc: 0.90806\tvalid_1's auc: 0.789283\n",
      "[4582]\ttraining's auc: 0.908075\tvalid_1's auc: 0.789281\n",
      "[4583]\ttraining's auc: 0.908097\tvalid_1's auc: 0.789278\n",
      "[4584]\ttraining's auc: 0.908111\tvalid_1's auc: 0.789277\n",
      "[4585]\ttraining's auc: 0.908135\tvalid_1's auc: 0.789278\n",
      "[4586]\ttraining's auc: 0.908159\tvalid_1's auc: 0.789276\n",
      "[4587]\ttraining's auc: 0.908174\tvalid_1's auc: 0.789272\n",
      "[4588]\ttraining's auc: 0.908185\tvalid_1's auc: 0.789272\n",
      "[4589]\ttraining's auc: 0.908197\tvalid_1's auc: 0.789275\n",
      "[4590]\ttraining's auc: 0.908219\tvalid_1's auc: 0.78928\n",
      "[4591]\ttraining's auc: 0.908236\tvalid_1's auc: 0.789283\n",
      "[4592]\ttraining's auc: 0.90825\tvalid_1's auc: 0.78928\n",
      "[4593]\ttraining's auc: 0.908263\tvalid_1's auc: 0.789283\n",
      "[4594]\ttraining's auc: 0.908288\tvalid_1's auc: 0.789284\n",
      "[4595]\ttraining's auc: 0.908305\tvalid_1's auc: 0.789279\n",
      "[4596]\ttraining's auc: 0.90832\tvalid_1's auc: 0.789284\n",
      "[4597]\ttraining's auc: 0.908333\tvalid_1's auc: 0.789285\n",
      "[4598]\ttraining's auc: 0.908343\tvalid_1's auc: 0.789278\n",
      "[4599]\ttraining's auc: 0.908361\tvalid_1's auc: 0.789276\n",
      "[4600]\ttraining's auc: 0.908379\tvalid_1's auc: 0.789279\n",
      "[4601]\ttraining's auc: 0.908397\tvalid_1's auc: 0.789281\n",
      "[4602]\ttraining's auc: 0.908417\tvalid_1's auc: 0.789282\n",
      "[4603]\ttraining's auc: 0.908437\tvalid_1's auc: 0.789279\n",
      "[4604]\ttraining's auc: 0.90845\tvalid_1's auc: 0.789277\n",
      "[4605]\ttraining's auc: 0.908464\tvalid_1's auc: 0.78928\n",
      "[4606]\ttraining's auc: 0.90848\tvalid_1's auc: 0.789282\n",
      "[4607]\ttraining's auc: 0.908498\tvalid_1's auc: 0.789279\n",
      "[4608]\ttraining's auc: 0.908518\tvalid_1's auc: 0.789274\n",
      "[4609]\ttraining's auc: 0.908535\tvalid_1's auc: 0.789278\n",
      "[4610]\ttraining's auc: 0.908551\tvalid_1's auc: 0.78928\n",
      "[4611]\ttraining's auc: 0.908563\tvalid_1's auc: 0.789278\n",
      "[4612]\ttraining's auc: 0.90858\tvalid_1's auc: 0.789283\n",
      "[4613]\ttraining's auc: 0.908589\tvalid_1's auc: 0.789284\n",
      "[4614]\ttraining's auc: 0.908596\tvalid_1's auc: 0.789283\n",
      "[4615]\ttraining's auc: 0.908615\tvalid_1's auc: 0.789279\n",
      "[4616]\ttraining's auc: 0.908627\tvalid_1's auc: 0.789282\n",
      "[4617]\ttraining's auc: 0.908646\tvalid_1's auc: 0.789293\n",
      "[4618]\ttraining's auc: 0.908653\tvalid_1's auc: 0.789291\n",
      "[4619]\ttraining's auc: 0.908664\tvalid_1's auc: 0.789287\n",
      "[4620]\ttraining's auc: 0.90868\tvalid_1's auc: 0.789285\n",
      "[4621]\ttraining's auc: 0.908695\tvalid_1's auc: 0.789287\n",
      "[4622]\ttraining's auc: 0.908703\tvalid_1's auc: 0.789286\n",
      "[4623]\ttraining's auc: 0.908719\tvalid_1's auc: 0.789283\n",
      "[4624]\ttraining's auc: 0.908724\tvalid_1's auc: 0.789285\n",
      "[4625]\ttraining's auc: 0.908732\tvalid_1's auc: 0.789286\n",
      "[4626]\ttraining's auc: 0.908736\tvalid_1's auc: 0.789285\n",
      "[4627]\ttraining's auc: 0.908752\tvalid_1's auc: 0.789286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4628]\ttraining's auc: 0.908769\tvalid_1's auc: 0.789283\n",
      "[4629]\ttraining's auc: 0.908792\tvalid_1's auc: 0.789275\n",
      "[4630]\ttraining's auc: 0.908806\tvalid_1's auc: 0.789274\n",
      "[4631]\ttraining's auc: 0.908823\tvalid_1's auc: 0.789273\n",
      "[4632]\ttraining's auc: 0.908843\tvalid_1's auc: 0.789281\n",
      "[4633]\ttraining's auc: 0.908849\tvalid_1's auc: 0.789279\n",
      "[4634]\ttraining's auc: 0.908856\tvalid_1's auc: 0.789281\n",
      "[4635]\ttraining's auc: 0.908877\tvalid_1's auc: 0.789283\n",
      "[4636]\ttraining's auc: 0.908886\tvalid_1's auc: 0.789282\n",
      "[4637]\ttraining's auc: 0.908905\tvalid_1's auc: 0.789282\n",
      "[4638]\ttraining's auc: 0.908922\tvalid_1's auc: 0.789283\n",
      "[4639]\ttraining's auc: 0.908935\tvalid_1's auc: 0.789284\n",
      "[4640]\ttraining's auc: 0.908949\tvalid_1's auc: 0.789285\n",
      "[4641]\ttraining's auc: 0.908964\tvalid_1's auc: 0.789278\n",
      "[4642]\ttraining's auc: 0.90898\tvalid_1's auc: 0.789276\n",
      "[4643]\ttraining's auc: 0.908993\tvalid_1's auc: 0.789276\n",
      "[4644]\ttraining's auc: 0.909006\tvalid_1's auc: 0.789276\n",
      "[4645]\ttraining's auc: 0.90902\tvalid_1's auc: 0.789274\n",
      "[4646]\ttraining's auc: 0.909038\tvalid_1's auc: 0.789273\n",
      "[4647]\ttraining's auc: 0.909057\tvalid_1's auc: 0.789277\n",
      "[4648]\ttraining's auc: 0.909074\tvalid_1's auc: 0.789278\n",
      "[4649]\ttraining's auc: 0.909091\tvalid_1's auc: 0.789274\n",
      "[4650]\ttraining's auc: 0.909107\tvalid_1's auc: 0.789275\n",
      "[4651]\ttraining's auc: 0.909113\tvalid_1's auc: 0.789274\n",
      "[4652]\ttraining's auc: 0.909129\tvalid_1's auc: 0.789271\n",
      "[4653]\ttraining's auc: 0.90914\tvalid_1's auc: 0.789266\n",
      "[4654]\ttraining's auc: 0.909154\tvalid_1's auc: 0.789263\n",
      "[4655]\ttraining's auc: 0.909164\tvalid_1's auc: 0.789268\n",
      "[4656]\ttraining's auc: 0.909181\tvalid_1's auc: 0.789268\n",
      "[4657]\ttraining's auc: 0.9092\tvalid_1's auc: 0.789263\n",
      "[4658]\ttraining's auc: 0.909217\tvalid_1's auc: 0.789261\n",
      "[4659]\ttraining's auc: 0.909231\tvalid_1's auc: 0.789259\n",
      "[4660]\ttraining's auc: 0.909244\tvalid_1's auc: 0.789259\n",
      "[4661]\ttraining's auc: 0.909253\tvalid_1's auc: 0.789264\n",
      "[4662]\ttraining's auc: 0.909262\tvalid_1's auc: 0.789258\n",
      "[4663]\ttraining's auc: 0.909285\tvalid_1's auc: 0.789258\n",
      "[4664]\ttraining's auc: 0.909298\tvalid_1's auc: 0.789255\n",
      "[4665]\ttraining's auc: 0.90931\tvalid_1's auc: 0.789251\n",
      "[4666]\ttraining's auc: 0.909327\tvalid_1's auc: 0.789244\n",
      "[4667]\ttraining's auc: 0.909347\tvalid_1's auc: 0.789247\n",
      "[4668]\ttraining's auc: 0.909365\tvalid_1's auc: 0.789243\n",
      "[4669]\ttraining's auc: 0.909376\tvalid_1's auc: 0.789237\n",
      "[4670]\ttraining's auc: 0.909401\tvalid_1's auc: 0.789245\n",
      "[4671]\ttraining's auc: 0.909419\tvalid_1's auc: 0.789248\n",
      "[4672]\ttraining's auc: 0.909425\tvalid_1's auc: 0.78925\n",
      "[4673]\ttraining's auc: 0.909444\tvalid_1's auc: 0.789252\n",
      "[4674]\ttraining's auc: 0.90946\tvalid_1's auc: 0.789254\n",
      "[4675]\ttraining's auc: 0.909474\tvalid_1's auc: 0.78926\n",
      "[4676]\ttraining's auc: 0.909491\tvalid_1's auc: 0.789259\n",
      "[4677]\ttraining's auc: 0.909501\tvalid_1's auc: 0.789257\n",
      "[4678]\ttraining's auc: 0.909519\tvalid_1's auc: 0.789261\n",
      "[4679]\ttraining's auc: 0.909535\tvalid_1's auc: 0.78926\n",
      "[4680]\ttraining's auc: 0.909551\tvalid_1's auc: 0.789254\n",
      "[4681]\ttraining's auc: 0.909565\tvalid_1's auc: 0.789252\n",
      "[4682]\ttraining's auc: 0.909579\tvalid_1's auc: 0.789255\n",
      "[4683]\ttraining's auc: 0.909603\tvalid_1's auc: 0.789254\n",
      "[4684]\ttraining's auc: 0.909616\tvalid_1's auc: 0.789254\n",
      "[4685]\ttraining's auc: 0.909632\tvalid_1's auc: 0.789257\n",
      "[4686]\ttraining's auc: 0.909645\tvalid_1's auc: 0.789259\n",
      "[4687]\ttraining's auc: 0.909666\tvalid_1's auc: 0.789259\n",
      "[4688]\ttraining's auc: 0.909683\tvalid_1's auc: 0.789257\n",
      "[4689]\ttraining's auc: 0.909698\tvalid_1's auc: 0.789252\n",
      "[4690]\ttraining's auc: 0.909716\tvalid_1's auc: 0.78926\n",
      "[4691]\ttraining's auc: 0.909735\tvalid_1's auc: 0.78926\n",
      "[4692]\ttraining's auc: 0.909755\tvalid_1's auc: 0.78926\n",
      "[4693]\ttraining's auc: 0.909768\tvalid_1's auc: 0.789256\n",
      "[4694]\ttraining's auc: 0.909791\tvalid_1's auc: 0.78925\n",
      "[4695]\ttraining's auc: 0.909808\tvalid_1's auc: 0.789251\n",
      "[4696]\ttraining's auc: 0.909826\tvalid_1's auc: 0.789251\n",
      "[4697]\ttraining's auc: 0.909842\tvalid_1's auc: 0.789255\n",
      "[4698]\ttraining's auc: 0.909855\tvalid_1's auc: 0.789259\n",
      "[4699]\ttraining's auc: 0.909873\tvalid_1's auc: 0.789264\n",
      "[4700]\ttraining's auc: 0.909891\tvalid_1's auc: 0.78927\n",
      "[4701]\ttraining's auc: 0.909898\tvalid_1's auc: 0.78927\n",
      "[4702]\ttraining's auc: 0.909908\tvalid_1's auc: 0.789271\n",
      "[4703]\ttraining's auc: 0.909917\tvalid_1's auc: 0.789271\n",
      "[4704]\ttraining's auc: 0.909937\tvalid_1's auc: 0.78927\n",
      "[4705]\ttraining's auc: 0.909952\tvalid_1's auc: 0.78927\n",
      "[4706]\ttraining's auc: 0.909962\tvalid_1's auc: 0.789268\n",
      "[4707]\ttraining's auc: 0.909986\tvalid_1's auc: 0.789263\n",
      "[4708]\ttraining's auc: 0.909994\tvalid_1's auc: 0.789262\n",
      "[4709]\ttraining's auc: 0.910014\tvalid_1's auc: 0.789261\n",
      "[4710]\ttraining's auc: 0.910028\tvalid_1's auc: 0.789262\n",
      "[4711]\ttraining's auc: 0.910043\tvalid_1's auc: 0.789259\n",
      "[4712]\ttraining's auc: 0.910054\tvalid_1's auc: 0.789255\n",
      "[4713]\ttraining's auc: 0.910069\tvalid_1's auc: 0.789256\n",
      "[4714]\ttraining's auc: 0.910078\tvalid_1's auc: 0.789257\n",
      "[4715]\ttraining's auc: 0.91009\tvalid_1's auc: 0.789257\n",
      "[4716]\ttraining's auc: 0.910104\tvalid_1's auc: 0.789257\n",
      "[4717]\ttraining's auc: 0.910116\tvalid_1's auc: 0.789257\n",
      "[4718]\ttraining's auc: 0.910134\tvalid_1's auc: 0.789256\n",
      "[4719]\ttraining's auc: 0.910152\tvalid_1's auc: 0.78925\n",
      "[4720]\ttraining's auc: 0.910166\tvalid_1's auc: 0.789252\n",
      "[4721]\ttraining's auc: 0.910183\tvalid_1's auc: 0.789253\n",
      "[4722]\ttraining's auc: 0.910198\tvalid_1's auc: 0.78925\n",
      "[4723]\ttraining's auc: 0.910217\tvalid_1's auc: 0.789248\n",
      "[4724]\ttraining's auc: 0.910232\tvalid_1's auc: 0.789247\n",
      "[4725]\ttraining's auc: 0.910243\tvalid_1's auc: 0.789243\n",
      "[4726]\ttraining's auc: 0.910261\tvalid_1's auc: 0.789241\n",
      "[4727]\ttraining's auc: 0.910277\tvalid_1's auc: 0.789231\n",
      "[4728]\ttraining's auc: 0.910285\tvalid_1's auc: 0.789232\n",
      "[4729]\ttraining's auc: 0.910301\tvalid_1's auc: 0.789232\n",
      "[4730]\ttraining's auc: 0.910312\tvalid_1's auc: 0.789227\n",
      "[4731]\ttraining's auc: 0.910333\tvalid_1's auc: 0.78923\n",
      "[4732]\ttraining's auc: 0.910347\tvalid_1's auc: 0.789228\n",
      "[4733]\ttraining's auc: 0.910352\tvalid_1's auc: 0.789225\n",
      "[4734]\ttraining's auc: 0.91037\tvalid_1's auc: 0.789224\n",
      "[4735]\ttraining's auc: 0.910389\tvalid_1's auc: 0.789223\n",
      "[4736]\ttraining's auc: 0.910407\tvalid_1's auc: 0.789217\n",
      "[4737]\ttraining's auc: 0.910424\tvalid_1's auc: 0.789212\n",
      "[4738]\ttraining's auc: 0.910435\tvalid_1's auc: 0.789209\n",
      "[4739]\ttraining's auc: 0.910452\tvalid_1's auc: 0.789209\n",
      "[4740]\ttraining's auc: 0.910455\tvalid_1's auc: 0.789206\n",
      "[4741]\ttraining's auc: 0.910468\tvalid_1's auc: 0.789207\n",
      "[4742]\ttraining's auc: 0.910475\tvalid_1's auc: 0.789209\n",
      "[4743]\ttraining's auc: 0.910493\tvalid_1's auc: 0.78921\n",
      "[4744]\ttraining's auc: 0.910506\tvalid_1's auc: 0.789209\n",
      "[4745]\ttraining's auc: 0.910523\tvalid_1's auc: 0.789206\n",
      "[4746]\ttraining's auc: 0.910535\tvalid_1's auc: 0.789206\n",
      "[4747]\ttraining's auc: 0.910549\tvalid_1's auc: 0.78921\n",
      "[4748]\ttraining's auc: 0.910571\tvalid_1's auc: 0.789204\n",
      "[4749]\ttraining's auc: 0.910576\tvalid_1's auc: 0.789202\n",
      "[4750]\ttraining's auc: 0.910583\tvalid_1's auc: 0.789201\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"clf = lgb.train(\\n    params,\\n    training_dataset,\\n    valid_sets=[training_dataset, testing_dataset],\\n)\";\n",
       "                var nbb_formatted_code = \"clf = lgb.train(\\n    params,\\n    training_dataset,\\n    valid_sets=[training_dataset, testing_dataset],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = lgb.train(\n",
    "    params,\n",
    "    training_dataset,\n",
    "    valid_sets=[training_dataset, testing_dataset],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"y_proba = clf.predict(X_val)\\nto_csv(y_proba, \\\"lgbm_WHO_WILL_WIN\\\")\";\n",
       "                var nbb_formatted_code = \"y_proba = clf.predict(X_val)\\nto_csv(y_proba, \\\"lgbm_WHO_WILL_WIN\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_proba = clf.predict(X_val)\n",
    "to_csv(y_proba, \"lgbm_WHO_WILL_WIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. When dealing with many to one relationship inside csv files, it would be more efficient to extract not only AVG and COUNT but MIN, MAX as well.\n",
    "2. Sometimes advanced imputing techniques like IterativeImputer, KNNImputer and MiceImputer could create bias inside of datasets and SimpleImputer with constant filling outperforms them.\n",
    "3. Creating different features out of existing ones was the crucial part of the project.\n",
    "4. Clustering as a feature had the highest correlation coeficient with the target.\n",
    "5. When dealing with big datasets, it is important to choose fast models. LightGBM helped a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](proof.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
